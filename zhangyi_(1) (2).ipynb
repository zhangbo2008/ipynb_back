{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29af6e22ca994f5ca3fd02ed9babcd18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_272c45848ad94f99872c1c6c198fd9d2",
              "IPY_MODEL_3d814a46af2a4749a771e369b8163eb6",
              "IPY_MODEL_5395576a9f6b4c60960468f6fb91edab"
            ],
            "layout": "IPY_MODEL_0055493399da4f7198f110a2f2dfc0db"
          }
        },
        "272c45848ad94f99872c1c6c198fd9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21c85c90ada4986b1191bb2a06c1033",
            "placeholder": "​",
            "style": "IPY_MODEL_d4bd82a61e384e5c90c56b2432f2bc28",
            "value": "Caching latents: 100%"
          }
        },
        "3d814a46af2a4749a771e369b8163eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20ec550829154f7584793f9837360e79",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d057bc34d8f94558b1a0406f179c764c",
            "value": 8
          }
        },
        "5395576a9f6b4c60960468f6fb91edab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c87b38d40ad4c168b259b519d7dd07d",
            "placeholder": "​",
            "style": "IPY_MODEL_a1495180f7c34eceb4da25eaabdb95e2",
            "value": " 8/8 [00:01&lt;00:00,  5.36it/s]"
          }
        },
        "0055493399da4f7198f110a2f2dfc0db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21c85c90ada4986b1191bb2a06c1033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4bd82a61e384e5c90c56b2432f2bc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20ec550829154f7584793f9837360e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d057bc34d8f94558b1a0406f179c764c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c87b38d40ad4c168b259b519d7dd07d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1495180f7c34eceb4da25eaabdb95e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff79a279698a42b0a92d8965508e3ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f04b6b376d294826b6a17b2199a0cd1c",
              "IPY_MODEL_84bc58177d4141b1a91f3fd2c67fac1f",
              "IPY_MODEL_943dc465516a4faea20eb9c7d6300df1"
            ],
            "layout": "IPY_MODEL_01e3ad20b421438b952a522e32d0ee86"
          }
        },
        "f04b6b376d294826b6a17b2199a0cd1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aedcaa4032b645bcbc3f97345c345723",
            "placeholder": "​",
            "style": "IPY_MODEL_e7c3b7bf321542b3b1f6029dcd9e0f9f",
            "value": "Steps:   0%"
          }
        },
        "84bc58177d4141b1a91f3fd2c67fac1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f70ad8e46e994edd9b45c4ac694af22a",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecb4c33f74204cc29558ad4ee086c146",
            "value": 0
          }
        },
        "943dc465516a4faea20eb9c7d6300df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a0c41b835842fc971276e7cb57b12a",
            "placeholder": "​",
            "style": "IPY_MODEL_7ef228dabbbf47b48de1b55c0493c46d",
            "value": " 0/800 [00:00&lt;?, ?it/s]"
          }
        },
        "01e3ad20b421438b952a522e32d0ee86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aedcaa4032b645bcbc3f97345c345723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c3b7bf321542b3b1f6029dcd9e0f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f70ad8e46e994edd9b45c4ac694af22a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecb4c33f74204cc29558ad4ee086c146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97a0c41b835842fc971276e7cb57b12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef228dabbbf47b48de1b55c0493c46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YGTJaVkLuQn",
        "outputId": "157b1069-cf88-4a71-9473-03deb52dcc6c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/zhangbo2008/person_face\n",
        "!git clone https://github.com/zhangbo2008/zhangyi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mkbg3_li287",
        "outputId": "fad1e289-61a1-4095-ae28-6bd1d5cfba72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'person_face'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 10 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (10/10), 659.32 KiB | 1.06 MiB/s, done.\n",
            "Cloning into 'zhangyi'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), 804.48 KiB | 1.43 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" \n",
        "\n",
        "\n",
        "OUTPUT_DIR = \"stable_diffusion_weights/sd_v15_dr\"\n",
        "!mkdir -p $OUTPUT_DIR\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":      \"photo of zhangyi_person\",\n",
        "        \"instance_data_dir\":    \"zhangyi\",\n",
        "                     \"class_prompt\":         \"photo of person\",\n",
        "        \"class_data_dir\":       \"person_face\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# `class_data_dir` contains regularization images\n",
        "import json\n",
        "import os\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)\n"
      ],
      "metadata": {
        "id": "SIiI1b9uL9dl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import hashlib\n",
        "import itertools\n",
        "import random\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "from contextlib import nullcontext\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from accelerate.logging import get_logger\n",
        "from accelerate.utils import set_seed\n",
        "from diffusers import AutoencoderKL, DDIMScheduler, DDPMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n",
        "from diffusers.optimization import get_scheduler\n",
        "from diffusers.utils.import_utils import is_xformers_available\n",
        "from huggingface_hub import HfFolder, Repository, whoami\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "logger = get_logger(__name__)\n",
        "\n",
        "\n",
        "def parse_args(input_args=None):\n",
        "\n",
        "    MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" \n",
        "    OUTPUT_DIR = \"stable_diffusion_weights/sd_v15_dr\"\n",
        "    parser = argparse.ArgumentParser(description=\"Simple example of a training script.\")\n",
        "    parser.add_argument(\n",
        "        \"--pretrained_model_name_or_path\",\n",
        "        type=str,\n",
        "        default=MODEL_NAME,\n",
        "        required=False,\n",
        "        help=\"Path to pretrained model or model identifier from huggingface.co/models.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--pretrained_vae_name_or_path\",\n",
        "        type=str,\n",
        "        default=\"stabilityai/sd-vae-ft-mse\",\n",
        "        help=\"Path to pretrained vae or vae identifier from huggingface.co/models.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--revision\",\n",
        "        type=str,\n",
        "        default='fp16',\n",
        "        required=False,\n",
        "        help=\"Revision of pretrained model identifier from huggingface.co/models.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--tokenizer_name\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--instance_data_dir\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"A folder containing the training data of instance images.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--class_data_dir\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"A folder containing the training data of class images.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--instance_prompt\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"The prompt with identifier specifying the instance\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--class_prompt\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"The prompt to specify images in the same class as provided instance images.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--save_sample_prompt\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"The prompt used to generate sample outputs to save.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--save_sample_negative_prompt\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"The negative prompt used to generate sample outputs to save.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--n_save_sample\",\n",
        "        type=int,\n",
        "        default=4,\n",
        "        help=\"The number of samples to save.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--save_guidance_scale\",\n",
        "        type=float,\n",
        "        default=7.5,\n",
        "        help=\"CFG for save sample.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--save_infer_steps\",\n",
        "        type=int,\n",
        "        default=20,\n",
        "        help=\"The number of inference steps for save sample.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--pad_tokens\",\n",
        "        default=False,\n",
        "        action=\"store_true\",\n",
        "        help=\"Flag to pad tokens to length 77.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--with_prior_preservation\",\n",
        "        default=True,\n",
        "        action=\"store_true\",\n",
        "        help=\"Flag to add prior preservation loss.\",\n",
        "    )\n",
        "    parser.add_argument(\"--prior_loss_weight\", type=float, default=1.0, help=\"The weight of prior preservation loss.\")\n",
        "    parser.add_argument(\n",
        "        \"--num_class_images\",\n",
        "        type=int,\n",
        "        default=100,\n",
        "        help=(\n",
        "            \"Minimal class images for prior preservation loss. If not have enough images, additional images will be\"\n",
        "            \" sampled with class_prompt.\"\n",
        "        ),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\",\n",
        "        type=str,\n",
        "        default=OUTPUT_DIR,\n",
        "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        "    )\n",
        "    parser.add_argument(\"--seed\", type=int, default=None, help=\"A seed for reproducible training.\")\n",
        "    parser.add_argument(\n",
        "        \"--resolution\",\n",
        "        type=int,\n",
        "        default=512,\n",
        "        help=(\n",
        "            \"The resolution for input images, all the images in the train/validation dataset will be resized to this\"\n",
        "            \" resolution\"\n",
        "        ),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--center_crop\", action=\"store_true\", help=\"Whether to center crop images before resizing to resolution\"\n",
        "    )\n",
        "    parser.add_argument(\"--train_text_encoder\", action=\"store_true\", help=\"Whether to train the text encoder\")\n",
        "    parser.add_argument(\n",
        "        \"--train_batch_size\", type=int, default=4, help=\"Batch size (per device) for the training dataloader.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--sample_batch_size\", type=int, default=4, help=\"Batch size (per device) for sampling images.\"\n",
        "    )\n",
        "    parser.add_argument(\"--num_train_epochs\", type=int, default=1)\n",
        "    parser.add_argument(\n",
        "        \"--max_train_steps\",\n",
        "        type=int,\n",
        "        default=None,\n",
        "        help=\"Total number of training steps to perform.  If provided, overrides num_train_epochs.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gradient_accumulation_steps\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gradient_checkpointing\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether or not to use gradient checkpointing to save memory at the expense of slower backward pass.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--learning_rate\",\n",
        "        type=float,\n",
        "        default=5e-6,\n",
        "        help=\"Initial learning rate (after the potential warmup period) to use.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--scale_lr\",\n",
        "        action=\"store_true\",\n",
        "        default=False,\n",
        "        help=\"Scale the learning rate by the number of GPUs, gradient accumulation steps, and batch size.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--lr_scheduler\",\n",
        "        type=str,\n",
        "        default=\"constant\",\n",
        "        help=(\n",
        "            'The scheduler type to use. Choose between [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\",'\n",
        "            ' \"constant\", \"constant_with_warmup\"]'\n",
        "        ),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--lr_warmup_steps\", type=int, default=500, help=\"Number of steps for the warmup in the lr scheduler.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--use_8bit_adam\", action=\"store_true\", help=\"Whether or not to use 8-bit Adam from bitsandbytes.\"\n",
        "    )\n",
        "    parser.add_argument(\"--adam_beta1\", type=float, default=0.9, help=\"The beta1 parameter for the Adam optimizer.\")\n",
        "    parser.add_argument(\"--adam_beta2\", type=float, default=0.999, help=\"The beta2 parameter for the Adam optimizer.\")\n",
        "    parser.add_argument(\"--adam_weight_decay\", type=float, default=1e-2, help=\"Weight decay to use.\")\n",
        "    parser.add_argument(\"--adam_epsilon\", type=float, default=1e-08, help=\"Epsilon value for the Adam optimizer\")\n",
        "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
        "    parser.add_argument(\"--push_to_hub\", action=\"store_true\", help=\"Whether or not to push the model to the Hub.\")\n",
        "    parser.add_argument(\"--hub_token\", type=str, default=None, help=\"The token to use to push to the Model Hub.\")\n",
        "    parser.add_argument(\n",
        "        \"--hub_model_id\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"The name of the repository to keep in sync with the local `output_dir`.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--logging_dir\",\n",
        "        type=str,\n",
        "        default=\"logs\",\n",
        "        help=(\n",
        "            \"[TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to\"\n",
        "            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n",
        "        ),\n",
        "    )\n",
        "    parser.add_argument(\"--log_interval\", type=int, default=10, help=\"Log every N steps.\")\n",
        "    parser.add_argument(\"--save_interval\", type=int, default=10_000, help=\"Save weights every N steps.\")\n",
        "    parser.add_argument(\"--save_min_steps\", type=int, default=0, help=\"Start saving weights after N steps.\")\n",
        "    parser.add_argument(\n",
        "        \"--mixed_precision\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        choices=[\"no\", \"fp16\", \"bf16\"],\n",
        "        help=(\n",
        "            \"Whether to use mixed precision. Choose between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >=\"\n",
        "            \" 1.10.and an Nvidia Ampere GPU.  Default to the value of accelerate config of the current system or the\"\n",
        "            \" flag passed with the `accelerate.launch` command. Use this argument to override the accelerate config.\"\n",
        "        ),\n",
        "    )\n",
        "    parser.add_argument(\"--not_cache_latents\", action=\"store_true\", help=\"Do not precompute and cache latents from VAE.\")\n",
        "    parser.add_argument(\"--hflip\", action=\"store_true\", help=\"Apply horizontal flip data augmentation.\")\n",
        "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n",
        "    parser.add_argument(\n",
        "        \"--concepts_list\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"Path to json containing multiple concepts, will overwrite parameters like instance_prompt, class_prompt, etc.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--read_prompts_from_txts\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Use prompt per image. Put prompts in the same directory as images, e.g. for image.png create image.png.txt.\",\n",
        "    )\n",
        "\n",
        "    if input_args is not None:\n",
        "        args = parser.parse_args(input_args)\n",
        "    else:\n",
        "        args = parser.parse_args()\n",
        "\n",
        "    env_local_rank = int(os.environ.get(\"LOCAL_RANK\", -1))\n",
        "    if env_local_rank != -1 and env_local_rank != args.local_rank:\n",
        "        args.local_rank = env_local_rank\n",
        "\n",
        "\n",
        "    args.seed=1337 \n",
        "    args.resolution=512 \n",
        "    args.train_batch_size=1 \n",
        "    args.train_text_encoder=False\n",
        "    args.mixed_precision=\"fp16\"\n",
        "    args.use_8bit_adam=True\n",
        "    args.gradient_accumulation_steps=1 \n",
        "    args.learning_rate=1e-6 \n",
        "    args.lr_scheduler=\"constant\" \n",
        "    args.lr_warmup_steps=0 \n",
        "    args.num_class_images=8 \n",
        "    args.sample_batch_size=4 \n",
        "    args.max_train_steps=800 \n",
        "    args.save_interval=10000 \n",
        "    args.concepts_list=\"concepts_list.json\"\n",
        "    \n",
        "\n",
        "\n",
        "\t\t\n",
        "    return args\n",
        "\n",
        "\n",
        "class DreamBoothDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset to prepare the instance and class images with the prompts for fine-tuning the model.\n",
        "    It pre-processes the images and the tokenizes prompts.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        concepts_list,\n",
        "        tokenizer,\n",
        "        with_prior_preservation=True,\n",
        "        size=512,\n",
        "        center_crop=False,\n",
        "        num_class_images=None,\n",
        "        pad_tokens=False,\n",
        "        hflip=False,\n",
        "        read_prompts_from_txts=False,\n",
        "    ):\n",
        "        self.size = size\n",
        "        self.center_crop = center_crop\n",
        "        self.tokenizer = tokenizer\n",
        "        self.with_prior_preservation = with_prior_preservation\n",
        "        self.pad_tokens = pad_tokens\n",
        "        self.read_prompts_from_txts = read_prompts_from_txts\n",
        "\n",
        "        self.instance_images_path = []\n",
        "        self.class_images_path = []\n",
        "\n",
        "        for concept in concepts_list:\n",
        "            inst_img_path = [\n",
        "                (x, concept[\"instance_prompt\"])\n",
        "                for x in Path(concept[\"instance_data_dir\"]).iterdir()\n",
        "                if x.is_file() and not str(x).endswith(\".txt\")\n",
        "            ]\n",
        "            self.instance_images_path.extend(inst_img_path)\n",
        "\n",
        "            if with_prior_preservation:\n",
        "                class_img_path = [(x, concept[\"class_prompt\"]) for x in Path(concept[\"class_data_dir\"]).iterdir() if x.is_file()]\n",
        "                self.class_images_path.extend(class_img_path[:num_class_images])\n",
        "\n",
        "        random.shuffle(self.instance_images_path)\n",
        "        self.num_instance_images = len(self.instance_images_path)\n",
        "        self.num_class_images = len(self.class_images_path)\n",
        "        self._length = max(self.num_class_images, self.num_instance_images)\n",
        "\n",
        "        self.image_transforms = transforms.Compose(\n",
        "            [\n",
        "                transforms.RandomHorizontalFlip(0.5 * hflip),\n",
        "                transforms.Resize(size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "                transforms.CenterCrop(size) if center_crop else transforms.RandomCrop(size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.5], [0.5]),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        example = {}\n",
        "        instance_path, instance_prompt = self.instance_images_path[index % self.num_instance_images]\n",
        "\n",
        "        if self.read_prompts_from_txts:\n",
        "            with open(str(instance_path) + \".txt\") as f:\n",
        "                instance_prompt = f.read().strip()\n",
        "\n",
        "        instance_image = Image.open(instance_path)\n",
        "        if not instance_image.mode == \"RGB\":\n",
        "            instance_image = instance_image.convert(\"RGB\")\n",
        "\n",
        "        example[\"instance_images\"] = self.image_transforms(instance_image)\n",
        "        example[\"instance_prompt_ids\"] = self.tokenizer(\n",
        "            instance_prompt,\n",
        "            padding=\"max_length\" if self.pad_tokens else \"do_not_pad\",\n",
        "            truncation=True,\n",
        "            max_length=self.tokenizer.model_max_length,\n",
        "        ).input_ids\n",
        "\n",
        "        if self.with_prior_preservation:\n",
        "            class_path, class_prompt = self.class_images_path[index % self.num_class_images]\n",
        "            class_image = Image.open(class_path)\n",
        "            if not class_image.mode == \"RGB\":\n",
        "                class_image = class_image.convert(\"RGB\")\n",
        "            example[\"class_images\"] = self.image_transforms(class_image)\n",
        "            example[\"class_prompt_ids\"] = self.tokenizer(\n",
        "                class_prompt,\n",
        "                padding=\"max_length\" if self.pad_tokens else \"do_not_pad\",\n",
        "                truncation=True,\n",
        "                max_length=self.tokenizer.model_max_length,\n",
        "            ).input_ids\n",
        "\n",
        "        return example\n",
        "\n",
        "\n",
        "class PromptDataset(Dataset):\n",
        "    \"A simple dataset to prepare the prompts to generate class images on multiple GPUs.\"\n",
        "\n",
        "    def __init__(self, prompt, num_samples):\n",
        "        self.prompt = prompt\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        example = {}\n",
        "        example[\"prompt\"] = self.prompt\n",
        "        example[\"index\"] = index\n",
        "        return example\n",
        "\n",
        "\n",
        "class LatentsDataset(Dataset):\n",
        "    def __init__(self, latents_cache, text_encoder_cache):\n",
        "        self.latents_cache = latents_cache\n",
        "        self.text_encoder_cache = text_encoder_cache\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.latents_cache)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.latents_cache[index], self.text_encoder_cache[index]\n",
        "\n",
        "\n",
        "class AverageMeter:\n",
        "    def __init__(self, name=None):\n",
        "        self.name = name\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.sum = self.count = self.avg = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def get_full_repo_name(model_id: str, organization: Optional[str] = None, token: Optional[str] = None):\n",
        "    if token is None:\n",
        "        token = HfFolder.get_token()\n",
        "    if organization is None:\n",
        "        username = whoami(token)[\"name\"]\n",
        "        return f\"{username}/{model_id}\"\n",
        "    else:\n",
        "        return f\"{organization}/{model_id}\"\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    logging_dir = Path(args.output_dir, \"0\", args.logging_dir)\n",
        "\n",
        "    accelerator = Accelerator(\n",
        "        gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
        "        mixed_precision=args.mixed_precision,\n",
        "        log_with=\"tensorboard\",\n",
        "        logging_dir=logging_dir,\n",
        "    )\n",
        "\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        "    )\n",
        "\n",
        "    # Currently, it's not possible to do gradient accumulation when training two models with accelerate.accumulate\n",
        "    # This will be enabled soon in accelerate. For now, we don't allow gradient accumulation when training two models.\n",
        "    # TODO (patil-suraj): Remove this check when gradient accumulation with two models is enabled in accelerate.\n",
        "    if args.train_text_encoder and args.gradient_accumulation_steps > 1 and accelerator.num_processes > 1:\n",
        "        raise ValueError(\n",
        "            \"Gradient accumulation is not supported when training the text encoder in distributed training. \"\n",
        "            \"Please set gradient_accumulation_steps to 1. This feature will be supported in the future.\"\n",
        "        )\n",
        "\n",
        "    if args.seed is not None:\n",
        "        set_seed(args.seed)\n",
        "\n",
        "    if args.concepts_list is None:\n",
        "        args.concepts_list = [\n",
        "            {\n",
        "                \"instance_prompt\": args.instance_prompt,\n",
        "                \"class_prompt\": args.class_prompt,\n",
        "                \"instance_data_dir\": args.instance_data_dir,\n",
        "                \"class_data_dir\": args.class_data_dir\n",
        "            }\n",
        "        ]\n",
        "    else:\n",
        "        with open(args.concepts_list, \"r\") as f:\n",
        "            args.concepts_list = json.load(f)\n",
        "\n",
        "    if args.with_prior_preservation:\n",
        "        pipeline = None\n",
        "        for concept in args.concepts_list:\n",
        "            class_images_dir = Path(concept[\"class_data_dir\"])\n",
        "            class_images_dir.mkdir(parents=True, exist_ok=True)\n",
        "            cur_class_images = len(list(class_images_dir.iterdir()))\n",
        "\n",
        "            if cur_class_images < args.num_class_images:\n",
        "                torch_dtype = torch.float16 if accelerator.device.type == \"cuda\" else torch.float32\n",
        "                if pipeline is None:\n",
        "                    pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "                        args.pretrained_model_name_or_path,\n",
        "                        vae=AutoencoderKL.from_pretrained(\n",
        "                            args.pretrained_vae_name_or_path or args.pretrained_model_name_or_path,\n",
        "                            subfolder=None if args.pretrained_vae_name_or_path else \"vae\",\n",
        "                            revision=None if args.pretrained_vae_name_or_path else args.revision,\n",
        "                            torch_dtype=torch_dtype\n",
        "                        ),\n",
        "                        torch_dtype=torch_dtype,\n",
        "                        safety_checker=None,\n",
        "                        revision=args.revision\n",
        "                    )\n",
        "                    pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)\n",
        "                    if is_xformers_available():\n",
        "                        pipeline.enable_xformers_memory_efficient_attention()\n",
        "                    pipeline.set_progress_bar_config(disable=True)\n",
        "                    pipeline.to(accelerator.device)\n",
        "\n",
        "                num_new_images = args.num_class_images - cur_class_images\n",
        "                logger.info(f\"Number of class images to sample: {num_new_images}.\")\n",
        "\n",
        "                sample_dataset = PromptDataset(concept[\"class_prompt\"], num_new_images)\n",
        "                sample_dataloader = torch.utils.data.DataLoader(sample_dataset, batch_size=args.sample_batch_size)\n",
        "\n",
        "                sample_dataloader = accelerator.prepare(sample_dataloader)\n",
        "\n",
        "                with torch.autocast(\"cuda\"), torch.inference_mode():\n",
        "                    for example in tqdm(\n",
        "                        sample_dataloader, desc=\"Generating class images\", disable=not accelerator.is_local_main_process\n",
        "                    ):\n",
        "                        images = pipeline(\n",
        "                            example[\"prompt\"],\n",
        "                            num_inference_steps=args.save_infer_steps\n",
        "                            ).images\n",
        "\n",
        "                        for i, image in enumerate(images):\n",
        "                            hash_image = hashlib.sha1(image.tobytes()).hexdigest()\n",
        "                            image_filename = class_images_dir / f\"{example['index'][i] + cur_class_images}-{hash_image}.jpg\"\n",
        "                            image.save(image_filename)\n",
        "\n",
        "        del pipeline\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Load the tokenizer\n",
        "    if args.tokenizer_name:\n",
        "        tokenizer = CLIPTokenizer.from_pretrained(\n",
        "            args.tokenizer_name,\n",
        "            revision=args.revision,\n",
        "        )\n",
        "    elif args.pretrained_model_name_or_path:\n",
        "        tokenizer = CLIPTokenizer.from_pretrained(\n",
        "            args.pretrained_model_name_or_path,\n",
        "            subfolder=\"tokenizer\",\n",
        "            revision=args.revision,\n",
        "        )\n",
        "\n",
        "    # Load models and create wrapper for stable diffusion\n",
        "    text_encoder = CLIPTextModel.from_pretrained(\n",
        "        args.pretrained_model_name_or_path,\n",
        "        subfolder=\"text_encoder\",\n",
        "        revision=args.revision,\n",
        "    )\n",
        "    vae = AutoencoderKL.from_pretrained(\n",
        "        args.pretrained_model_name_or_path,\n",
        "        subfolder=\"vae\",\n",
        "        revision=args.revision,\n",
        "    )\n",
        "    unet = UNet2DConditionModel.from_pretrained(\n",
        "        args.pretrained_model_name_or_path,\n",
        "        subfolder=\"unet\",\n",
        "        revision=args.revision,\n",
        "        torch_dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    vae.requires_grad_(False)\n",
        "    if not args.train_text_encoder:\n",
        "        text_encoder.requires_grad_(False)\n",
        "\n",
        "    if is_xformers_available():\n",
        "        vae.enable_xformers_memory_efficient_attention()\n",
        "        unet.enable_xformers_memory_efficient_attention()\n",
        "    else:\n",
        "        logger.warning(\"xformers is not available. Make sure it is installed correctly\")\n",
        "\n",
        "    if args.gradient_checkpointing:\n",
        "        unet.enable_gradient_checkpointing()\n",
        "        if args.train_text_encoder:\n",
        "            text_encoder.gradient_checkpointing_enable()\n",
        "\n",
        "    if args.scale_lr:\n",
        "        args.learning_rate = (\n",
        "            args.learning_rate * args.gradient_accumulation_steps * args.train_batch_size * accelerator.num_processes\n",
        "        )\n",
        "\n",
        "    # Use 8-bit Adam for lower memory usage or to fine-tune the model in 16GB GPUs\n",
        "    if args.use_8bit_adam:\n",
        "        try:\n",
        "            import bitsandbytes as bnb\n",
        "        except ImportError:\n",
        "            raise ImportError(\n",
        "                \"To use 8-bit Adam, please install the bitsandbytes library: `pip install bitsandbytes`.\"\n",
        "            )\n",
        "\n",
        "        optimizer_class = bnb.optim.AdamW8bit\n",
        "    else:\n",
        "        optimizer_class = torch.optim.AdamW\n",
        "\n",
        "    params_to_optimize = (\n",
        "        itertools.chain(unet.parameters(), text_encoder.parameters()) if args.train_text_encoder else unet.parameters()\n",
        "    )\n",
        "    optimizer = optimizer_class(\n",
        "        params_to_optimize,\n",
        "        lr=args.learning_rate,\n",
        "        betas=(args.adam_beta1, args.adam_beta2),\n",
        "        weight_decay=args.adam_weight_decay,\n",
        "        eps=args.adam_epsilon,\n",
        "    )\n",
        "\n",
        "    noise_scheduler = DDPMScheduler.from_config(args.pretrained_model_name_or_path, subfolder=\"scheduler\")\n",
        "\n",
        "    train_dataset = DreamBoothDataset(\n",
        "        concepts_list=args.concepts_list,\n",
        "        tokenizer=tokenizer,\n",
        "        with_prior_preservation=args.with_prior_preservation,\n",
        "        size=args.resolution,\n",
        "        center_crop=args.center_crop,\n",
        "        num_class_images=args.num_class_images,\n",
        "        pad_tokens=args.pad_tokens,\n",
        "        hflip=args.hflip,\n",
        "        read_prompts_from_txts=args.read_prompts_from_txts,\n",
        "    )\n",
        "\n",
        "    def collate_fn(examples):\n",
        "        input_ids = [example[\"instance_prompt_ids\"] for example in examples]\n",
        "        pixel_values = [example[\"instance_images\"] for example in examples]\n",
        "\n",
        "        # Concat class and instance examples for prior preservation.\n",
        "        # We do this to avoid doing two forward passes.\n",
        "        if args.with_prior_preservation:\n",
        "            input_ids += [example[\"class_prompt_ids\"] for example in examples]\n",
        "            pixel_values += [example[\"class_images\"] for example in examples]\n",
        "\n",
        "        pixel_values = torch.stack(pixel_values)\n",
        "        pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
        "\n",
        "        input_ids = tokenizer.pad(\n",
        "            {\"input_ids\": input_ids},\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\",\n",
        "        ).input_ids\n",
        "\n",
        "        batch = {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"pixel_values\": pixel_values,\n",
        "        }\n",
        "        return batch\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=args.train_batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True\n",
        "    )\n",
        "\n",
        "    weight_dtype = torch.float32\n",
        "    if args.mixed_precision == \"fp16\":\n",
        "        weight_dtype = torch.float16\n",
        "    elif args.mixed_precision == \"bf16\":\n",
        "        weight_dtype = torch.bfloat16\n",
        "\n",
        "    # Move text_encode and vae to gpu.\n",
        "    # For mixed precision training we cast the text_encoder and vae weights to half-precision\n",
        "    # as these models are only used for inference, keeping weights in full precision is not required.\n",
        "    vae.to(accelerator.device, dtype=weight_dtype)\n",
        "    if not args.train_text_encoder:\n",
        "        text_encoder.to(accelerator.device, dtype=weight_dtype)\n",
        "\n",
        "    if not args.not_cache_latents:\n",
        "        latents_cache = []\n",
        "        text_encoder_cache = []\n",
        "        for batch in tqdm(train_dataloader, desc=\"Caching latents\"):\n",
        "            with torch.no_grad():\n",
        "                batch[\"pixel_values\"] = batch[\"pixel_values\"].to(accelerator.device, non_blocking=True, dtype=weight_dtype)\n",
        "                batch[\"input_ids\"] = batch[\"input_ids\"].to(accelerator.device, non_blocking=True)\n",
        "                latents_cache.append(vae.encode(batch[\"pixel_values\"]).latent_dist)\n",
        "                if args.train_text_encoder:\n",
        "                    text_encoder_cache.append(batch[\"input_ids\"])\n",
        "                else:\n",
        "                    text_encoder_cache.append(text_encoder(batch[\"input_ids\"])[0])\n",
        "        train_dataset = LatentsDataset(latents_cache, text_encoder_cache)\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x, shuffle=True)\n",
        "\n",
        "        del vae\n",
        "        if not args.train_text_encoder:\n",
        "            del text_encoder\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Scheduler and math around the number of training steps.\n",
        "    overrode_max_train_steps = False\n",
        "    num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps)\n",
        "    if args.max_train_steps is None:\n",
        "        args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\n",
        "        overrode_max_train_steps = True\n",
        "\n",
        "    lr_scheduler = get_scheduler(\n",
        "        args.lr_scheduler,\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=args.lr_warmup_steps * args.gradient_accumulation_steps,\n",
        "        num_training_steps=args.max_train_steps * args.gradient_accumulation_steps,\n",
        "    )\n",
        "\n",
        "    if args.train_text_encoder:\n",
        "        unet, text_encoder, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
        "            unet, text_encoder, optimizer, train_dataloader, lr_scheduler\n",
        "        )\n",
        "    else:\n",
        "        unet, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
        "            unet, optimizer, train_dataloader, lr_scheduler\n",
        "        )\n",
        "\n",
        "    # We need to recalculate our total training steps as the size of the training dataloader may have changed.\n",
        "    num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps)\n",
        "    if overrode_max_train_steps:\n",
        "        args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\n",
        "    # Afterwards we recalculate our number of training epochs\n",
        "    args.num_train_epochs = math.ceil(args.max_train_steps / num_update_steps_per_epoch)\n",
        "\n",
        "    # We need to initialize the trackers we use, and also store our configuration.\n",
        "    # The trackers initializes automatically on the main process.\n",
        "    if accelerator.is_main_process:\n",
        "        accelerator.init_trackers(\"dreambooth\")\n",
        "\n",
        "    # Train!\n",
        "    total_batch_size = args.train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps\n",
        "\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
        "    logger.info(f\"  Num batches each epoch = {len(train_dataloader)}\")\n",
        "    logger.info(f\"  Num Epochs = {args.num_train_epochs}\")\n",
        "    logger.info(f\"  Instantaneous batch size per device = {args.train_batch_size}\")\n",
        "    logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
        "    logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
        "    logger.info(f\"  Total optimization steps = {args.max_train_steps}\")\n",
        "\n",
        "    def save_weights(step):\n",
        "        # Create the pipeline using using the trained modules and save it.\n",
        "        if accelerator.is_main_process:\n",
        "            if args.train_text_encoder:\n",
        "                text_enc_model = accelerator.unwrap_model(text_encoder, keep_fp32_wrapper=True)\n",
        "            else:\n",
        "                text_enc_model = CLIPTextModel.from_pretrained(args.pretrained_model_name_or_path, subfolder=\"text_encoder\", revision=args.revision)\n",
        "            pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "                args.pretrained_model_name_or_path,\n",
        "                unet=accelerator.unwrap_model(unet, keep_fp32_wrapper=True),\n",
        "                text_encoder=text_enc_model,\n",
        "                vae=AutoencoderKL.from_pretrained(\n",
        "                    args.pretrained_vae_name_or_path or args.pretrained_model_name_or_path,\n",
        "                    subfolder=None if args.pretrained_vae_name_or_path else \"vae\",\n",
        "                    revision=None if args.pretrained_vae_name_or_path else args.revision,\n",
        "                ),\n",
        "                safety_checker=None,\n",
        "                torch_dtype=torch.float16,\n",
        "                revision=args.revision,\n",
        "            )\n",
        "            pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)\n",
        "            if is_xformers_available():\n",
        "                pipeline.enable_xformers_memory_efficient_attention()\n",
        "            save_dir = os.path.join(args.output_dir, f\"{step}\")\n",
        "            pipeline.save_pretrained(save_dir)\n",
        "            with open(os.path.join(save_dir, \"args.json\"), \"w\") as f:\n",
        "                json.dump(args.__dict__, f, indent=2)\n",
        "\n",
        "            if args.save_sample_prompt is not None:\n",
        "                pipeline = pipeline.to(accelerator.device)\n",
        "                g_cuda = torch.Generator(device=accelerator.device).manual_seed(args.seed)\n",
        "                pipeline.set_progress_bar_config(disable=True)\n",
        "                sample_dir = os.path.join(save_dir, \"samples\")\n",
        "                os.makedirs(sample_dir, exist_ok=True)\n",
        "                with torch.autocast(\"cuda\"), torch.inference_mode():\n",
        "                    for i in tqdm(range(args.n_save_sample), desc=\"Generating samples\"):\n",
        "                        images = pipeline(\n",
        "                            args.save_sample_prompt,\n",
        "                            negative_prompt=args.save_sample_negative_prompt,\n",
        "                            guidance_scale=args.save_guidance_scale,\n",
        "                            num_inference_steps=args.save_infer_steps,\n",
        "                            generator=g_cuda\n",
        "                        ).images\n",
        "                        images[0].save(os.path.join(sample_dir, f\"{i}.png\"))\n",
        "                del pipeline\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "            print(f\"[*] Weights saved at {save_dir}\")\n",
        "            global models_dir\n",
        "            models_dir=save_dir\n",
        "\n",
        "    # Only show the progress bar once on each machine.\n",
        "    progress_bar = tqdm(range(args.max_train_steps), disable=not accelerator.is_local_main_process)\n",
        "    progress_bar.set_description(\"Steps\")\n",
        "    global_step = 0\n",
        "    loss_avg = AverageMeter()\n",
        "    text_enc_context = nullcontext() if args.train_text_encoder else torch.no_grad()\n",
        "    for epoch in range(args.num_train_epochs):\n",
        "        unet.train()\n",
        "        if args.train_text_encoder:\n",
        "            text_encoder.train()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            with accelerator.accumulate(unet):\n",
        "                # Convert images to latent space\n",
        "                with torch.no_grad():\n",
        "                    if not args.not_cache_latents:\n",
        "                        latent_dist = batch[0][0]\n",
        "                    else:\n",
        "                        latent_dist = vae.encode(batch[\"pixel_values\"].to(dtype=weight_dtype)).latent_dist\n",
        "                    latents = latent_dist.sample() * 0.18215\n",
        "\n",
        "                # Sample noise that we'll add to the latents\n",
        "                noise = torch.randn_like(latents)\n",
        "                bsz = latents.shape[0]\n",
        "                # Sample a random timestep for each image\n",
        "                timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n",
        "                timesteps = timesteps.long()\n",
        "\n",
        "                # Add noise to the latents according to the noise magnitude at each timestep\n",
        "                # (this is the forward diffusion process)\n",
        "                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
        "\n",
        "                # Get the text embedding for conditioning\n",
        "                with text_enc_context:\n",
        "                    if not args.not_cache_latents:\n",
        "                        if args.train_text_encoder:\n",
        "                            encoder_hidden_states = text_encoder(batch[0][1])[0]\n",
        "                        else:\n",
        "                            encoder_hidden_states = batch[0][1]\n",
        "                    else:\n",
        "                        encoder_hidden_states = text_encoder(batch[\"input_ids\"])[0]\n",
        "\n",
        "                # Predict the noise residual\n",
        "                model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
        "\n",
        "                # Get the target for loss depending on the prediction type\n",
        "                if noise_scheduler.config.prediction_type == \"epsilon\":\n",
        "                    target = noise\n",
        "                elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
        "                    target = noise_scheduler.get_velocity(latents, noise, timesteps)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unknown prediction type {noise_scheduler.config.prediction_type}\")\n",
        "\n",
        "                if args.with_prior_preservation:\n",
        "                    # Chunk the noise and model_pred into two parts and compute the loss on each part separately.\n",
        "                    model_pred, model_pred_prior = torch.chunk(model_pred, 2, dim=0)\n",
        "                    target, target_prior = torch.chunk(target, 2, dim=0)\n",
        "\n",
        "                    # Compute instance loss\n",
        "                    loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n",
        "\n",
        "                    # Compute prior loss\n",
        "                    prior_loss = F.mse_loss(model_pred_prior.float(), target_prior.float(), reduction=\"mean\")\n",
        "\n",
        "                    # Add the prior loss to the instance loss.\n",
        "                    loss = loss + args.prior_loss_weight * prior_loss\n",
        "                else:\n",
        "                    loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n",
        "\n",
        "                accelerator.backward(loss)\n",
        "                # if accelerator.sync_gradients:\n",
        "                #     params_to_clip = (\n",
        "                #         itertools.chain(unet.parameters(), text_encoder.parameters())\n",
        "                #         if args.train_text_encoder\n",
        "                #         else unet.parameters()\n",
        "                #     )\n",
        "                #     accelerator.clip_grad_norm_(params_to_clip, args.max_grad_norm)\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                loss_avg.update(loss.detach_(), bsz)\n",
        "\n",
        "            if not global_step % args.log_interval:\n",
        "                logs = {\"loss\": loss_avg.avg.item(), \"lr\": lr_scheduler.get_last_lr()[0]}\n",
        "                progress_bar.set_postfix(**logs)\n",
        "                accelerator.log(logs, step=global_step)\n",
        "\n",
        "            if global_step > 0 and not global_step % args.save_interval and global_step >= args.save_min_steps:\n",
        "                save_weights(global_step)\n",
        "\n",
        "            progress_bar.update(1)\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step >= args.max_train_steps:\n",
        "                break\n",
        "\n",
        "        accelerator.wait_for_everyone()\n",
        "\n",
        "    save_weights(global_step)\n",
        "\n",
        "    accelerator.end_training()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_dir=''\n",
        "    args = parse_args('')\n",
        "    print(args)\n",
        "#=========超级参数都在这里设置是最方便的.\n",
        "\n",
        "\n",
        "    args.seed=1337 \n",
        "    args.resolution=512 \n",
        "    args.train_batch_size=1 \n",
        "    args.train_text_encoder=False\n",
        "    args.mixed_precision=\"fp16\"       # 这个两行必须开, 不然显存不够!\n",
        "    args.use_8bit_adam=True\n",
        "    args.gradient_accumulation_steps=1 \n",
        "    args.learning_rate=3e-6\n",
        "    args.lr_scheduler=\"constant\" \n",
        "    args.lr_warmup_steps = 0\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    args.sample_batch_size=4 \n",
        "    args.max_train_steps=800 \n",
        "    args.save_interval=10000 \n",
        "    args.concepts_list=\"concepts_list.json\"\n",
        "\n",
        "\n",
        "    with open(args.concepts_list, \"r\") as f:\n",
        "            a = json.load(f)\n",
        "\n",
        "    class_images_dir = Path(a[0][\"class_data_dir\"])\n",
        "    class_images_dir.mkdir(parents=True, exist_ok=True)\n",
        "    cur_class_images = len(list(class_images_dir.iterdir()))\n",
        "    args.num_class_images=8 \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    main(args)\n",
        "    print('训练完毕,模型在',models_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "29af6e22ca994f5ca3fd02ed9babcd18",
            "272c45848ad94f99872c1c6c198fd9d2",
            "3d814a46af2a4749a771e369b8163eb6",
            "5395576a9f6b4c60960468f6fb91edab",
            "0055493399da4f7198f110a2f2dfc0db",
            "c21c85c90ada4986b1191bb2a06c1033",
            "d4bd82a61e384e5c90c56b2432f2bc28",
            "20ec550829154f7584793f9837360e79",
            "d057bc34d8f94558b1a0406f179c764c",
            "9c87b38d40ad4c168b259b519d7dd07d",
            "a1495180f7c34eceb4da25eaabdb95e2",
            "ff79a279698a42b0a92d8965508e3ceb",
            "f04b6b376d294826b6a17b2199a0cd1c",
            "84bc58177d4141b1a91f3fd2c67fac1f",
            "943dc465516a4faea20eb9c7d6300df1",
            "01e3ad20b421438b952a522e32d0ee86",
            "aedcaa4032b645bcbc3f97345c345723",
            "e7c3b7bf321542b3b1f6029dcd9e0f9f",
            "f70ad8e46e994edd9b45c4ac694af22a",
            "ecb4c33f74204cc29558ad4ee086c146",
            "97a0c41b835842fc971276e7cb57b12a",
            "7ef228dabbbf47b48de1b55c0493c46d"
          ]
        },
        "id": "MGNMQpL1wpNL",
        "outputId": "0497e80f-4ccd-43d3-d206-b894356edf40"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "unet/diffusion_pytorch_model.safetensors not found\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Weights saved at stable_diffusion_weights/sd_v15_dr/800\n",
            "训练完毕,模型在 stable_diffusion_weights/sd_v15_dr/800\n",
            "Namespace(pretrained_model_name_or_path='runwayml/stable-diffusion-v1-5', pretrained_vae_name_or_path='stabilityai/sd-vae-ft-mse', revision='fp16', tokenizer_name=None, instance_data_dir=None, class_data_dir=None, instance_prompt=None, class_prompt=None, save_sample_prompt=None, save_sample_negative_prompt=None, n_save_sample=4, save_guidance_scale=7.5, save_infer_steps=20, pad_tokens=False, with_prior_preservation=True, prior_loss_weight=1.0, num_class_images=8, output_dir='stable_diffusion_weights/sd_v15_dr', seed=1337, resolution=512, center_crop=False, train_text_encoder=False, train_batch_size=1, sample_batch_size=4, num_train_epochs=1, max_train_steps=800, gradient_accumulation_steps=1, gradient_checkpointing=False, learning_rate=1e-06, scale_lr=False, lr_scheduler='constant', lr_warmup_steps=0, use_8bit_adam=True, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, push_to_hub=False, hub_token=None, hub_model_id=None, logging_dir='logs', log_interval=10, save_interval=10000, save_min_steps=0, mixed_precision='fp16', not_cache_latents=False, hflip=False, local_rank=-1, concepts_list='concepts_list.json', read_prompts_from_txts=False)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Caching latents:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29af6e22ca994f5ca3fd02ed9babcd18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/800 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff79a279698a42b0a92d8965508e3ceb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 892>\u001b[0m:\u001b[94m932\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mmain\u001b[0m:\u001b[94m866\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m134\u001b[0m in \u001b[92mstep\u001b[0m                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mxm.optimizer_step(\u001b[96mself\u001b[0m.optimizer, optimizer_args=optimizer_args)           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.scaler \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mscale_before = \u001b[96mself\u001b[0m.scaler.get_scale()                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m134 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.scaler.step(\u001b[96mself\u001b[0m.optimizer, closure)                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.scaler.update()                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mscale_after = \u001b[96mself\u001b[0m.scaler.get_scale()                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# If we reduced the loss scale, it means the optimizer step was skipped \u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/\u001b[0m\u001b[1;33mgrad_scaler.py\u001b[0m:\u001b[94m370\u001b[0m in \u001b[92mstep\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mlen\u001b[0m(optimizer_state[\u001b[33m\"\u001b[0m\u001b[33mfound_inf_per_device\u001b[0m\u001b[33m\"\u001b[0m]) > \u001b[94m0\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mNo inf checks were rec\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m369 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m370 \u001b[2m│   │   \u001b[0mretval = \u001b[96mself\u001b[0m._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m371 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m│   │   \u001b[0moptimizer_state[\u001b[33m\"\u001b[0m\u001b[33mstage\u001b[0m\u001b[33m\"\u001b[0m] = OptState.STEPPED                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m373 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/\u001b[0m\u001b[1;33mgrad_scaler.py\u001b[0m:\u001b[94m290\u001b[0m in \u001b[92m_maybe_opt_step\u001b[0m     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m287 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_maybe_opt_step\u001b[0m(\u001b[96mself\u001b[0m, optimizer, optimizer_state, *args, **kwargs):                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m288 \u001b[0m\u001b[2m│   │   \u001b[0mretval = \u001b[94mNone\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96msum\u001b[0m(v.item() \u001b[94mfor\u001b[0m v \u001b[95min\u001b[0m optimizer_state[\u001b[33m\"\u001b[0m\u001b[33mfound_inf_per_device\u001b[0m\u001b[33m\"\u001b[0m].values()):    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m290 \u001b[2m│   │   │   \u001b[0mretval = optimizer.step(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m291 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m retval                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m292 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mstep\u001b[0m(\u001b[96mself\u001b[0m, optimizer, *args, **kwargs):                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/optim/\u001b[0m\u001b[1;33mlr_scheduler.py\u001b[0m:\u001b[94m69\u001b[0m in \u001b[92mwrapper\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  66 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minstance = instance_ref()                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  67 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minstance._step_count += \u001b[94m1\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  68 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mwrapped = func.\u001b[92m__get__\u001b[0m(instance, \u001b[96mcls\u001b[0m)                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  69 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m wrapped(*args, **kwargs)                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  70 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  71 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Note that the returned function here is no longer a bound method,\u001b[0m           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  72 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# so attributes like `__func__` and `__self__` no longer exist.\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m280\u001b[0m in \u001b[92mwrapper\u001b[0m                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mfunc\u001b[33m}\u001b[0m\u001b[33m must return None or a tuple of (\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m278 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │      \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbut got \u001b[0m\u001b[33m{\u001b[0mresult\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m)                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m279 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m280 \u001b[2m│   │   │   │   \u001b[0mout = func(*args, **kwargs)                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._optimizer_step_code()                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# call optimizer step post hooks\u001b[0m                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m263\u001b[0m in \u001b[92mstep\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mcontinue\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mstate = \u001b[96mself\u001b[0m.state[p]                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(state) == \u001b[94m0\u001b[0m:                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m263 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.init_state(group, p, gindex, pindex)                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.update_step(group, p, gindex, pindex)                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m266 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m393\u001b[0m in \u001b[92minit_state\u001b[0m        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m390 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mp.device                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m391 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m392 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m393 \u001b[2m│   │   │   \u001b[0mstate[\u001b[33m\"\u001b[0m\u001b[33mstate1\u001b[0m\u001b[33m\"\u001b[0m] = torch.zeros_like(                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m394 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mp,                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m395 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmemory_format=torch.preserve_format,                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m396 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdtype=torch.uint8,                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m14.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m14.75\u001b[0m GiB total capacity; \u001b[1;36m13.21\u001b[0m GiB \n",
              "already allocated; \u001b[1;36m14.81\u001b[0m MiB free; \u001b[1;36m13.38\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \n",
              "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
              "PYTORCH_CUDA_ALLOC_CONF\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 892&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">932</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">main</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">866</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">134</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131 │   │   │   │   </span>xm.optimizer_step(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer, optimizer_args=optimizer_args)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   │   │   │   </span>scale_before = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.get_scale()                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>134 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.step(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer, closure)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.update()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 │   │   │   │   </span>scale_after = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.get_scale()                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   │   │   │   # If we reduced the loss scale, it means the optimizer step was skipped </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">grad_scaler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">370</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">367 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">368 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(optimizer_state[<span style=\"color: #808000; text-decoration-color: #808000\">\"found_inf_per_device\"</span>]) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"No inf checks were rec</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">369 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>370 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>retval = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">371 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">372 │   │   </span>optimizer_state[<span style=\"color: #808000; text-decoration-color: #808000\">\"stage\"</span>] = OptState.STEPPED                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">373 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">grad_scaler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">290</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_maybe_opt_step</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">287 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_maybe_opt_step</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, optimizer, optimizer_state, *args, **kwargs):                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">288 │   │   </span>retval = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">289 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">sum</span>(v.item() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> optimizer_state[<span style=\"color: #808000; text-decoration-color: #808000\">\"found_inf_per_device\"</span>].values()):    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>290 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>retval = optimizer.step(*args, **kwargs)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">291 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> retval                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">292 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">293 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, optimizer, *args, **kwargs):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lr_scheduler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">69</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  66 │   │   │   │   </span>instance = instance_ref()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  67 │   │   │   │   </span>instance._step_count += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  68 │   │   │   │   </span>wrapped = func.<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__get__</span>(instance, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  69 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapped(*args, **kwargs)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  70 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  71 │   │   │   # Note that the returned function here is no longer a bound method,</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  72 │   │   │   # so attributes like `__func__` and `__self__` no longer exist.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">280</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 │   │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>func<span style=\"color: #808000; text-decoration-color: #808000\">} must return None or a tuple of (</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">278 │   │   │   │   │   │   │   │   │   │   │      </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"but got {</span>result<span style=\"color: #808000; text-decoration-color: #808000\">}.\"</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">279 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>280 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>out = func(*args, **kwargs)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._optimizer_step_code()                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">282 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">283 │   │   │   │   # call optimizer step post hooks</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">263</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">continue</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">261 │   │   │   │   </span>state = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state[p]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">262 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(state) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>263 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.init_state(group, p, gindex, pindex)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">264 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.update_step(group, p, gindex, pindex)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">393</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">init_state</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">390 │   │   │   │   │   </span>p.device                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">391 │   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">392 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>393 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>state[<span style=\"color: #808000; text-decoration-color: #808000\">\"state1\"</span>] = torch.zeros_like(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">394 │   │   │   │   </span>p,                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">395 │   │   │   │   </span>memory_format=torch.preserve_format,                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">396 │   │   │   │   </span>dtype=torch.uint8,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.75</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.21</span> GiB \n",
              "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.81</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.38</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \n",
              "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
              "PYTORCH_CUDA_ALLOC_CONF\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "\n",
        "model_path = models_dir            # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "g_cuda = None\n",
        "\n",
        "\n",
        "prompt=\"photo of zhangyi_person wearing a black hat\"\n",
        "prompt=\"photo of zhangyi_person\"\n",
        "negative_prompt = \"\" \n",
        "num_samples = 4 \n",
        "guidance_scale = 7.5 \n",
        "num_inference_steps = 50 \n",
        "height = 512 \n",
        "width = 512 \n",
        "save_dir='/save666'\n",
        "import os\n",
        "sample_dir = \"samples\"\n",
        "\n",
        "os.makedirs(sample_dir, exist_ok=True)\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "i=0\n",
        "for img in images:\n",
        "\n",
        "    img.save(os.path.join(sample_dir, f\"{i}.png\"))\n",
        "    \n",
        "    print('保存在',os.path.join(sample_dir, f\"{i}.png\"))\n",
        "    i+=1\n",
        "from IPython.display import display\n",
        "for img in images:\n",
        "    display(img)\n"
      ],
      "metadata": {
        "id": "TudY-gIwStu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "7068e45a-ccf3-4d82-a78a-c27b4e663bff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 8>\u001b[0m:\u001b[94m8\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/\u001b[0m\u001b[1;33mpipeline_utils.py\u001b[0m:\u001b[94m769\u001b[0m in             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 766 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 1. Download the checkpoints and configs\u001b[0m                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 767 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# use snapshot download here to get it working from from_pretrained\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 768 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m os.path.isdir(pretrained_model_name_or_path):                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 769 \u001b[2m│   │   │   \u001b[0mcached_folder = \u001b[96mcls\u001b[0m.download(                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 770 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name_or_path,                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 771 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcache_dir=cache_dir,                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 772 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mresume_download=resume_download,                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/\u001b[0m\u001b[1;33mpipeline_utils.py\u001b[0m:\u001b[94m1098\u001b[0m in \u001b[92mdownload\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1095 \u001b[0m\u001b[2m│   │   \u001b[0mignore_patterns = \u001b[94mNone\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1096 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1097 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m local_files_only:                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1098 \u001b[2m│   │   │   \u001b[0mconfig_file = hf_hub_download(                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1099 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name,                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1100 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mcls\u001b[0m.config_name,                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1101 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcache_dir=cache_dir,                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m112\u001b[0m in \u001b[92m_inner_fn\u001b[0m    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs.items(),  \u001b[2m# Kwargs values\u001b[0m                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m arg_name \u001b[95min\u001b[0m [\u001b[33m\"\u001b[0m\u001b[33mrepo_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mfrom_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mto_id\u001b[0m\u001b[33m\"\u001b[0m]:                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m112 \u001b[2m│   │   │   │   \u001b[0mvalidate_repo_id(arg_value)                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m arg_name == \u001b[33m\"\u001b[0m\u001b[33mtoken\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mand\u001b[0m arg_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhas_token = \u001b[94mTrue\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m166\u001b[0m in              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mvalidate_repo_id\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m REPO_ID_REGEX.match(repo_id):                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m166 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m HFValidationError(                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mRepo id must use alphanumeric chars or \u001b[0m\u001b[33m'\u001b[0m\u001b[33m-\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m\u001b[33m_\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m\u001b[33m--\u001b[0m\u001b[33m'\u001b[0m\u001b[33m and \u001b[0m\u001b[33m'\u001b[0m\u001b[33m..\u001b[0m\u001b[33m'\u001b[0m\u001b[33m are\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m forbidden, \u001b[0m\u001b[33m'\u001b[0m\u001b[33m-\u001b[0m\u001b[33m'\u001b[0m\u001b[33m and \u001b[0m\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m'\u001b[0m\u001b[33m cannot start or end the name, max length is 96:\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mrepo_id\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mHFValidationError: \u001b[0mRepo id must use alphanumeric chars or \u001b[32m'-'\u001b[0m, \u001b[32m'_'\u001b[0m, \u001b[32m'.'\u001b[0m, \u001b[32m'--'\u001b[0m and \u001b[32m'..'\u001b[0m are forbidden, \u001b[32m'-'\u001b[0m and \u001b[32m'.'\u001b[0m \n",
              "cannot start or end the name, max length is \u001b[1;36m96\u001b[0m: \u001b[32m''\u001b[0m.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 8&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pipeline_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">769</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 766 │   │   # 1. Download the checkpoints and configs</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 767 │   │   # use snapshot download here to get it working from from_pretrained</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 768 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> os.path.isdir(pretrained_model_name_or_path):                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 769 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>cached_folder = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.download(                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 770 │   │   │   │   </span>pretrained_model_name_or_path,                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 771 │   │   │   │   </span>cache_dir=cache_dir,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 772 │   │   │   │   </span>resume_download=resume_download,                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pipeline_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1098</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">download</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1095 │   │   </span>ignore_patterns = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1096 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1097 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> local_files_only:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1098 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>config_file = hf_hub_download(                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1099 │   │   │   │   </span>pretrained_model_name,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1100 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.config_name,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1101 │   │   │   │   </span>cache_dir=cache_dir,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">112</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109 │   │   │   </span>kwargs.items(),  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Kwargs values</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 │   │   </span>):                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> arg_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> [<span style=\"color: #808000; text-decoration-color: #808000\">\"repo_id\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"from_id\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"to_id\"</span>]:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>112 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>validate_repo_id(arg_value)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> arg_name == <span style=\"color: #808000; text-decoration-color: #808000\">\"token\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> arg_value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   │   │   │   </span>has_token = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">166</span> in              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">validate_repo_id</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> REPO_ID_REGEX.match(repo_id):                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>166 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> HFValidationError(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are\"</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" forbidden, '-' and '.' cannot start or end the name, max length is 96:\"</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" '{</span>repo_id<span style=\"color: #808000; text-decoration-color: #808000\">}'.\"</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">HFValidationError: </span>Repo id must use alphanumeric chars or <span style=\"color: #008000; text-decoration-color: #008000\">'-'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'_'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'--'</span> and <span style=\"color: #008000; text-decoration-color: #008000\">'..'</span> are forbidden, <span style=\"color: #008000; text-decoration-color: #008000\">'-'</span> and <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span> \n",
              "cannot start or end the name, max length is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm person_face/*"
      ],
      "metadata": {
        "id": "zd2hl6nxU1Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!fuser -v /dev/nvidia*  #清空显存.\n",
        "!kill 15821   \n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "DtFcGPfhWGeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install transformers==4.0"
      ],
      "metadata": {
        "id": "bsP479o0NH0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu5ojd-1K3f_",
        "outputId": "cf414b27-7dc5-4a88-cdc9-f2093bd903c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-15 06:50:11.754515: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "usage: accelerate <command> [<args>]\n",
            "\n",
            "positional arguments:\n",
            "  {config,env,launch,tpu-config,test}\n",
            "    accelerate\n",
            "    command\n",
            "    helpers\n",
            "\n",
            "options:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n"
          ]
        }
      ]
    }
  ]
}