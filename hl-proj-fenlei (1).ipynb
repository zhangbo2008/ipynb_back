{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/zhangbo2008/hl_detec","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-29T06:01:01.038410Z","iopub.execute_input":"2023-06-29T06:01:01.038762Z","iopub.status.idle":"2023-06-29T06:01:06.454127Z","shell.execute_reply.started":"2023-06-29T06:01:01.038733Z","shell.execute_reply":"2023-06-29T06:01:06.452143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd hl_detec","metadata":{"execution":{"iopub.status.busy":"2023-06-29T06:01:06.457010Z","iopub.execute_input":"2023-06-29T06:01:06.457427Z","iopub.status.idle":"2023-06-29T06:01:06.478009Z","shell.execute_reply.started":"2023-06-29T06:01:06.457385Z","shell.execute_reply":"2023-06-29T06:01:06.472913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm tvsum50_ver_1_1.tgz -rf  # 先删除旧文件就非常robost\n!wget https://huggingface.co/datasets/zhangbo2008/tvsum/resolve/main/tvsum50_ver_1_1.tgz","metadata":{"execution":{"iopub.status.busy":"2023-06-29T06:01:06.479638Z","iopub.execute_input":"2023-06-29T06:01:06.480401Z","iopub.status.idle":"2023-06-29T06:01:41.382886Z","shell.execute_reply.started":"2023-06-29T06:01:06.480366Z","shell.execute_reply":"2023-06-29T06:01:41.381678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -xvzf tvsum50_ver_1_1.tgz","metadata":{"execution":{"iopub.status.busy":"2023-06-29T06:01:41.386174Z","iopub.execute_input":"2023-06-29T06:01:41.387539Z","iopub.status.idle":"2023-06-29T06:01:47.281856Z","shell.execute_reply.started":"2023-06-29T06:01:41.386827Z","shell.execute_reply":"2023-06-29T06:01:47.280654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ./ydata-tvsum50-v1_1/ydata-tvsum50-video.zip","metadata":{"execution":{"iopub.status.busy":"2023-06-29T06:01:47.283659Z","iopub.execute_input":"2023-06-29T06:01:47.284048Z","iopub.status.idle":"2023-06-29T06:01:53.297425Z","shell.execute_reply.started":"2023-06-29T06:01:47.284010Z","shell.execute_reply":"2023-06-29T06:01:53.296227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install av\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-06-29T06:01:53.299036Z","iopub.execute_input":"2023-06-29T06:01:53.299973Z","iopub.status.idle":"2023-06-29T06:02:23.096173Z","shell.execute_reply.started":"2023-06-29T06:01:53.299933Z","shell.execute_reply":"2023-06-29T06:02:23.094961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm model2.pt     #从hf服务器下载模型文件.\n!wget https://huggingface.co/datasets/zhangbo2008/saving_tmp/resolve/main/model2.pt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# =======vid path :  /mnt/e/ydata-tvsum50-v1_1/video\n#=======后续版本持续调优参数.\n#  使用数值来模拟结果,收敛很慢. 改成多酚类试试. 变成多酚类.\n\nimport av\nimport torch\n\n#=======================超级参数都放在这里!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\nmodel_name='model2.pt'\n\n\n\n\n\n\n\n\nimport numpy as np\n\nfrom fenlei.transformers import AutoProcessor, AutoModel\nfrom huggingface_hub import hf_hub_download\ndevice = torch.device(\"cuda\" if torch.cuda.is_available()else \"cpu\") \nnp.random.seed(0)\nprocessor = AutoProcessor.from_pretrained(\"microsoft/xclip-base-patch32\")\nmodel = AutoModel.from_pretrained(\"microsoft/xclip-base-patch32\")\nmodel=torch.load(model_name)\n\ndef read_video_pyav(container, indices):\n    '''\n    Decode the video with PyAV decoder.\n    Args:\n        container (`av.container.input.InputContainer`): PyAV container.\n        indices (`List[int]`): List of frame indices to decode.\n    Returns:\n        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n    '''\n    frames = []\n    container.seek(0)\n    start_index = indices[0]\n    end_index = indices[-1]\n    for i, frame in enumerate(container.decode(video=0)):\n        if i > end_index:\n            break\n        if i >= start_index and i in indices:\n            frames.append(frame)\n    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n\n#=============做数据集\n\nimport numpy as np\n\ndatap='video'\nimport pandas as pd\nanno='ydata-tvsum50-anno.tsv'\ninfo='ydata-tvsum50-info.tsv'\n\nimport os # ========做本地电脑和服务器的适配.\nprint(os.uname().nodename)\nif os.uname().nodename=='PC-202003302200':\n    #============做本地适配\n    anno='/mnt/e/ydata-tvsum50-v1_1/ydata-tvsum50-anno.tsv'\n    info='/mnt/e/ydata-tvsum50-v1_1/ydata-tvsum50-info.tsv'\n\n    datap='/mnt/e/ydata-tvsum50-v1_1/video'\nprint()\n\nall_video=[]\nall_label=[]\nchulitvsum=1\nidex=0\ninfo = pd.read_csv(info, sep=\"\\t\")\nif chulitvsum:\n print()\n\n\n    \n\n\nprint()\n\n#================ferz\n\n\nprint('开始训练')\nepoch=10\nfrom torch import nn, optim\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\nimport torch.optim as optim\n\nfor p in model.parameters():\n    p.requires_grad=False\n\nfor p in model.base_model.last.parameters():\n    p.requires_grad=True\nfor p in model.base_model.last2.parameters():\n    p.requires_grad=True\nprint()\n\n\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)\nmodel=model.to(device)\nfor i in range(epoch):\n\n#   for out3, out4 in zip(all_video,all_label):\n#     #  getdata\n  for idex in range(len(info)):\n    # idex=0\n    \n    time=[]\n    for i in range(len(info)):\n        tmp=info.iloc[i].length\n        time.append(int(tmp.split(':')[0])*60+int(tmp.split(':')[1]))\n\n    import glob\n    files=glob.glob(datap+'/*.mp4')\n\n\n    print(1)\n    dummy=datap+'/'+info.iloc[idex].video_id+'.mp4'  #取第一个做dummytest\n    dummy_shipinchang=time[idex] # diyige shipinchnag .\n    dummy_fps=1\n    import av\n    container = av.open(dummy)\n    container.streams.video[0].average_rate\n    time=container.streams.video[0].duration/10000\n    time=dummy_shipinchang\n    frames=container.streams.video[0].frames\n    fps=frames/time\n    print(1)\n\n    indices=[]\n    jiange=int(fps*2/8) # 每8个一组\n    for i in range(0,frames,jiange):\n        indices.append(i)\n\n    print(1) \n    t=[]\n    out=[]\n    for i in indices:\n\n        t.append(i)\n        if len(t)==8:\n                out.append(t)\n                t=[]\n    # if t:\n    #     out.append(t)\n    hout=out\n    print(2)\n    #-------每一组的平分.\n\n\n    # import numpy as np \n    # df = pd.read_csv(anno, sep=\"\\t\")  # 用pd速度快.\n    # df.iloc[0]\n    with open(anno) as f:\n        tmp=f.readlines()\n\n    tmp=[''.join(i.strip().split('\\t')[2:]).split(',') for i in tmp]\n    tmp2=[]\n    for i in range(len(tmp)):\n        tmp2.append([int(i) for i in tmp[i]])\n    tmp=tmp2 \n    all=[]\n#     for i in tmp:\n#         print(len(i))\n    for i in range(0,len(tmp),20):\n        \n        t=(np.array(tmp[i])+np.array(tmp[i+1])+np.array(tmp[i+2]))/3\n#         print()\n        all.append(t)\n    #========改变out平分.\n#     print()\n    all2=[]\n    frames2 = []\n    container.seek(0)\n    out=sum(out,[])\n    for i, frame in enumerate(container.decode(video=0)):\n        if i in out:\n            frames2.append(frame)\n#     print()\n    t=[]\n    out2=[]\n    for i in frames2:\n\n        t.append(i)\n        if len(t)==8:\n                out2.append(t)\n                t=[]\n    # if t:\n    #     out2.append(t)\n#     print(2)\n    out3=[]\n    for i in out2:\n\n        out3.append(np.stack([x.to_ndarray(format=\"rgb24\") for x in i]))\n    print(len(out3),'numberofkeyframe')\n    print()\n    fenshu=all[idex]\n    hout\n    out4=[]\n    for i in hout:\n        ttt=fenshu[i]\n        t=np.mean(ttt) #===============guiyihua\n        out4.append(t)\n\n\n    #-=----to int\n    out4=[int(i+0.5)-1 for i in out4]\n    print()\n    # all_video.append(out3)\n    # all_label.append(out4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n    bs=200\n    model.train()\n    import gc\n    gc.collect()\n    for i in range(0,len(out3),bs):\n        \n        tmp1=out3[i:i+bs]\n        tmp2=out4[i:i+bs]\n\n\n        for jj in range(5):\n            optimizer.zero_grad()\n            \n            video=tmp1\n\n            tmp2=torch.tensor(tmp2).to(device)\n\n            # Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor.\n            inputs = processor(\n                text=[\"\"],\n                videos=list(video),\n                return_tensors=\"pt\",\n                padding=True,\n            )\n            for i in inputs:\n                inputs[i]=inputs[i].to(device)\n\n\n\n\n\n            #=============收集所有的数据和标签.\n\n        #     print(inputs,66666666666666666)\n\n\n\n            # forward pass\n            \n            outputs,loss = model(**inputs,return_loss=True,label=tmp2,fenlei=1)\n\n\n \n            loss.backward()\n            print(loss.item(),'当前损失')\n            print(optimizer.param_groups[0][\"lr\"],'当前学习率')\n            print('当前学习的视频索引',idex)\n            optimizer.step()\n#============测试一下加这个.#一般在del 变量后面使用.\n            # torch.cuda.empty_cache()\n\n\n\nprint('over_train')\n\n\ntorch.save(model, model_name)\nprint('存完.')\n# logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n# probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n# print(probs)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-29T09:13:56.614352Z","iopub.execute_input":"2023-06-29T09:13:56.614820Z","iopub.status.idle":"2023-06-29T09:46:28.202887Z","shell.execute_reply.started":"2023-06-29T09:13:56.614784Z","shell.execute_reply":"2023-06-29T09:46:28.201355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!fuser -v /dev/nvidia*  #清空显存.\n!kill 158211111111    # 这里面输入号. 号会运行这块之后出现.\n!nvidia-smi\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-06-29T06:40:51.052821Z","iopub.execute_input":"2023-06-29T06:40:51.053188Z","iopub.status.idle":"2023-06-29T06:40:54.415294Z","shell.execute_reply.started":"2023-06-29T06:40:51.053159Z","shell.execute_reply":"2023-06-29T06:40:54.414026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token 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 --add-to-git-credential","metadata":{"execution":{"iopub.status.busy":"2023-06-29T06:40:54.417424Z","iopub.execute_input":"2023-06-29T06:40:54.417821Z","iopub.status.idle":"2023-06-29T06:40:56.506496Z","shell.execute_reply.started":"2023-06-29T06:40:54.417782Z","shell.execute_reply":"2023-06-29T06:40:56.505229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi\napi = HfApi()\nupfile=model_name\napi.upload_file(\n    path_or_fileobj=upfile,\n    path_in_repo=upfile,\n    repo_id=\"zhangbo2008/saving_tmp\",\n    repo_type=\"dataset\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-29T09:07:31.777835Z","iopub.execute_input":"2023-06-29T09:07:31.778452Z","iopub.status.idle":"2023-06-29T09:08:37.084339Z","shell.execute_reply.started":"2023-06-29T09:07:31.778411Z","shell.execute_reply":"2023-06-29T09:08:37.083213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time         \nimport os # ========做本地电脑和服务器的适配.\nprint(os.uname().nodename)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-29T06:42:03.386956Z","iopub.execute_input":"2023-06-29T06:42:03.387333Z","iopub.status.idle":"2023-06-29T06:42:03.396054Z","shell.execute_reply.started":"2023-06-29T06:42:03.387285Z","shell.execute_reply":"2023-06-29T06:42:03.395031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://huggingface.co/datasets/zhangbo2008/saving_tmp/blob/main/model2.pt","metadata":{"execution":{"iopub.status.busy":"2023-06-29T09:09:18.135157Z","iopub.execute_input":"2023-06-29T09:09:18.136242Z","iopub.status.idle":"2023-06-29T09:09:19.890082Z","shell.execute_reply.started":"2023-06-29T09:09:18.136192Z","shell.execute_reply":"2023-06-29T09:09:19.888609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-29T09:11:22.008668Z","iopub.execute_input":"2023-06-29T09:11:22.009133Z","iopub.status.idle":"2023-06-29T09:12:01.938065Z","shell.execute_reply.started":"2023-06-29T09:11:22.009097Z","shell.execute_reply":"2023-06-29T09:12:01.936853Z"},"trusted":true},"execution_count":null,"outputs":[]}]}