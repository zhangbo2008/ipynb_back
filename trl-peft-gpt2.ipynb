{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 微调GPT2生成正面评论\n\n\n> 将BERT情感分类器作为奖励模型(RM, reward model)来优化GPT2生成正面的额IMDB电影评论。\n\n典型的RLHF微调模式：\n- SFT：GPT2模型，这里没有做进一步的有监督微调；\n- RM：使用BERT情感分类模型作为奖励模型\n- RL：使用PPO进行强化学习训练，引导模型生成\n\n鼎鼎大名的ChatGPT的训练三步法，如下如所示。\n![](https://pic3.zhimg.com/80/v2-85fc3194aa6e8c7202048a9143da998a_1440w.webp)","metadata":{"_uuid":"08103717-c568-49b9-afbe-12db76b14821","_cell_guid":"dc654db9-74a6-4e30-acb7-16da490829ed","trusted":true}},{"cell_type":"markdown","source":"<div style=\"text-align: center\">\n<img src='https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/gpt2_bert_training.png' width='600'>\n<p style=\"text-align: center;\"> <b>Figure:</b> 微调GPT2的实验流程. </p>\n</div>","metadata":{"_uuid":"abeaba39-5908-4b8c-9a6a-5c6e97694f45","_cell_guid":"899ffe66-b48e-4abb-82a2-5a25cf846ad7","trusted":true}},{"cell_type":"markdown","source":">本文微调一个GPT2（相比ChatGPT是非常小了），来生成正面的电影评论。给模型输入一个电影评论，然后生成一个正面的较长的评论。使用BERT分类器来评价生成评论的正面程度，强化学习算法是ChatGPT同款PPO（CloseAI自己提出来的）。","metadata":{}},{"cell_type":"markdown","source":"## 基本设置","metadata":{"_uuid":"a9c071d7-a722-4e65-a817-2570f46bcc53","_cell_guid":"a19ec510-cf99-40a3-a492-64ab7a15da32","trusted":true}},{"cell_type":"markdown","source":"### 安装和加载依赖包","metadata":{"_uuid":"56dd4f75-1cfc-4d08-b7e8-5abd6936d21f","_cell_guid":"eeaf00a6-124c-4688-aafd-4f72cb2857a9","trusted":true}},{"cell_type":"code","source":"# %load_ext autoreload\n# %autoreload 2\n!pip install git+https://github.com/huggingface/transformers.git -U\n!pip install -U accelerate\n!pip install git+https://github.com/huggingface/peft.git -U\n%pip install trl wandb bitsandbytes loralib sentencepiece appdirs","metadata":{"_uuid":"02fd7678-aed1-42ac-b970-be1cc1afe49d","_cell_guid":"48890c82-c288-4a76-ae43-f26b4a4ea997","collapsed":false,"jupyter":{"outputs_hidden":false},"scrolled":true,"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-04-20T14:57:40.447896Z","iopub.execute_input":"2023-04-20T14:57:40.449175Z","iopub.status.idle":"2023-04-20T14:59:11.712265Z","shell.execute_reply.started":"2023-04-20T14:57:40.449117Z","shell.execute_reply":"2023-04-20T14:59:11.710791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:59:11.715996Z","iopub.execute_input":"2023-04-20T14:59:11.716319Z","iopub.status.idle":"2023-04-20T14:59:22.466716Z","shell.execute_reply.started":"2023-04-20T14:59:11.716285Z","shell.execute_reply":"2023-04-20T14:59:22.465532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nimport pandas as pd\ntqdm.pandas()\nfrom datasets import load_dataset\n\n# 使用lora进行微调，速度更快，效果和直接微调原模型效果接近（通过实验验证）。\nfrom peft import LoraConfig, PeftConfig, PeftModel, get_peft_model, prepare_model_for_int8_training\n\n# trl包，是transformer reinforcement learning的首字母缩写，提供了非常方便的transformer模型的RLHF训练API\n# 感谢开源！有兴趣的可以去github上的\nfrom trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\nfrom trl.core import LengthSampler","metadata":{"_uuid":"388ac9cb-e5bb-4c85-a351-803f78ce7149","_cell_guid":"a0a338ca-4fda-4b08-a930-0e537506f3ca","collapsed":false,"jupyter":{"outputs_hidden":false},"scrolled":true,"execution":{"iopub.status.busy":"2023-04-20T14:59:22.468292Z","iopub.execute_input":"2023-04-20T14:59:22.468665Z","iopub.status.idle":"2023-04-20T14:59:22.956145Z","shell.execute_reply.started":"2023-04-20T14:59:22.468629Z","shell.execute_reply":"2023-04-20T14:59:22.955028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 配置","metadata":{"_uuid":"ca8e3301-66b8-48f8-b300-fddf7614a884","_cell_guid":"323e5762-d8ad-490f-9536-99f95ec5903a","trusted":true}},{"cell_type":"code","source":"config = PPOConfig(\n    model_name=\"lvwerra/gpt2-imdb\", # 这个是Huggingface上要训练的gpt2-imdb的名称，在transformer中可以用from_pretrained直接下载和缓存\n    learning_rate=1.41e-5, # 学习率\n#     log_with=\"wandb\", # 使用wandb监视训练过程，也可以使用tensorboard\n#     log_with=\"tensorboard\", # 使用wandb监视训练过程，也可以使用tensorboard\n#     accelerator_kwargs={\"logging_dir\": \"./tb_logger\"}\n)\n\nsent_kwargs = {\n    \"return_all_scores\": True, # 文本生成的参数，这里设置为True，表示生成文本时返回得分\n    \"function_to_apply\": \"none\", \n    \"batch_size\": 16 # 批大小，不解释了。玩深度学习这个读懂。GPU显存越大，这个可以设的越大。\n}","metadata":{"_uuid":"a00d2ec4-458a-482d-9fc8-2a400edfe475","_cell_guid":"7f50b804-7d9e-4fbf-8673-f57dece1c8d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T14:59:22.958014Z","iopub.execute_input":"2023-04-20T14:59:22.9593Z","iopub.status.idle":"2023-04-20T14:59:22.966339Z","shell.execute_reply.started":"2023-04-20T14:59:22.959257Z","shell.execute_reply":"2023-04-20T14:59:22.964896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```python\n# 使用transformers的AutoModelForXXX来加载模型\npretrained_model = AutoModelForCausalLM.from_pretrained(config.model_name, load_in_8bit=True, device_map=\"auto\")\n\n# 设置目标模块名称\ntarget_modules = None\nif \"gpt-neox\" in script_args.model_name:\n    target_modules = [\"query_key_value\", \"xxx\"]  # workaround to use 8bit training on this model\n\n# 设置lora配置参数\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=target_modules,  # handled automatically by peft\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\n# 设置8bit训练\npretrained_model = prepare_model_for_int8_training(pretrained_model, output_embedding_layer_name=\"embed_out\")\n\n# 设置lora模型\npretrained_model = get_peft_model(pretrained_model, lora_config)\n\n# 将lora模型加载入trl模型，加上value head\nmodel = AutoModelForCausalLMWithValueHead.from_pretrained(pretrained_model)\n\n# 做必要的设置，梯度检查。\nmodel.gradient_checkpointing_disable = model.pretrained_model.gradient_checkpointing_disable\nmodel.gradient_checkpointing_enable = model.pretrained_model.gradient_checkpointing_enable\n```","metadata":{}},{"cell_type":"code","source":"# step 1: 使用transformers库加载模型\npretrained_model = AutoModelForCausalLM.from_pretrained(\n    config.model_name,\n#     device_map=\"auto\",\n#     load_in_8bit=True,\n)\n\n# 设置目标模块名称\ntarget_modules = None\ntarget_modules = [\"c_attn\"]  # workaround to use 8bit training on this model\n\n# 设置lora配置参数\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=target_modules,  # handled automatically by peft\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\n# step 2: 设置8bit训练\npretrained_model = prepare_model_for_int8_training(pretrained_model, output_embedding_layer_name=\"lm_head\")\n# for name, param in pretrained_model.named_parameters():\n#     # freeze base model's layers\n#     param.requires_grad = False\n\n#     if getattr(pretrained_model, \"is_loaded_in_8bit\", False):\n#         # cast layer norm in fp32 for stability for 8bit models\n#         if param.ndim == 1 and \"layer_norm\" in name:\n#             param.data = param.data.to(torch.float16)\n\n# step 3: 设置lora模型。做instruction learning，到这里就好了。如果要做RLHF，还要做第四步。\npretrained_model = get_peft_model(pretrained_model, lora_config)\n\n# step 4: 将lora模型加载入trl模型，加上value head。\nmodel = AutoModelForCausalLMWithValueHead.from_pretrained(pretrained_model)\n\n# 做必要的设置，梯度检查。\nmodel.gradient_checkpointing_disable = model.pretrained_model.gradient_checkpointing_disable\nmodel.gradient_checkpointing_enable = model.pretrained_model.gradient_checkpointing_enable\n\n# model.gradient_checkpointing_disable()\n# model.pretrained_model.config.use_cache = True\n# ppo_trainer = PPOTrainer(config, model, ref_model=None, \n#                          tokenizer=tokenizer, dataset=dataset, \n#                          data_collator=collator)\n# ppo_trainer.generate(query, **generation_kwargs)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-20T14:59:22.970093Z","iopub.execute_input":"2023-04-20T14:59:22.970529Z","iopub.status.idle":"2023-04-20T14:59:28.317581Z","shell.execute_reply.started":"2023-04-20T14:59:22.970499Z","shell.execute_reply":"2023-04-20T14:59:28.316521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )\n    \nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:59:28.318915Z","iopub.execute_input":"2023-04-20T14:59:28.319491Z","iopub.status.idle":"2023-04-20T14:59:28.32869Z","shell.execute_reply.started":"2023-04-20T14:59:28.319451Z","shell.execute_reply":"2023-04-20T14:59:28.32749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import wandb\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# wandb_api = user_secrets.get_secret(\"wandb_key\")\n# wandb.login(key=wandb_api)\n# wandb.init(project=\"trl_imdb_positive\")","metadata":{"_uuid":"537e9085-22bb-40bc-8e92-5e4d582068c3","_cell_guid":"5d3135d3-cb0b-4a7d-ab4d-d2e6f69b145c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T14:59:28.331396Z","iopub.execute_input":"2023-04-20T14:59:28.331787Z","iopub.status.idle":"2023-04-20T15:00:03.005575Z","shell.execute_reply.started":"2023-04-20T14:59:28.331741Z","shell.execute_reply":"2023-04-20T15:00:03.00449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 可以看到前面设置了`gpt2_imdb`这样一个GPT2模型。这个模型已经在IMDB数据集上进行了微调，也就是SFT步骤。具体微调模型的代码可以在链接[script](https://github.com/huggingface/transformers/blob/master/examples/run_language_modeling.py)找到。具体论文可以参考链接[\"Fine-Tuning Language Models from Human Preferences\"](https://arxiv.org/pdf/1909.08593.pdf)。在Huggingface的Hub上可以找到GPT2和BERT\n对应的IMDB微调模型，链接为[here](https://huggingface.co/models)。下面的代码在kaggle上运行，会自动加载缓存数据集和模型。","metadata":{"_uuid":"b3838c7c-b976-4201-9a6a-a8c30ad05ef3","_cell_guid":"86e30e0a-97eb-4013-a853-d877ace8517e","trusted":true}},{"cell_type":"markdown","source":"## 加载数据和模型","metadata":{"_uuid":"9e036887-194e-467e-a532-1d88275e7e49","_cell_guid":"5ef5961e-741a-4bc2-80d8-c718f4e6198c","trusted":true}},{"cell_type":"markdown","source":"### 加载IMDB数据集\n\n> IMDB数据集包含50,000个电影评论，已经用`positive/negative`标注好了情感极性。我们将IMDB数据集转换为Pandas的DataFrame(可以参考pandas的文档)，并过滤掉评论超过200个字符的评论。然后对文本进行分词，并使用`LengthSampler`来将其切割为随机尺寸（保证模型对不同长度的评论都有作用）。","metadata":{"_uuid":"3332fc9b-2357-4ee7-9bfc-1ea9bd6f13f5","_cell_guid":"c7cb2d2d-f460-4410-8bc7-55050797061a","trusted":true}},{"cell_type":"code","source":"def build_dataset(config, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8):\n    \"\"\"\n    构建训练用的数据集。使用`load_dataset`函数下载和缓存数据集。如果要用自己的数据集，则需要替换该部分代码。\n    当然`load_dataset`也可以加载本地数据集，详情各自行百度，或者去datasets的官网查找帮助信息。\n    \n    Args:\n        dataset_name (`str`): \n            数据集名称\n    \n    Returns:\n        dataloader (`torch.utils.data.DataLoader`):\n            返回dataloader\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n    tokenizer.pad_token = tokenizer.eos_token # pad_token和eos_token是同一个，也可以用其它的token进行替换。\n    # 加载IMDB数据集，直接从huggingface的hub上下载数据，当然也可以下载其他数据\n    # 每次做DL或ML时，大量时间用在了做\n    ds = load_dataset(dataset_name, split='train') # 加载后是DataFrame格式！？\n    ds = ds.rename_columns({'text': 'review'})\n    ds = ds.filter(lambda x: len(x[\"review\"])>200, batched=False) # 这里filter是指len(x[\"review\"])>200都过滤掉\n\n    # 对batch_size进行裁剪，缩小到2到8之间。（2和8是函数中的默认参数）\n    # 即query的token长度控制在2到8之间，有点小呀\n    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n    \n    def tokenize(sample):\n        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[:input_size()] # 后面设置batched=False,每次input_size都不同\n        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n        return sample\n\n    ds = ds.map(tokenize, batched=False)\n    # 将数值型变量设置为torch的tensor格式，并且输出所有的列数据，在RL截断需要使用！一定要注意设置output_all_columns=True\n    ds.set_format(type='torch', columns=[\"input_ids\", \"label\"], output_all_columns=True)\n    return ds","metadata":{"_uuid":"cffe502f-9187-49e2-80c4-d326d0b7a142","_cell_guid":"5ca30130-93f6-4842-8930-64d5e2581f89","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T15:00:03.010333Z","iopub.execute_input":"2023-04-20T15:00:03.012941Z","iopub.status.idle":"2023-04-20T15:00:03.025207Z","shell.execute_reply.started":"2023-04-20T15:00:03.012893Z","shell.execute_reply":"2023-04-20T15:00:03.024257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = build_dataset(config)\n\ndef collator(data):\n    return dict((key, [d[key] for d in data]) for key in data[0])","metadata":{"_uuid":"e93c2019-239b-47ef-b141-a40678407113","_cell_guid":"9c3c3934-363d-482d-a39b-7695d5db875f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T15:00:03.026977Z","iopub.execute_input":"2023-04-20T15:00:03.027663Z","iopub.status.idle":"2023-04-20T15:01:12.542248Z","shell.execute_reply.started":"2023-04-20T15:00:03.027622Z","shell.execute_reply":"2023-04-20T15:01:12.540796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 加载已经预训练好的GPT2语言模型","metadata":{"_uuid":"6563bb2d-c3a1-45ee-ab0d-f07ed2916872","_cell_guid":"0efd6f26-4443-48d9-a3e1-c8641163eb50","trusted":true}},{"cell_type":"markdown","source":"> 这里加载带有value head的GPT2模型及其对应的分词器。下面加载了两次模型；第一次加载的模型用来进行强化学习，调整参数。第二次加载的模型作为参考模型，用来计算和前面可训练模型的KL散度。这个KL散度，用来作为PPO训练的额外奖励信号，来保证我们的模型不会太偏离原始模型（即防止灾难性遗忘情况的发生）。","metadata":{"_uuid":"d635c177-af75-4bbb-8bae-b5ca45ff8bd3","_cell_guid":"b17d3bac-2315-418e-a988-602461c7441c","trusted":true}},{"cell_type":"code","source":"# lora_config = LoraConfig(\n#     r=16,\n#     lora_alpha=32,\n#     lora_dropout=0.05,\n#     bias=\"none\",\n#     task_type=\"CAUSAL_LM\",\n# )\n\n# 下面的代码会报错！\n# model = AutoModelForCausalLMWithValueHead.from_pretrained(\n#     config.model_name,\n#     device_map=\"auto\",\n#     load_in_8bit=True,\n#     peft_config=lora_config,\n#     layer_norm_names=[]\n# )","metadata":{"execution":{"iopub.status.busy":"2023-04-20T15:01:12.543891Z","iopub.execute_input":"2023-04-20T15:01:12.544724Z","iopub.status.idle":"2023-04-20T15:01:12.558701Z","shell.execute_reply.started":"2023-04-20T15:01:12.544682Z","shell.execute_reply":"2023-04-20T15:01:12.556277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\ntokenizer = AutoTokenizer.from_pretrained(config.model_name)\n\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"_uuid":"1cdd7275-56ae-4ecd-bd63-183acdb043ae","_cell_guid":"b8a65324-d7b5-492c-bc17-896d2f9cd54d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T15:01:12.560295Z","iopub.execute_input":"2023-04-20T15:01:12.560657Z","iopub.status.idle":"2023-04-20T15:01:15.640924Z","shell.execute_reply.started":"2023-04-20T15:01:12.560617Z","shell.execute_reply":"2023-04-20T15:01:15.639017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ppo_trainer = PPOTrainer(config, model, ref_model=ref_model, \n                         tokenizer=tokenizer, dataset=dataset, \n                         data_collator=collator)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T15:01:15.642789Z","iopub.execute_input":"2023-04-20T15:01:15.643431Z","iopub.status.idle":"2023-04-20T15:01:57.294869Z","shell.execute_reply.started":"2023-04-20T15:01:15.643392Z","shell.execute_reply":"2023-04-20T15:01:57.293784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 初始化PPOTrainer\n\n> `PPOTrainer`可以很方便的进行训练，并且处理好数据在GPU上的计算。","metadata":{"_uuid":"c1e271ec-7548-4ca0-8bf9-9bdabf41bbcf","_cell_guid":"b3948965-a9a5-4343-845a-a4e621872d76","trusted":true}},{"cell_type":"markdown","source":"### 加载BERT分类器\n> 下面加载在IMDB数据集上微调过的BERT分类器","metadata":{"_uuid":"e5c9fe1d-41f0-4c2f-99f1-3485b2c22df4","_cell_guid":"cfb7fbd8-a9ab-4448-9dc9-f27108507113","trusted":true}},{"cell_type":"code","source":"device = ppo_trainer.accelerator.device\nif ppo_trainer.accelerator.num_processes == 1:\n    device = 0 if torch.cuda.is_available() else \"cpu\" # to avoid a `pipeline` bug\nsentiment_pipe = pipeline(\"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\", device=device)","metadata":{"_uuid":"55102732-4e53-4d64-877b-8f4430f580f2","_cell_guid":"a5d9f988-f3cf-4d6b-9364-307bc312a1f9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T15:01:57.296476Z","iopub.execute_input":"2023-04-20T15:01:57.296972Z","iopub.status.idle":"2023-04-20T15:02:01.381081Z","shell.execute_reply.started":"2023-04-20T15:01:57.29693Z","shell.execute_reply":"2023-04-20T15:02:01.37993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 模型会输出数值，来对应正面和负面的类别。下面使用正面类的得分作为语言模型的奖励信号。","metadata":{"_uuid":"aecb0fc8-12f3-40ab-ab28-f64b27a2e1ce","_cell_guid":"1ed173d8-3dda-4697-ac0c-8edaec9af794","trusted":true}},{"cell_type":"code","source":"# text = 'this movie was really bad!!'\n# sentiment_pipe(text, **sent_kwargs)","metadata":{"_uuid":"eb4ac0aa-7404-4fdf-886a-44fda2eda2fc","_cell_guid":"4c9d7348-6849-4446-b904-b27a91e3f206","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T15:02:01.385441Z","iopub.execute_input":"2023-04-20T15:02:01.38577Z","iopub.status.idle":"2023-04-20T15:02:01.389841Z","shell.execute_reply.started":"2023-04-20T15:02:01.385717Z","shell.execute_reply":"2023-04-20T15:02:01.388791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text = 'this movie was really good!!'\n# pipe_outputs = sentiment_pipe([text, text], **sent_kwargs)","metadata":{"_uuid":"72a17bb6-7353-4c5f-9d8e-8c0c20599b27","_cell_guid":"1b49d4b8-daf1-4aaf-af4f-ec4272732508","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T15:02:01.392446Z","iopub.execute_input":"2023-04-20T15:02:01.393486Z","iopub.status.idle":"2023-04-20T15:02:01.406025Z","shell.execute_reply.started":"2023-04-20T15:02:01.393447Z","shell.execute_reply":"2023-04-20T15:02:01.405064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output = pipe_outputs[0]\n# print(output)\n# print()\n# print(output[1])","metadata":{"execution":{"iopub.status.busy":"2023-04-20T15:02:01.407542Z","iopub.execute_input":"2023-04-20T15:02:01.40796Z","iopub.status.idle":"2023-04-20T15:02:01.415949Z","shell.execute_reply.started":"2023-04-20T15:02:01.407921Z","shell.execute_reply":"2023-04-20T15:02:01.414779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 通过下面的代码来获取正面得分","metadata":{}},{"cell_type":"code","source":"# rewards = [torch.tensor(output[1][\"score\"]) for output in pipe_outputs]\n# rewards","metadata":{"execution":{"iopub.status.busy":"2023-04-20T15:02:01.417056Z","iopub.execute_input":"2023-04-20T15:02:01.417365Z","iopub.status.idle":"2023-04-20T15:02:01.426206Z","shell.execute_reply.started":"2023-04-20T15:02:01.417337Z","shell.execute_reply":"2023-04-20T15:02:01.424786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 文本生成设置\n\n> 根据query生成response，这里的配置使用top_p和随机采样来生成文本。","metadata":{"_uuid":"19f8d46a-faf5-4787-bb06-003d2cefc2d4","_cell_guid":"1f3f649d-b03a-4307-a3a9-6085826834b6","trusted":true}},{"cell_type":"code","source":"gen_kwargs = {\n    \"min_length\":-1,\n    \"top_k\": 0.0,\n    \"top_p\": 1.0,\n    \"do_sample\": True,\n    \"pad_token_id\": tokenizer.eos_token_id\n}","metadata":{"_uuid":"123bc57a-d079-4f7b-a408-6eb2fe6d4c2d","_cell_guid":"424e71ff-2338-4ddd-85ed-1f55768c96f9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T15:02:01.427547Z","iopub.execute_input":"2023-04-20T15:02:01.427973Z","iopub.status.idle":"2023-04-20T15:02:01.436663Z","shell.execute_reply.started":"2023-04-20T15:02:01.427933Z","shell.execute_reply":"2023-04-20T15:02:01.435604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 使用PPO强化学习算法优化模型","metadata":{"_uuid":"65bc7fb9-de2e-4734-9263-0be077550a33","_cell_guid":"381162d0-7c26-4d0c-bbdc-c0bdfd45e09c"}},{"cell_type":"markdown","source":"### 训练循环","metadata":{"_uuid":"4f4c89b2-2f1d-4f5c-af26-3bd0366fb9e7","_cell_guid":"fff73937-9931-41b6-a5c9-e3592fc32c51","trusted":true}},{"cell_type":"markdown","source":"训练循环主要包含三个步骤：\n- 根据query，基于GPT2生成response\n- 拼接query和response，使用BERT来得到拼接后文本的得分\n- 基于(query, response, reward)三元组，基于PPO算法来优化模型\n\n**训练耗时**\n\n基于上述配置，在V100上大约耗时两个小时完成训练。（如果使用peft包，可能会快一些，但是效果不知道怎么样！）","metadata":{"_uuid":"ee9215ba-3c73-465a-b2e2-74b1ba8689d7","_cell_guid":"11e14bdb-c766-49d0-a643-d01aa972ab82","trusted":true}},{"cell_type":"code","source":"output_min_length = 4\noutput_max_length = 16\noutput_length_sampler = LengthSampler(output_min_length, output_max_length)\n\n\ngeneration_kwargs = {\n    \"min_length\":-1,\n    \"top_k\": 0.0,\n    \"top_p\": 1.0,\n    \"do_sample\": True,\n    \"pad_token_id\": tokenizer.eos_token_id\n}\n\n\nfor epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n    query_tensors = batch['input_ids']\n    \n    model.gradient_checkpointing_disable()\n    model.pretrained_model.config.use_cache = True\n    #### Get response from gpt2\n    response_tensors = []\n    for query in query_tensors:\n        gen_len = output_length_sampler()\n        generation_kwargs[\"max_new_tokens\"] = gen_len\n        response = ppo_trainer.generate(query, **generation_kwargs)\n        response_tensors.append(response.squeeze()[-gen_len:])\n    batch['response'] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n\n    #### Compute sentiment score\n    texts = [q + r for q,r in zip(batch['query'], batch['response'])]\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n    rewards = [torch.tensor(output[1][\"score\"]) for output in pipe_outputs]\n    \n    # Run PPO step\n    model.gradient_checkpointing_enable()\n    model.pretrained_model.config.use_cache = False\n    \n    #### Run PPO step \n    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n    ppo_trainer.log_stats(stats, batch, rewards)\n    \n#     break","metadata":{"_uuid":"9cd4eb57-3678-4da1-a211-bcb7c8f981b5","_cell_guid":"00601c24-d74a-42bd-b637-f88cace29d0b","collapsed":false,"jupyter":{"outputs_hidden":false},"scrolled":true,"execution":{"iopub.status.busy":"2023-04-20T15:02:01.437949Z","iopub.execute_input":"2023-04-20T15:02:01.440023Z","iopub.status.idle":"2023-04-20T15:03:14.402083Z","shell.execute_reply.started":"2023-04-20T15:02:01.439984Z","shell.execute_reply":"2023-04-20T15:03:14.400959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 训练过程\n如果使用Weights&Biases来跟踪训练过程，可以查看[链接](https://app.wandb.ai/lvwerra/trl-showcase/runs/1jtvxb1m/).该链接是已经训练好wandb工程。\n\n<div style=\"text-align: center\">\n<img src='https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/gpt2_tuning_progress.png' width='800'>\n<p style=\"text-align: center;\"> <b>图1:</b> 训练过程中的奖励均值和分布变化情况</p>\n</div>\n\n在训练一段时间之后，可以观察到该模型会生成正面的评论文本，表明模型的训练趋势是正确的。","metadata":{"_uuid":"e79cfee7-7330-416f-bd97-cd9c03abe2ad","_cell_guid":"9b76e36e-c71f-407f-bbb2-812839b40b00","trusted":true}},{"cell_type":"markdown","source":"## 测试模型效果\n让我们测试几个IMDB的评论生成例子。比较`model`和`model_ref`的生成结果和评论得分。","metadata":{"_uuid":"0aba7e65-da82-48a1-b948-a69d2233c5e7","_cell_guid":"cb833b5f-0281-433d-bf93-d1e21ddf349c","trusted":true}},{"cell_type":"code","source":"#### get a batch from the dataset\nbs = 16\ngame_data = dict()\ndataset.set_format(\"pandas\")\ndf_batch = dataset[:].sample(bs)\ngame_data['query'] = df_batch['query'].tolist()\nquery_tensors = df_batch['input_ids'].tolist()\n\nresponse_tensors_ref, response_tensors = [], []\n\n#### get response from gpt2 and gpt2_ref\nfor i in range(bs):\n    gen_len = output_length_sampler()\n    output = ref_model.generate(torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n                                     max_new_tokens=gen_len, **gen_kwargs).squeeze()[-gen_len:]\n    response_tensors_ref.append(output) # \n#     output = model.generate(torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n#                                  max_new_tokens=gen_len, **gen_kwargs).squeeze()[-gen_len:]\n    output = ppo_trainer.generate(torch.tensor(query_tensors[i]).to(device),\n                                 max_new_tokens=gen_len, **gen_kwargs).squeeze()[-gen_len:]\n    response_tensors.append(output)\n\n#### decode responses\ngame_data['response (before)'] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\ngame_data['response (after)'] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n\n#### sentiment analysis of query/response pairs before/after\ntexts = [q + r for q,r in zip(game_data['query'], game_data['response (before)'])]\ngame_data['rewards (before)'] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n\ntexts = [q + r for q,r in zip(game_data['query'], game_data['response (after)'])]\ngame_data['rewards (after)'] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n\n# store results in a dataframe\ndf_results = pd.DataFrame(game_data)\ndf_results","metadata":{"_uuid":"bfd9d244-58cc-410a-8475-6d19a8032805","_cell_guid":"09f310d8-3ee1-4f68-9170-0f84947d62e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T15:06:26.315422Z","iopub.execute_input":"2023-04-20T15:06:26.315924Z","iopub.status.idle":"2023-04-20T15:06:30.692641Z","shell.execute_reply.started":"2023-04-20T15:06:26.315876Z","shell.execute_reply":"2023-04-20T15:06:30.691677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"然后观察下生成序列的奖励均值和中位数，存在明显的区别，如下。","metadata":{"_uuid":"189632d7-c91b-4ca8-ac3f-e9e13c461997","_cell_guid":"8614794f-b1d4-49ed-b006-69bc10d37e00","trusted":true}},{"cell_type":"code","source":"print('mean:')\ndisplay(df_results[[\"rewards (before)\", \"rewards (after)\"]].mean())\nprint()\nprint('median:')\ndisplay(df_results[[\"rewards (before)\", \"rewards (after)\"]].median())","metadata":{"_uuid":"0a382e5b-639f-4a2a-afd4-8d2d2651e609","_cell_guid":"125141a3-a6cf-4bbb-b4b1-bb6882f3dde4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T15:07:00.593386Z","iopub.execute_input":"2023-04-20T15:07:00.593884Z","iopub.status.idle":"2023-04-20T15:07:00.628028Z","shell.execute_reply.started":"2023-04-20T15:07:00.593843Z","shell.execute_reply":"2023-04-20T15:07:00.627123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 保存模型\n最后，将模型保存到HuggingFace的官网上。","metadata":{"_uuid":"cda13dd0-a158-44e3-a86c-a7feba9b881c","_cell_guid":"5ba1a753-8e6c-47cc-b6ad-1a160b1ab39e","trusted":true}},{"cell_type":"code","source":"# 登录huggingface Hub\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhuggingface_key = user_secrets.get_secret(\"huggingface_key\")\nlogin(token=huggingface_key, add_to_git_credential=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T15:07:05.23065Z","iopub.execute_input":"2023-04-20T15:07:05.231377Z","iopub.status.idle":"2023-04-20T15:07:05.813312Z","shell.execute_reply.started":"2023-04-20T15:07:05.231337Z","shell.execute_reply":"2023-04-20T15:07:05.811902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained('gpt2-imdb-pos-v2', push_to_hub=True)\ntokenizer.save_pretrained('gpt2-imdb-pos-v2', push_to_hub=True)","metadata":{"_uuid":"309f182d-9c34-443b-92d4-615909e8cd73","_cell_guid":"d4104801-5ba5-4f9c-a6c7-bb9dfb5ec333","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-20T15:07:20.413662Z","iopub.execute_input":"2023-04-20T15:07:20.414178Z","iopub.status.idle":"2023-04-20T15:07:20.635704Z","shell.execute_reply.started":"2023-04-20T15:07:20.414133Z","shell.execute_reply":"2023-04-20T15:07:20.634405Z"},"trusted":true},"execution_count":null,"outputs":[]}]}