{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchkeras peft","metadata":{"execution":{"iopub.status.busy":"2023-08-17T04:20:43.115439Z","iopub.execute_input":"2023-08-17T04:20:43.116073Z","iopub.status.idle":"2023-08-17T04:20:58.174528Z","shell.execute_reply.started":"2023-08-17T04:20:43.116035Z","shell.execute_reply":"2023-08-17T04:20:58.173274Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchkeras\n  Downloading torchkeras-3.9.3-py3-none-any.whl (6.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting peft\n  Downloading peft-0.4.0-py3-none-any.whl (72 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from torchkeras) (0.20.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchkeras) (4.65.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.30.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft) (2023.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nInstalling collected packages: torchkeras, peft\nSuccessfully installed peft-0.4.0 torchkeras-3.9.3\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n############先是所有的配置参数.\n\nimport os\n\n# 导入常用模块\nimport numpy as np\n\nimport torch\nfrom torch import nn \nfrom torch.utils.data import Dataset,DataLoader \n\n\n# 配置参数\nfrom argparse import Namespace\ncfg = Namespace()\n\n#dataset\ncfg.prompt_column = 'prompt'\ncfg.response_column = 'response'\ncfg.history_column =None\ncfg.source_prefix = '' #添加到每个prompt开头的前缀引导语\n\ncfg.max_source_length = 128 \ncfg.max_target_length = 128\n\n#model\ncfg.model_name_or_path = 'THUDM/chatglm2-6b'  #远程'THUDM/chatglm-6b' \ncfg.quantization_bit = None #仅仅预测时可以选 4 or 8 \n\n\n#train\ncfg.epochs = 100 \ncfg.lr = 5e-3\ncfg.batch_size = 2\ncfg.gradient_accumulation_steps = 1 #梯度累积\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available()else \"cpu\") \n\n\n\n\n\n\n#==========定义知识样本.######先处理我们的数据.\nfrom torch.utils.data import Dataset,DataLoader \nimport transformers\nfrom transformers import  AutoModel,AutoTokenizer,AutoConfig,DataCollatorForSeq2Seq\ntokenizer = AutoTokenizer.from_pretrained(\n    cfg.model_name_or_path, trust_remote_code=True)\nimport transformers\nfrom transformers import  AutoModel,AutoTokenizer,AutoConfig,DataCollatorForSeq2Seq\n\n\nimport pandas as pd \nkeyword = '梦中情炉'\n\ndescription = '''梦中情炉一般指的是炼丹工具torchkeras。\n这是一个通用的pytorch模型训练模版工具。\ntorchkeras是一个三好炼丹炉：好看，好用，好改。\n她有torch的灵动，也有keras的优雅，并且她的美丽，无与伦比。\n所以她的作者一个有毅力的吃货给她取了一个别名叫做梦中情炉。'''\n\n\n\n\n#对prompt使用一些简单的数据增强的方法，以便更好地收敛。\ndef get_prompt_list(keyword):\n    return [f'{keyword}', \n            f'你知道{keyword}吗?',\n            f'{keyword}是什么？',\n            f'介绍一下{keyword}',\n            f'你听过{keyword}吗?',\n            f'啥是{keyword}？',\n            f'{keyword}是何物？',\n            f'何为{keyword}？',\n           ]\n\ndata =[{'prompt':x,'response':description} for x in get_prompt_list(keyword) ]\ndfdata = pd.DataFrame(data)\n\n\n\n\n\nimport datasets \n#训练集和验证集一样\nds_train_raw = ds_val_raw = datasets.Dataset.from_pandas(dfdata)\n#这是支持 history列处理，并且按照batch预处理数据的方法。\n\ndef preprocess(examples):\n    max_seq_length = cfg.max_source_length + cfg.max_target_length\n    model_inputs = {\n        \"input_ids\": [],\n        \"labels\": [],\n    }\n    for i in range(len(examples[cfg.prompt_column])):\n        if examples[cfg.prompt_column][i] and examples[cfg.response_column][i]:\n            query, answer = examples[cfg.prompt_column][i], examples[cfg.response_column][i]\n\n            history = examples[cfg.history_column][i] if cfg.history_column is not None else None\n            prompt = tokenizer.build_prompt(query, history)\n\n            prompt = cfg.source_prefix + prompt\n            a_ids = tokenizer.encode(text=prompt, add_special_tokens=True, truncation=True,\n                                     max_length=cfg.max_source_length)\n            b_ids = tokenizer.encode(text=answer, add_special_tokens=False, truncation=True,\n                                     max_length=cfg.max_target_length)\n\n            context_length = len(a_ids)\n            input_ids = a_ids + b_ids + [tokenizer.eos_token_id]\n            labels = [tokenizer.pad_token_id] * context_length + b_ids + [tokenizer.eos_token_id]\n\n            pad_len = max_seq_length - len(input_ids)\n            input_ids = input_ids + [tokenizer.pad_token_id] * pad_len\n            labels = labels + [tokenizer.pad_token_id] * pad_len\n            labels = [(l if l != tokenizer.pad_token_id else -100) for l in labels]\n            model_inputs[\"input_ids\"].append(input_ids)\n            model_inputs[\"labels\"].append(labels)\n    return model_inputs\n\n\nds_train = ds_train_raw.map(\n    preprocess,\n    batched=True,\n    num_proc=4,\n    remove_columns=ds_train_raw.column_names\n)\n\nds_val = ds_val_raw.map(\n    preprocess,\n    batched=True,\n    num_proc=4,\n    remove_columns=ds_val_raw.column_names\n)\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer,\n    model=None,\n    label_pad_token_id=-100,\n    pad_to_multiple_of=None,\n    padding=False\n)\n\ndl_train = DataLoader(ds_train,batch_size = cfg.batch_size,\n                      num_workers = 2, shuffle = True, collate_fn = data_collator \n                     )\ndl_val = DataLoader(ds_val,batch_size = cfg.batch_size,\n                      num_workers = 2, shuffle = False, collate_fn = data_collator \n                     )\n\n\n\n\nprint(len(dl_train))\n\n\n\n\nconfig = AutoConfig.from_pretrained(cfg.model_name_or_path, trust_remote_code=True)\n\n\n\nmodel = AutoModel.from_pretrained(cfg.model_name_or_path,config=config,\n                                  trust_remote_code=True, device_map='auto').half() #==========16位用来gpu训练.设备一定写auto,自动配置显卡和内存.\n\n#先量化瘦身  =======测试时候可以用这个. 不见一开启.除非配置 特别差.\nif cfg.quantization_bit is not None:\n    print(f\"Quantized to {cfg.quantization_bit} bit\")\n    model = model.quantize(cfg.quantization_bit)\n    \n#再移动到GPU上\n# model = model.cuda();\n\n\n# # 通过注册jupyter魔法命令可以很方便地在jupyter中测试ChatGLM \n# from torchkeras.chat import ChatGLM \n# chatglm = ChatGLM(model,tokenizer)\n\nprint('测试一下是否加载成功')\nresponse,history= model.chat(tokenizer,query='世界上最高的山峰是什么？',history=[])\nprint(response)\n\n\n\n\n#定义一条知识样本~#===========================\n\n\nfrom peft import get_peft_model, AdaLoraConfig, TaskType\n\n#训练时节约GPU占用\nmodel.config.use_cache=False\nmodel.supports_gradient_checkpointing = True  #\nmodel.gradient_checkpointing_enable()\nmodel.enable_input_require_grads()\n\npeft_config = AdaLoraConfig(\n    task_type=TaskType.CAUSAL_LM, inference_mode=False,\n    r=8,\n    lora_alpha=32, lora_dropout=0.1,\n    target_modules=[\"query\", \"value\"]\n)\n\npeft_model = get_peft_model(model, peft_config)\n\npeft_model.is_parallelizable = True\npeft_model.model_parallel = True\npeft_model.print_trainable_parameters()\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-17T04:20:58.180531Z","iopub.execute_input":"2023-08-17T04:20:58.182447Z","iopub.status.idle":"2023-08-17T04:32:29.200250Z","shell.execute_reply.started":"2023-08-17T04:20:58.182405Z","shell.execute_reply":"2023-08-17T04:32:29.199123Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/244 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b686f42e896a4cbcbe3015dbe80d76ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)enization_chatglm.py:   0%|          | 0.00/10.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"457942642c4c4e32b333ea01f4eabb9f"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n- tokenization_chatglm.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/1.02M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7042e9a6458444129b6b80b98b6ea6c9"}},"metadata":{}},{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"791b597c0fd84de188159cc1a4525a33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dc8681a6afd481da71e28d3a863d940"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d02abb00f45140ef901002ce853e66db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcefd2c7e8194b63a8db09881e434a99"}},"metadata":{}},{"name":"stdout","text":"       ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"906df65aa9af4f12a35391b26bfa33cb"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f358675422e74214865796a26ce6f1c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62614813c460422ab79ff99911d4fd4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29bee5de2e4541238d9e7db8f571dddf"}},"metadata":{}},{"name":"stdout","text":"4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.22k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8bd5da35ed7469d9ed9ca74ea48cae5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)iguration_chatglm.py:   0%|          | 0.00/2.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d48ee70fc6542fbb335fc046af5cece"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n- configuration_chatglm.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/modeling_chatglm.py:   0%|          | 0.00/50.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c12e89bea5ff43e0a5f3507657afcb3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)main/quantization.py:   0%|          | 0.00/14.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbed371e8b3b42b2ae055c708b6d2fb0"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n- quantization.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n- modeling_chatglm.py\n- quantization.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)model.bin.index.json:   0%|          | 0.00/20.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5de5cfcae4c489a86ae9b3887f86b56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7425fd8025747fc8fae8a8285990e8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00007.bin:   0%|          | 0.00/1.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cea1efdbd3484d3f85e9792580157f5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00007.bin:   0%|          | 0.00/1.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"438890361dac4ebfaf6b0d47c5184390"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00003-of-00007.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6929816dfd1d40aebed0f476eefa62ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00004-of-00007.bin:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de74076429c544258c337b586fcb033a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00005-of-00007.bin:   0%|          | 0.00/1.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5634cfc4829b4b0eb933d232c3cefb6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00006-of-00007.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7799f6d195d40e497bcf0dacc91f4a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00007-of-00007.bin:   0%|          | 0.00/1.05G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32e4a6470cef4caeb6f13fd0fe5c270f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5685ed0c2e7e48b5bff274c3d58be51e"}},"metadata":{}},{"name":"stdout","text":"测试一下是否加载成功\n世界上最高的山峰是珠穆朗玛峰(Mount Everest),位于喜马拉雅山脉,地处尼泊尔和中国之间的边界线上,海拔高度8,848.86米(29,031.69英尺)。珠穆朗玛峰是世界上最著名和最具挑战性的登山目标之一,吸引了许多登山者前来挑战。\ntrainable params: 2,924,880 || all params: 6,246,508,908 || trainable%: 0.04682423483386154\n","output_type":"stream"}]},{"cell_type":"code","source":"from accelerate import Accelerator\nAC=Accelerator(mixed_precision='fp16',cpu=None,\n            gradient_accumulation_steps=1)\n\n#================over.\n\n# #===============说明peft化之后,没法直接做预测.\n# with AC.autocast() , torch.no_grad():\n\n#     a=peft_model.chat(tokenizer,query='世界上最高的山峰是什么',history=[],max_length=40)\n#     print(a,'debug!!!!!!!!!!!')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T04:32:29.202086Z","iopub.execute_input":"2023-08-17T04:32:29.202544Z","iopub.status.idle":"2023-08-17T04:32:29.211688Z","shell.execute_reply.started":"2023-08-17T04:32:29.202506Z","shell.execute_reply":"2023-08-17T04:32:29.210699Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\nimport sys,datetime\nfrom tqdm import tqdm\nfrom copy import deepcopy\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom accelerate import Accelerator\n\n#=========设置打印信息的.\nclass EpochRunner:\n    def __init__(self,steprunner,quiet=False):\n        self.steprunner = steprunner\n        self.stage = steprunner.stage\n        self.accelerator = steprunner.accelerator\n        self.net = steprunner.net\n        self.quiet = quiet\n        \n    def __call__(self,dataloader):\n        n = dataloader.size  if hasattr(dataloader,'size') else len(dataloader)\n        loop = tqdm(enumerate(dataloader,start=1), \n                    total=n,\n                    file=sys.stdout,\n                    disable=not self.accelerator.is_local_main_process or self.quiet,\n                    ncols=100\n                   )\n        epoch_losses = {}\n        \n        for step, batch in loop: \n            with self.accelerator.accumulate(self.net):\n                step_losses,step_metrics = self.steprunner(batch)   \n                step_log = dict(step_losses,**step_metrics)\n\n                for k,v in step_losses.items():\n                    epoch_losses[k] = epoch_losses.get(k,0.0)+v\n                \n          #=============打印训练日志.\n                print('当前step')\n                if step<n:\n                    loop.set_postfix(**step_log)\n                    \n                    if hasattr(self,'progress') and self.accelerator.is_local_main_process:\n                        post_log = dict(**{'i':step,'n':n},**step_log)\n                        self.progress.set_postfix(**post_log)\n\n                elif step==n:\n                    epoch_metrics = step_metrics\n                    epoch_metrics.update({self.stage+\"_\"+name:metric_fn.compute().item() \n                                     for name,metric_fn in self.steprunner.metrics_dict.items()})\n                    epoch_losses = {k:v/step for k,v in epoch_losses.items()}\n                    epoch_log = dict(epoch_losses,**epoch_metrics)\n                    loop.set_postfix(**epoch_log)\n            \n                    \n                    if hasattr(self,'progress') and self.accelerator.is_local_main_process:\n                        post_log = dict(**{'i':step,'n':n},**epoch_log)\n                        self.progress.set_postfix(**post_log)\n                    \n                    for name,metric_fn in self.steprunner.metrics_dict.items():\n                        metric_fn.reset()  \n                else:\n                    break\n        print(55555,epoch_log)\n        return epoch_log\n\n\n#===============修改下面代码为自己跑. 来优化性能:\n\nfrom accelerate import Accelerator \n#============torchkeras来写训练代码果然牛逼,图标太牛逼了.\n#======第一步设置好自定义的KerasModel\nflag=0\nclass StepRunner:\n    def __init__(self, net, loss_fn, accelerator=None, stage = \"train\", metrics_dict = None, \n                 optimizer = None, lr_scheduler = None\n                 ):\n        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n        self.accelerator = accelerator if accelerator is not None else Accelerator() \n        if self.stage=='train':\n            self.net.train() \n        else:\n            self.net.eval()\n        self.flag=0\n    \n    def __call__(self, batch):\n        \n        #loss\n        global flag\n        if 0:\n#           if not flag: #=======我们打印第一个输入变量的数据,方便理解数据集.\n            print('查看第一个batch',batch)\n            flag=1\n        with self.accelerator.autocast():\n            loss = self.net(input_ids=batch[\"input_ids\"],labels=batch[\"labels\"]).loss\n#=========================从这往下的全是固定写法不用动.\n        #backward()\n        if self.optimizer is not None and self.stage==\"train\":\n            self.accelerator.backward(loss)\n            if self.accelerator.sync_gradients:\n                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n            self.optimizer.step()\n            if self.lr_scheduler is not None:\n                self.lr_scheduler.step()\n            self.optimizer.zero_grad()\n            \n        all_loss = self.accelerator.gather(loss).sum()\n        \n        #losses (or plain metrics that can be averaged)\n        step_losses = {self.stage+\"_loss\":all_loss.item()}\n        \n        #metrics (stateful metrics)\n        step_metrics = {}\n        \n        if self.stage==\"train\":\n            if self.optimizer is not None:\n                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n            else:\n                step_metrics['lr'] = 0.0\n        return step_losses,step_metrics\nclass KerasModel(torch.nn.Module):\n    \n    StepRunner,EpochRunner = StepRunner,EpochRunner\n    \n    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None,tokenizer=None):\n        super().__init__()\n        self.net,self.loss_fn,self.metrics_dict = net, loss_fn, torch.nn.ModuleDict(metrics_dict) \n        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(\n            self.net.parameters(), lr=3e-4)\n        self.lr_scheduler = lr_scheduler\n        self.from_scratch = True     #没有加载加载预先的权重.#初始化时候没加载, scratcch是草图的意思表示没有权重在网络里面.\n    #########=============一般不用下面这2个保存加载, 适配性不够.\n    def save_ckpt(self, ckpt_path=None, accelerator= None):\n        accelerator = accelerator if accelerator is not None else self.accelerator\n        net_dict = accelerator.get_state_dict(self.net)\n        accelerator.save(net_dict,ckpt_path if ckpt_path is not None else self.ckpt_path)\n      \n    def load_ckpt(self, ckpt_path=None):\n        self.net.load_state_dict(\n            torch.load(ckpt_path if ckpt_path is not None else self.ckpt_path,\n            map_location='cpu'))\n        self.from_scratch = False\n\n    def forward(self, x):\n        return self.net.forward(x)\n    \n    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint',\n            patience=5, monitor=\"val_loss\", mode=\"min\", callbacks=None, \n            plot=False,  wandb=False, quiet=None, \n            mixed_precision='no', cpu=False, gradient_accumulation_steps=1,dfhistorypath='dfhistory.csv'):\n        from torchkeras.utils import colorful,is_jupyter\n        self.__dict__.update(locals())\n        self.accelerator = AC\n        device = str(self.accelerator.device)\n        device_type = '🐌'  if 'cpu' in device else ('⚡️' if 'cuda' in device else '🚀')\n        self.accelerator.print(\n            colorful(\"<<<<<< \"+device_type +\" \"+ device +\" is used >>>>>>\"))\n    \n        self.net,self.loss_fn,self.metrics_dict,self.optimizer,self.lr_scheduler= self.accelerator.prepare(\n            self.net,self.loss_fn,self.metrics_dict,self.optimizer,self.lr_scheduler)\n        \n        train_dataloader,val_dataloader = self.accelerator.prepare(train_data,val_data)\n        train_dataloader.size = train_data.size if hasattr(train_data,'size') else len(train_data)\n        train_dataloader.size = min(train_dataloader.size,len(train_dataloader))\n        \n        if val_data:\n            val_dataloader.size = val_data.size if hasattr(val_data,'size') else len(val_data)\n            val_dataloader.size = min(val_dataloader.size,len(val_dataloader))\n        \n        self.history = {}\n        callbacks = callbacks if callbacks is not None else []\n        \n        if bool(plot):\n            from torchkeras.kerascallbacks import VisProgress,VisMetric\n            callbacks = [VisMetric(),VisProgress()]+callbacks\n            \n        if wandb!=False:\n            from torchkeras.kerascallbacks import WandbCallback\n            project = wandb if isinstance(wandb,str) else 'torchkeras'\n            callbacks.append(WandbCallback(project=project))\n            \n        self.callbacks = [self.accelerator.prepare(x) for x in callbacks]\n        \n        if self.accelerator.is_local_main_process:\n            [cb.on_fit_start(model = self) for cb in self.callbacks if hasattr(cb,'on_fit_start')]\n                \n        start_epoch = 1 if self.from_scratch else 0\n        \n        if bool(plot) or quiet is None:\n            quiet = True\n        \n        quiet_fn = (lambda epoch:quiet) if isinstance(quiet,bool) else (\n            (lambda epoch:epoch>quiet) if isinstance(quiet,int) else quiet)\n        #==========================训练.\n        for epoch in range(start_epoch,epochs+1):\n            if 0:\n                should_quiet = quiet_fn(epoch)\n            \n                if not should_quiet:\n                    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n                    self.accelerator.print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n                    self.accelerator.print(\"Epoch {0} / {1}\".format(epoch, epochs)+\"\\n\")\n\n            # 1，train -------------------------------------------------  \n            train_step_runner = self.StepRunner(    #训练一个step\n                    net = self.net,\n                    loss_fn = self.loss_fn,\n                    accelerator = self.accelerator,\n                    stage=\"train\",\n                    metrics_dict=deepcopy(self.metrics_dict),\n                    optimizer = self.optimizer if epoch>0 else None,\n                    lr_scheduler = self.lr_scheduler if epoch>0 else None\n            )\n            should_quiet=True\n            train_epoch_runner = self.EpochRunner(train_step_runner,should_quiet)\n            train_metrics = {'epoch':epoch}\n            print('111111')\n            train_metrics.update(train_epoch_runner(train_dataloader))\n            print(train_metrics)\n            for name, metric in train_metrics.items():\n                    self.history[name] = self.history.get(name, []) + [metric]\n            #==================调用callback函数!!!!!!!!!\n            if 0:\n                if self.accelerator.is_local_main_process: #=================420函数的含义就是调用全部的self.callbacks函数!!!!!!!!\n                    [cb.on_train_epoch_end(model = self) for cb in self.callbacks \n                    if hasattr(cb,'on_train_epoch_end')]\n                    \n            # 2，validate -------------------------------------------------\n            if val_dataloader is not None:\n                val_step_runner = self.StepRunner(\n                    net = self.net,\n                    loss_fn = self.loss_fn,\n                    accelerator = self.accelerator,\n                    stage=\"val\",\n                    metrics_dict= deepcopy(self.metrics_dict)\n                )\n                val_epoch_runner = self.EpochRunner(val_step_runner,should_quiet)\n                with torch.no_grad():\n                    val_metrics = val_epoch_runner(val_dataloader)\n\n                for name, metric in val_metrics.items():\n                    self.history[name] = self.history.get(name, []) + [metric]\n                \n            if self.accelerator.is_local_main_process:\n                [cb.on_validation_epoch_end(model = self) for cb in self.callbacks \n                 if hasattr(cb,'on_validation_epoch_end')]\n\n            # 3，early-stopping -------------------------------------------------\n            if 1: #======这部分逻辑不太对啊.#保存太密集了.我修改掉保存的.\n                self.accelerator.wait_for_everyone()\n                arr_scores = self.history[monitor]\n                best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n\n\n\n                if len(arr_scores)-best_score_idx>patience:\n                    break\n                \n        if self.accelerator.is_local_main_process:   \n            dfhistory = pd.DataFrame(self.history)\n            # [cb.on_fit_end(model = self) for cb in self.callbacks \n            #      if hasattr(cb,'on_fit_end')]\n            if epoch<epochs:\n                self.accelerator.print(colorful(\n                        \"<<<<<< {} without improvement in {} epoch,\"\"early stopping >>>>>> \\n\"\n                    ).format(monitor,patience))\n            # self.net = self.accelerator.unwrap_model(self.net)\n            # self.net.cpu()\n\n            dfhistory = pd.DataFrame(model.history)\n            dfhistory.to_csv(self.dfhistorypath,index=None)\n            # self.load_ckpt(ckpt_path)\n            return dfhistory\n    def predict(self,batch):\n\n        accelerator = Accelerator() if not hasattr(self,'accelerator') else self.accelerator\n        self.net,self.loss_fn,self.metrics_dict = accelerator.prepare(\n            self.net,self.loss_fn,self.metrics_dict)\n        val_data = accelerator.prepare(val_data)\n        with torch.no_grad():\n            a=self.StepRunner.net(input_ids=batch[\"input_ids\"])\n\n\n        return a\n\n    def evaluate(self, val_data, quiet=False):\n        accelerator = Accelerator() if not hasattr(self,'accelerator') else self.accelerator\n        self.net,self.loss_fn,self.metrics_dict = accelerator.prepare(\n            self.net,self.loss_fn,self.metrics_dict)\n        val_data = accelerator.prepare(val_data)\n        val_step_runner = self.StepRunner(net = self.net,stage=\"val\",\n                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n                    accelerator = accelerator)\n        val_epoch_runner = self.EpochRunner(val_step_runner,quiet=quiet)\n        with torch.no_grad():\n            val_metrics = val_epoch_runner(val_data)\n        return val_metrics\n    \n    def fit_ddp(self,num_processes,train_data,\n            val_data=None, epochs=10, ckpt_path='checkpoint',\n            patience=5, monitor=\"val_loss\", mode=\"min\", callbacks=None, \n            plot=True, wandb=False, quiet=None, \n            mixed_precision='no', cpu=False, gradient_accumulation_steps=1\n           ):\n        from accelerate import notebook_launcher\n        args = (train_data,val_data,epochs,ckpt_path,patience,monitor,mode,\n            callbacks,plot,wandb,quiet,mixed_precision,cpu,gradient_accumulation_steps)\n        notebook_launcher(self.fit, args, num_processes=num_processes)\n    \n    def evaluate_ddp(self, num_processes, val_data, quiet=False):\n        from accelerate import notebook_launcher\n        args = (val_data,quiet)\n        notebook_launcher(self.evaluate, args, num_processes=num_processes)\n\n\n\n\n\n\n\n\n\n    \nKerasModel.StepRunner = StepRunner \n\n\n#仅仅保存lora相关的可训练参数\ndef save_ckpt(self, ckpt_path='checkpoint', accelerator = None):\n    unwrap_net = accelerator.unwrap_model(self.net)\n    unwrap_net.save_pretrained(ckpt_path)\n    \ndef load_ckpt(self, ckpt_path='checkpoint'):\n    self.net = self.net.from_pretrained(self.net.base_model.model,ckpt_path)\n    self.from_scratch = False\n    \nKerasModel.save_ckpt = save_ckpt \nKerasModel.load_ckpt = load_ckpt \noptimizer = torch.optim.AdamW(peft_model.parameters(),lr=cfg.lr) \n\n#########第二步实例化model\nkeras_model = KerasModel(peft_model,loss_fn = None,\n        optimizer=optimizer) \nckpt_path = 'chatglm2_my' #===========保存的路径.\n#=========第三部下面函数自动训练, 画图, 和存模型.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport sys,datetime\nfrom tqdm import tqdm\nfrom copy import deepcopy\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom accelerate import Accelerator\n\n#=========设置打印信息的.\nclass EpochRunner:\n    def __init__(self,steprunner,quiet=False):\n        self.steprunner = steprunner\n        self.stage = steprunner.stage\n        self.accelerator = steprunner.accelerator\n        self.net = steprunner.net\n        self.quiet = quiet\n        \n    def __call__(self,dataloader):\n        n = dataloader.size  if hasattr(dataloader,'size') else len(dataloader)\n        loop = tqdm(enumerate(dataloader,start=1), \n                    total=n,\n                    file=sys.stdout,\n                    disable=not self.accelerator.is_local_main_process or self.quiet,\n                    ncols=100\n                   )\n        epoch_losses = {}\n        \n        for step, batch in loop: \n            with self.accelerator.accumulate(self.net):\n                step_losses,step_metrics = self.steprunner(batch)   \n                step_log = dict(step_losses,**step_metrics)\n                print(step_losses.items())\n                for k,v in step_losses.items():\n                    epoch_losses[k] = epoch_losses.get(k,0.0)+v\n          #=============打印训练日志.\n                if step<n:\n                    loop.set_postfix(**step_log)\n                    \n                    if hasattr(self,'progress') and self.accelerator.is_local_main_process:\n                        post_log = dict(**{'i':step,'n':n},**step_log)\n                        self.progress.set_postfix(**post_log)\n\n                elif step==n:\n    \n                    epoch_metrics = step_metrics\n                    epoch_metrics.update({self.stage+\"_\"+name:metric_fn.compute().item() \n                                     for name,metric_fn in self.steprunner.metrics_dict.items()})\n                    epoch_losses = {k:v/step for k,v in epoch_losses.items()}\n                    epoch_log = dict(epoch_losses,**epoch_metrics)\n                    loop.set_postfix(**epoch_log)\n            \n                    \n                    if hasattr(self,'progress') and self.accelerator.is_local_main_process:\n                        post_log = dict(**{'i':step,'n':n},**epoch_log)\n                        self.progress.set_postfix(**post_log)\n                    \n                    for name,metric_fn in self.steprunner.metrics_dict.items():\n                        metric_fn.reset()  \n                else:\n                    break\n        return epoch_log\n\n\n#===============修改下面代码为自己跑. 来优化性能:\n\nfrom accelerate import Accelerator \n#============torchkeras来写训练代码果然牛逼,图标太牛逼了.\n#======第一步设置好自定义的KerasModel\nflag=0\nclass StepRunner:\n    def __init__(self, net, loss_fn, accelerator=None, stage = \"train\", metrics_dict = None, \n                 optimizer = None, lr_scheduler = None\n                 ):\n        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n        self.accelerator = accelerator if accelerator is not None else Accelerator() \n        if self.stage=='train':\n            self.net.train() \n        else:\n            self.net.eval()\n        self.flag=0\n\n    \n    def __call__(self, batch):\n        \n        #loss\n        global flag\n        if not flag: #=======我们打印第一个输入变量的数据,方便理解数据集.\n            \n            flag=1\n        with self.accelerator.autocast():\n            loss = self.net(input_ids=batch[\"input_ids\"],labels=batch[\"labels\"]).loss\n#=========================从这往下的全是固定写法不用动.\n        #backward()\n        if self.optimizer is not None and self.stage==\"train\":\n            self.accelerator.backward(loss)\n            if self.accelerator.sync_gradients:\n                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n            self.optimizer.step()\n            if self.lr_scheduler is not None:\n                self.lr_scheduler.step()\n            self.optimizer.zero_grad()\n            \n        all_loss = self.accelerator.gather(loss).sum()\n        \n        #losses (or plain metrics that can be averaged)\n        step_losses = {self.stage+\"_loss\":all_loss.item()}\n        \n        #metrics (stateful metrics)\n        step_metrics = {}\n        \n        if self.stage==\"train\":\n            if self.optimizer is not None:\n                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n            else:\n                step_metrics['lr'] = 0.0\n        return step_losses,step_metrics\nclass KerasModel(torch.nn.Module):\n    \n    StepRunner,EpochRunner = StepRunner,EpochRunner\n    \n    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None,tokenizer=None,mixed_precision=None,cpu=None,gradient_accumulation_steps=None):\n        super().__init__()\n        self.net,self.loss_fn,self.metrics_dict = net, loss_fn, torch.nn.ModuleDict(metrics_dict) \n        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(\n            self.net.parameters(), lr=3e-4)\n        self.lr_scheduler = lr_scheduler\n        self.from_scratch = True     #没有加载加载预先的权重.#初始化时候没加载, scratcch是草图的意思表示没有权重在网络里面.\n        \n        self.accelerator= AC\n    #########=============一般不用下面这2个保存加载, 适配性不够.\n    def save_ckpt(self, ckpt_path=None, accelerator= None):\n        accelerator = accelerator if accelerator is not None else self.accelerator\n        net_dict = accelerator.get_state_dict(self.net)\n        accelerator.save(net_dict,ckpt_path if ckpt_path is not None else self.ckpt_path)\n      \n    def load_ckpt(self, ckpt_path=None):\n        self.net.load_state_dict(\n            torch.load(ckpt_path if ckpt_path is not None else self.ckpt_path,\n            map_location='cpu'))\n        self.from_scratch = False\n\n    def forward(self, x):\n        return self.net.forward(x)\n    \n    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint',\n            patience=5, monitor=\"val_loss\", mode=\"min\", callbacks=None, \n            plot=False,  wandb=False, quiet=None, \n            mixed_precision='no', cpu=False, gradient_accumulation_steps=1,dfhistorypath='dfhistory.csv'):\n        from torchkeras.utils import colorful,is_jupyter\n        self.__dict__.update(locals())\n\n        device = str(self.accelerator.device)\n        device_type = '🐌'  if 'cpu' in device else ('⚡️' if 'cuda' in device else '🚀')\n        self.accelerator.print(\n            colorful(\"<<<<<< \"+device_type +\" \"+ device +\" is used >>>>>>\"))\n    \n        self.net,self.loss_fn,self.metrics_dict,self.optimizer,self.lr_scheduler= self.accelerator.prepare(\n            self.net,self.loss_fn,self.metrics_dict,self.optimizer,self.lr_scheduler)\n        \n        train_dataloader,val_dataloader = self.accelerator.prepare(train_data,val_data)\n        train_dataloader.size = train_data.size if hasattr(train_data,'size') else len(train_data)\n        train_dataloader.size = min(train_dataloader.size,len(train_dataloader))\n        \n        if val_data:\n            val_dataloader.size = val_data.size if hasattr(val_data,'size') else len(val_data)\n            val_dataloader.size = min(val_dataloader.size,len(val_dataloader))\n        \n        self.history = {}\n        callbacks = callbacks if callbacks is not None else []\n        \n        if bool(plot):\n            from torchkeras.kerascallbacks import VisProgress,VisMetric\n            callbacks = [VisMetric(),VisProgress()]+callbacks\n            \n        if wandb!=False:\n            from torchkeras.kerascallbacks import WandbCallback\n            project = wandb if isinstance(wandb,str) else 'torchkeras'\n            callbacks.append(WandbCallback(project=project))\n            \n        self.callbacks = [self.accelerator.prepare(x) for x in callbacks]\n        \n        if self.accelerator.is_local_main_process:\n            [cb.on_fit_start(model = self) for cb in self.callbacks if hasattr(cb,'on_fit_start')]\n                \n        start_epoch = 1 if self.from_scratch else 0\n        \n        if bool(plot) or quiet is None:\n            quiet = True\n        \n        quiet_fn = (lambda epoch:quiet) if isinstance(quiet,bool) else (\n            (lambda epoch:epoch>quiet) if isinstance(quiet,int) else quiet)\n        #==========================训练.\n        for epoch in range(start_epoch,epochs+1):\n            if 0:\n                should_quiet = quiet_fn(epoch)\n            \n                if not should_quiet:\n                    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n                    self.accelerator.print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n                    self.accelerator.print(\"Epoch {0} / {1}\".format(epoch, epochs)+\"\\n\")\n            should_quiet=True\n            # 1，train -------------------------------------------------  \n            train_step_runner = self.StepRunner(    #训练一个step\n                    net = self.net,\n                    loss_fn = self.loss_fn,\n                    accelerator = self.accelerator,\n                    stage=\"train\",\n                    metrics_dict=deepcopy(self.metrics_dict),\n                    optimizer = self.optimizer if epoch>0 else None,\n                    lr_scheduler = self.lr_scheduler if epoch>0 else None\n            )\n\n            train_epoch_runner = self.EpochRunner(train_step_runner,should_quiet)\n            train_metrics = {'epoch':epoch}\n            train_metrics.update(train_epoch_runner(train_dataloader))\n\n            for name, metric in train_metrics.items():\n                    self.history[name] = self.history.get(name, []) + [metric]\n            #==================调用callback函数!!!!!!!!!\n            if 0:\n                if self.accelerator.is_local_main_process: #=================420函数的含义就是调用全部的self.callbacks函数!!!!!!!!\n                    [cb.on_train_epoch_end(model = self) for cb in self.callbacks \n                    if hasattr(cb,'on_train_epoch_end')]\n                    \n            # 2，validate -------------------------------------------------\n            if val_dataloader is not None:\n                val_step_runner = self.StepRunner(\n                    net = self.net,\n                    loss_fn = self.loss_fn,\n                    accelerator = self.accelerator,\n                    stage=\"val\",\n                    metrics_dict= deepcopy(self.metrics_dict)\n                )\n                val_epoch_runner = self.EpochRunner(val_step_runner,should_quiet)\n                with torch.no_grad():\n                    val_metrics = val_epoch_runner(val_dataloader)\n\n                for name, metric in val_metrics.items():\n                    self.history[name] = self.history.get(name, []) + [metric]\n                \n            if self.accelerator.is_local_main_process:\n                [cb.on_validation_epoch_end(model = self) for cb in self.callbacks \n                 if hasattr(cb,'on_validation_epoch_end')]\n\n            # 3，early-stopping -------------------------------------------------\n            if 1: #======这部分逻辑不太对啊.#保存太密集了.我修改掉保存的.\n                self.accelerator.wait_for_everyone()\n                arr_scores = self.history[monitor]\n                best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n\n\n\n                if len(arr_scores)-best_score_idx>patience:\n                    break\n                \n        if self.accelerator.is_local_main_process:   \n            dfhistory = pd.DataFrame(self.history)\n            # [cb.on_fit_end(model = self) for cb in self.callbacks \n            #      if hasattr(cb,'on_fit_end')]\n            if epoch<epochs:\n                self.accelerator.print(colorful(\n                        \"<<<<<< {} without improvement in {} epoch,\"\"early stopping >>>>>> \\n\"\n                    ).format(monitor,patience))\n            # self.net = self.accelerator.unwrap_model(self.net)\n            # self.net.cpu()\n\n#             dfhistory = pd.DataFrame(model.history)\n            dfhistory.to_csv(self.dfhistorypath,index=None)\n            # self.load_ckpt(ckpt_path)\n            return dfhistory\n#=====================!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!实现预测代码.\n\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n\n    def evaluate(self, val_data, quiet=False):\n        accelerator = Accelerator() if not hasattr(self,'accelerator') else self.accelerator\n        self.net,self.loss_fn,self.metrics_dict = accelerator.prepare(\n            self.net,self.loss_fn,self.metrics_dict)\n        val_data = accelerator.prepare(val_data)\n        val_step_runner = self.StepRunner(net = self.net,stage=\"val\",\n                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n                    accelerator = accelerator)\n        val_epoch_runner = self.EpochRunner(val_step_runner,quiet=quiet)\n        with torch.no_grad():\n            val_metrics = val_epoch_runner(val_data)\n        return val_metrics\n    \n    def fit_ddp(self,num_processes,train_data,\n            val_data=None, epochs=10, ckpt_path='checkpoint',\n            patience=5, monitor=\"val_loss\", mode=\"min\", callbacks=None, \n            plot=True, wandb=False, quiet=None, \n            mixed_precision='no', cpu=False, gradient_accumulation_steps=1\n           ):\n        from accelerate import notebook_launcher\n        args = (train_data,val_data,epochs,ckpt_path,patience,monitor,mode,\n            callbacks,plot,wandb,quiet,mixed_precision,cpu,gradient_accumulation_steps)\n        notebook_launcher(self.fit, args, num_processes=num_processes)\n    \n    def evaluate_ddp(self, num_processes, val_data, quiet=False):\n        from accelerate import notebook_launcher\n        args = (val_data,quiet)\n        notebook_launcher(self.evaluate, args, num_processes=num_processes)\n\n\n\n\n\n\n\n\n\n    \nKerasModel.StepRunner = StepRunner \n\n\n#仅仅保存lora相关的可训练参数\ndef save_ckpt(self, ckpt_path='checkpoint', accelerator = None):\n    unwrap_net = accelerator.unwrap_model(self.net)\n    unwrap_net.save_pretrained(ckpt_path)\n    \ndef load_ckpt(self, ckpt_path='checkpoint'):\n    self.net = self.net.from_pretrained(self.net.base_model.model,ckpt_path)\n    self.from_scratch = False\n    \nKerasModel.save_ckpt = save_ckpt \nKerasModel.load_ckpt = load_ckpt \noptimizer = torch.optim.AdamW(peft_model.parameters(),lr=cfg.lr) \n\n#########第二步实例化model\nkeras_model = KerasModel(peft_model,loss_fn = None,\n        optimizer=optimizer, mixed_precision='fp16',cpu=False,\n            gradient_accumulation_steps=cfg.gradient_accumulation_steps) \nckpt_path = 'chatglm2_my' #===========保存的路径.\n#=========第三部下面函数自动训练, 画图, 和存模型.\n\nprint('配置完毕')\n# if 1: # 测试\n\n#         print('训练之前开始测试')\n#         print(keras_model.predict('梦中情炉',max_length=200)[0])\n#         print(keras_model.predict('世界上最高的山峰是什么',max_length=200)[0])\n\n\n# if 1: # 测试\n\n#         print('训练之后开始测试')\n#         print(keras_model.predict('梦中情炉',max_length=200)[0])\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T04:32:29.215143Z","iopub.execute_input":"2023-08-17T04:32:29.215573Z","iopub.status.idle":"2023-08-17T04:32:29.341339Z","shell.execute_reply.started":"2023-08-17T04:32:29.215535Z","shell.execute_reply":"2023-08-17T04:32:29.340102Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"配置完毕\n","output_type":"stream"}]},{"cell_type":"code","source":"# #-==========手动写predict代码.    \n# if 1:\n#         keras_model.net.eval()\n#         accelerator = keras_model.accelerator\n#         keras_model.net,keras_model.loss_fn,keras_model.metrics_dict = keras_model.accelerator.prepare(\n#             keras_model.net,keras_model.loss_fn,keras_model.metrics_dict)\n        \n#         with accelerator.autocast() , torch.no_grad():\n#             for batch in dl_train:\n                \n#                 a=keras_model.net(input_ids=batch[\"input_ids\"].cuda(),labels=batch[\"labels\"].cuda()).logits\n#                 print(a,'debug!!!!!!!!!!!')\n#                 break\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T04:32:29.342733Z","iopub.execute_input":"2023-08-17T04:32:29.344427Z","iopub.status.idle":"2023-08-17T04:32:29.351300Z","shell.execute_reply.started":"2023-08-17T04:32:29.344392Z","shell.execute_reply":"2023-08-17T04:32:29.349416Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if 1:#训练\n    keras_model.fit(train_data = dl_train,\n                val_data = dl_train,\n                epochs=5,\n                patience=20,\n                monitor='val_loss',\n                mode='min',\n                ckpt_path = ckpt_path,\n\n                plot=False, # 不画画节省空间.\n          \n               )","metadata":{"execution":{"iopub.status.busy":"2023-08-17T06:29:12.136545Z","iopub.execute_input":"2023-08-17T06:29:12.136998Z","iopub.status.idle":"2023-08-17T06:30:29.731168Z","shell.execute_reply.started":"2023-08-17T06:29:12.136959Z","shell.execute_reply":"2023-08-17T06:30:29.729740Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"\u001b[0;31m<<<<<< ⚡️ cuda is used >>>>>>\u001b[0m\ndict_items([('train_loss', 0.059356689453125)])\ndict_items([('train_loss', 0.0716552734375)])\ndict_items([('train_loss', 0.060638427734375)])\ndict_items([('train_loss', 0.05731201171875)])\ndict_items([('val_loss', 0.058013916015625)])\ndict_items([('val_loss', 0.0579833984375)])\ndict_items([('val_loss', 0.0579833984375)])\ndict_items([('val_loss', 0.0579833984375)])\ndict_items([('train_loss', 0.058013916015625)])\ndict_items([('train_loss', 0.077392578125)])\ndict_items([('train_loss', 0.05712890625)])\ndict_items([('train_loss', 0.055328369140625)])\ndict_items([('val_loss', 0.06451416015625)])\ndict_items([('val_loss', 0.06451416015625)])\ndict_items([('val_loss', 0.06451416015625)])\ndict_items([('val_loss', 0.06451416015625)])\ndict_items([('train_loss', 0.06451416015625)])\ndict_items([('train_loss', 0.07861328125)])\ndict_items([('train_loss', 0.058837890625)])\ndict_items([('train_loss', 0.06549072265625)])\ndict_items([('val_loss', 0.0621337890625)])\ndict_items([('val_loss', 0.0621337890625)])\ndict_items([('val_loss', 0.0621337890625)])\ndict_items([('val_loss', 0.0621337890625)])\ndict_items([('train_loss', 0.0621337890625)])\ndict_items([('train_loss', 0.071044921875)])\ndict_items([('train_loss', 0.058135986328125)])\ndict_items([('train_loss', 0.05804443359375)])\ndict_items([('val_loss', 0.059295654296875)])\ndict_items([('val_loss', 0.059326171875)])\ndict_items([('val_loss', 0.059326171875)])\ndict_items([('val_loss', 0.059326171875)])\ndict_items([('train_loss', 0.059326171875)])\ndict_items([('train_loss', 0.07440185546875)])\ndict_items([('train_loss', 0.058746337890625)])\ndict_items([('train_loss', 0.060302734375)])\ndict_items([('val_loss', 0.058624267578125)])\ndict_items([('val_loss', 0.05865478515625)])\ndict_items([('val_loss', 0.058624267578125)])\ndict_items([('val_loss', 0.058624267578125)])\n","output_type":"stream"}]},{"cell_type":"code","source":"if 0:\n    from transformers.generation.utils import LogitsProcessorList, StoppingCriteriaList, GenerationConfig, ModelOutput\n    from transformers.generation.logits_process import LogitsProcessor\n\n    class InvalidScoreLogitsProcessor(LogitsProcessor):\n        def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n            if torch.isnan(scores).any() or torch.isinf(scores).any():\n                scores.zero_()\n                scores[..., 5] = 5e4\n            return scores\n\n\n    #-==========手动写predict代码.    \n    if 1:\n            keras_model.net.eval()\n    #         accelerator = keras_model.accelerator\n    #         keras_model.net,keras_model.loss_fn,keras_model.metrics_dict = keras_model.accelerator.prepare(\n    #             keras_model.net,keras_model.loss_fn,keras_model.metrics_dict)\n            max_length= 50\n            num_beams=1\n            do_sample=True\n            top_p=0.8\n            logits_processor=None\n            temperature=1\n\n            gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams, \"do_sample\": do_sample, \"top_p\": top_p,\n                          \"temperature\": temperature, \"logits_processor\": logits_processor}\n            with accelerator.autocast() , torch.no_grad():\n\n                    query='梦中情炉'\n                    history=[]\n                    prompt = tokenizer.build_prompt(query, history)\n                    print('我们输入的prompt是',prompt)\n                    prompt = cfg.source_prefix + prompt\n                    a_ids=tokenizer.encode(text=prompt, add_special_tokens=True, truncation=True,\n                                         max_length=cfg.max_source_length)\n                    b_ids = tokenizer.encode(text='', add_special_tokens=False, truncation=True,\n                                         max_length=cfg.max_target_length)\n                    print(b_ids)\n                    input_ids = a_ids + b_ids + [tokenizer.eos_token_id]\n    #                 shuru=[64790, 64792,   790, 30951,   517, 30910, 30939, 30996]\n                    input_ids=torch.tensor(input_ids).view(1,-1)\n                    print(inputs,9999999999999999999999)\n\n    #                 print(batch[\"input_ids\"][:,:20])\n                    a=keras_model.net.generate(input_ids=input_ids.cuda(), **gen_kwargs)\n    #                 print(a)\n                    shuchu=tokenizer.decode(a[0])\n                    print('=============================================================')\n                    print(shuchu)\n\n\n\n\n\n\n                    if 0:\n                        history=None\n\n                        if history is None:\n                                    history = []\n                        if logits_processor is None:\n                            logits_processor = LogitsProcessorList()\n                        logits_processor.append(InvalidScoreLogitsProcessor())\n                        gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams, \"do_sample\": do_sample, \"top_p\": top_p,\n                                      \"temperature\": temperature, \"logits_processor\": logits_processor, }\n\n\n                        prompt = tokenizer.build_prompt(query, history=history)\n                        print('输入prompt是',prompt)\n                        inputs = tokenizer([prompt], return_tensors=\"pt\")\n                        inputs = inputs.to('cuda')\n                        print(inputs,9999999999999999999999)\n                        outputs = keras_model.net.generate(**inputs, **gen_kwargs)\n                        outputs = outputs.tolist()[0][len(inputs[\"input_ids\"][0]):]\n                        response = tokenizer.decode(outputs)\n\n                        history = history + [(query, response)]\n                        print('返回')\n                        print(response)\n\n                    print('难道是generate代码不对???????????')\n\n                    print(input_ids.shape)\n                    a=keras_model.net(input_ids=input_ids).logits\n                    print(a,'debug!!!!!!!!!!!')\n                    print(a)\n\n\n            \n            \n            \n                \n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T05:04:00.246028Z","iopub.execute_input":"2023-08-17T05:04:00.246611Z","iopub.status.idle":"2023-08-17T05:04:00.397323Z","shell.execute_reply.started":"2023-08-17T05:04:00.246567Z","shell.execute_reply":"2023-08-17T05:04:00.394970Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m27\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m24 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2m│   │   \u001b[0mgen_kwargs = {\u001b[33m\"\u001b[0m\u001b[33mmax_length\u001b[0m\u001b[33m\"\u001b[0m: max_length, \u001b[33m\"\u001b[0m\u001b[33mnum_beams\u001b[0m\u001b[33m\"\u001b[0m: num_beams, \u001b[33m\"\u001b[0m\u001b[33mdo_sample\u001b[0m\u001b[33m\"\u001b[0m: do_    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m│   │   │   │   │     \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mtemperature\u001b[0m\u001b[33m\"\u001b[0m: temperature, \u001b[33m\"\u001b[0m\u001b[33mlogits_processor\u001b[0m\u001b[33m\"\u001b[0m: logits_processor}     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m27 \u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m accelerator.autocast() , torch.no_grad():                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mquery=\u001b[33m'\u001b[0m\u001b[33m梦中情炉\u001b[0m\u001b[33m'\u001b[0m                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhistory=[]                                                                  \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mNameError: \u001b[0mname \u001b[32m'accelerator'\u001b[0m is not defined\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">27</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>gen_kwargs = {<span style=\"color: #808000; text-decoration-color: #808000\">\"max_length\"</span>: max_length, <span style=\"color: #808000; text-decoration-color: #808000\">\"num_beams\"</span>: num_beams, <span style=\"color: #808000; text-decoration-color: #808000\">\"do_sample\"</span>: do_    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">\"temperature\"</span>: temperature, <span style=\"color: #808000; text-decoration-color: #808000\">\"logits_processor\"</span>: logits_processor}     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>27 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> accelerator.autocast() , torch.no_grad():                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>query=<span style=\"color: #808000; text-decoration-color: #808000\">'梦中情炉'</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>history=[]                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'accelerator'</span> is not defined\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"#-==========手动写predict代码.    \nif 0:\n        keras_model.net.eval()\n        accelerator = keras_model.accelerator\n        keras_model.net,keras_model.loss_fn,keras_model.metrics_dict = keras_model.accelerator.prepare(\n            keras_model.net,keras_model.loss_fn,keras_model.metrics_dict)\n        \n        with accelerator.autocast() , torch.no_grad():\n            for batch in dl_train:\n                print(batch[\"input_ids\"].shape)\n#                 print(batch[\"input_ids\"])\n                print(batch[\"input_ids\"][:1,])\n                a=keras_model.net(input_ids=batch[\"input_ids\"][:1,].cuda(),labels=batch[\"labels\"][:1,].cuda()).logits\n                print(a,'debug!!!!!!!!!!!')\n                print(a.shape)\n                break","metadata":{"execution":{"iopub.status.busy":"2023-08-17T05:23:52.874408Z","iopub.execute_input":"2023-08-17T05:23:52.874797Z","iopub.status.idle":"2023-08-17T05:23:53.578733Z","shell.execute_reply.started":"2023-08-17T05:23:52.874759Z","shell.execute_reply":"2023-08-17T05:23:53.577448Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"torch.Size([2, 256])\ntensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754, 54532, 54873, 54679, 31514,    13,\n            13, 55437, 31211, 30910, 47132, 54623, 56754, 31873, 39741, 56093,\n         55823, 32715, 12852,   349,  5130,   298, 31155,    13, 36037, 54640,\n         32769, 30925,  4226, 64569, 34030, 32549, 55059, 55090, 32715, 31155,\n            13, 12852,   349,  5130,   298, 32103, 54645, 54591, 56093, 55823,\n         56754, 31211, 35886, 31123, 54591, 54571, 31123, 54591, 54858, 31155,\n            13, 54790, 54536, 12852,   349, 54530, 50745, 31123, 32106,  5130,\n           298, 54530, 35752, 31123, 32187, 32233, 32824, 31123, 54716, 54619,\n         55932, 54703, 31155,    13, 31672, 32233, 32032, 31623, 54536, 56548,\n         32365, 55058, 55466, 37358, 54891, 32547, 54835, 54653, 35528, 47132,\n         54623, 56754, 31155,     2,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\ntensor([[[-10.7344, -10.7344,   0.4717,  ..., -10.7266, -10.7344, -10.7344],\n         [-12.5781, -12.5859,   2.3027,  ..., -12.5781, -12.5781, -12.5781],\n         [ -6.9180,  -6.9180,  -3.5332,  ...,  -6.9180,  -6.9180,  -6.9180],\n         ...,\n         [  9.1875,   9.1797,  -0.5400,  ...,   9.1875,   9.1875,   9.1875],\n         [  9.1953,   9.1953,  -0.6509,  ...,   9.2031,   9.1953,   9.1953],\n         [  9.1875,   9.1875,  -0.6235,  ...,   9.1953,   9.1953,   9.1953]]],\n       device='cuda:0') debug!!!!!!!!!!!\ntorch.Size([1, 256, 65024])\n","output_type":"stream"}]},{"cell_type":"code","source":"#-==========手动写predict代码.    ################自己写generate\nif 1:\n        keras_model.net.eval()\n        accelerator = keras_model.accelerator\n        keras_model.net,keras_model.loss_fn,keras_model.metrics_dict = keras_model.accelerator.prepare(\n            keras_model.net,keras_model.loss_fn,keras_model.metrics_dict)\n        \n        with accelerator.autocast() :\n            for batch in dl_val:\n                max_length= 50\n                num_beams=1\n                do_sample=True\n                top_p=0.8\n                logits_processor=None\n                temperature=1\n                \n                \n#                 print(list(dl_val)[0])\n                query, answer = '梦中情炉', ''\n                max_seq_length = cfg.max_source_length + cfg.max_target_length\n                history = examples[cfg.history_column][i] if cfg.history_column is not None else None\n                prompt = tokenizer.build_prompt(query, history)\n                print('prompt',prompt)\n                prompt = cfg.source_prefix + prompt\n                a_ids = tokenizer.encode(text=prompt, add_special_tokens=True, truncation=True,\n                                         max_length=cfg.max_source_length)\n                b_ids = tokenizer.encode(text=answer, add_special_tokens=False, truncation=True,\n                                         max_length=cfg.max_target_length)\n                print(b_ids,'b_ids')\n                context_length = len(a_ids)\n                input_ids = a_ids + b_ids + [tokenizer.eos_token_id]\n                print('context_length',context_length)\n                labels = [tokenizer.pad_token_id] * context_length + b_ids + [tokenizer.eos_token_id]\n                print(labels,'labels')\n                pad_len = max_seq_length - len(input_ids)\n                input_ids = input_ids + [tokenizer.pad_token_id] * pad_len\n                print('有用的len',len(labels))\n                useful=len(labels)\n                useful_length=useful\n                labels = labels + [tokenizer.pad_token_id] * pad_len\n                print('labels2',labels)\n                labels = [(l if l != tokenizer.pad_token_id else -100) for l in labels]\n                print('labels3',labels)\n                input_ids=torch.tensor(input_ids).view(1,-1)\n                print(input_ids)\n                print('打印labels',)\n                print(batch[\"labels\"][:1,])\n                print('打印inputs',)\n                print(batch[\"input_ids\"][:1,])\n                \n                while 1:\n                    if useful_length>max_length:# 每生成一个字, 这个计数器就加加.\n                        print(tokenizer.decode(input_ids[0]))\n                        print('over')\n                        break\n                    print('每一个轮次的输入',input_ids)\n                    #=============理解了输出过程, 自己实现贪心输出即可.\n                    a=keras_model.net(input_ids=input_ids.cuda(),labels=batch[\"labels\"][:1,].cuda() ) ########=好奇怪label 必须写才行..........\n                    print(a.loss.item(),8888888888888888888888888888)\n                    \n                    a=a.logits\n#                     print('输入个数',input_ids.shape)\n                    \n                    a=torch.argmax(a, dim=-1)\n                    print(a,'中间过程')\n                    a=a[0,useful_length]\n#                     print('生成一个字编码',a,'汉字',tokenizer.decode(a))\n                    [useful_length]\n                    input_ids[0,useful_length]=a\n                    useful_length+=1\n                    \n                \n                \n#                 print(a,'debug!!!!!!!!!!!')\n#                 print('输出概率的shape',a.shape)\n                break","metadata":{"execution":{"iopub.status.busy":"2023-08-17T06:32:38.618583Z","iopub.execute_input":"2023-08-17T06:32:38.619272Z","iopub.status.idle":"2023-08-17T06:32:54.421141Z","shell.execute_reply.started":"2023-08-17T06:32:38.619222Z","shell.execute_reply":"2023-08-17T06:32:54.419915Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"prompt [Round 1]\n\n问：梦中情炉\n\n答：\n[] b_ids\ncontext_length 19\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2] labels\n有用的len 20\nlabels2 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nlabels3 [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\ntensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n打印labels\ntensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 30910,\n         47132, 54623, 56754, 31873, 39741, 56093, 55823, 32715, 12852,   349,\n          5130,   298, 31155,    13, 36037, 54640, 32769, 30925,  4226, 64569,\n         34030, 32549, 55059, 55090, 32715, 31155,    13, 12852,   349,  5130,\n           298, 32103, 54645, 54591, 56093, 55823, 56754, 31211, 35886, 31123,\n         54591, 54571, 31123, 54591, 54858, 31155,    13, 54790, 54536, 12852,\n           349, 54530, 50745, 31123, 32106,  5130,   298, 54530, 35752, 31123,\n         32187, 32233, 32824, 31123, 54716, 54619, 55932, 54703, 31155,    13,\n         31672, 32233, 32032, 31623, 54536, 56548, 32365, 55058, 55466, 37358,\n         54891, 32547, 54835, 54653, 35528, 47132, 54623, 56754, 31155,     2,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100]])\n打印inputs\ntensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211, 30910,\n         47132, 54623, 56754, 31873, 39741, 56093, 55823, 32715, 12852,   349,\n          5130,   298, 31155,    13, 36037, 54640, 32769, 30925,  4226, 64569,\n         34030, 32549, 55059, 55090, 32715, 31155,    13, 12852,   349,  5130,\n           298, 32103, 54645, 54591, 56093, 55823, 56754, 31211, 35886, 31123,\n         54591, 54571, 31123, 54591, 54858, 31155,    13, 54790, 54536, 12852,\n           349, 54530, 50745, 31123, 32106,  5130,   298, 54530, 35752, 31123,\n         32187, 32233, 32824, 31123, 54716, 54619, 55932, 54703, 31155,    13,\n         31672, 32233, 32032, 31623, 54536, 56548, 32365, 55058, 55466, 37358,\n         54891, 32547, 54835, 54653, 35528, 47132, 54623, 56754, 31155,     2,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n14.6796875 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30954, 30954,    13,    13,    13, 48620, 54296, 30932, 30932, 49294,\n         54296, 54296, 54296, 64715, 64715, 64715, 64715, 60069, 60069, 60069,\n         60069, 60069, 60069, 60069, 60069, 60069, 60069, 60069, 60069, 60069,\n         60069, 60069, 60069, 60069, 60069, 60069, 60069, 62249, 62249, 62249,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 48705, 48705, 48705, 51767, 51767, 51767, 51767,\n         51767, 51767, 51767, 51767, 51767, 51767, 51767, 51767, 51767, 51767,\n         51767, 51767, 51767, 51767, 51767, 51767, 51767, 51767, 51767, 51767,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         59801, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n12.9375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13,    13,    13,    13, 54296, 54296, 56177, 56177, 54296,\n         30954, 54296, 54296, 54296, 54296,    13,    13,    13,    13,    13,\n            13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13, 48705, 48705, 48705, 48705, 40715, 40715, 40715, 52662, 52662,\n         52662, 52662, 48705, 48705, 52662, 52662, 52662, 52662, 52662, 52662,\n         52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662,\n         52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662,\n         52662, 52662, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705,\n         48705, 48705, 48705, 60866, 60866, 53300, 53300, 53300, 53300, 59801,\n         53300, 53300, 53300, 53300, 53300, 53300, 53300, 53300, 53300, 53300,\n         53300, 53300, 53300, 53300, 53300, 53300, 53300, 53300, 53300, 53300,\n         53300, 53300, 53300, 53300, 53300, 53300, 53300, 53300, 53300, 53300,\n         53300, 61650, 61650, 61650, 61650, 61650, 54267, 54267, 61650, 61650,\n         61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650,\n         61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650,\n         61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650,\n         61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650,\n         61650, 61650, 61650, 61650, 61650, 61650]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.8671875 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13,    13,    13,    13,    13,    13, 56802, 56802, 29112,\n         52662, 52662, 52662, 52662, 52662, 52662, 47561, 47561, 47561, 52662,\n         52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662,\n         52662, 52662, 52662,    13,    13,    13, 52662, 52662, 52662, 52662,\n         52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662,\n         52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662,\n         52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662,\n         52662, 52662, 52662, 52662, 52662, 54440, 54440, 54440, 54440, 58773,\n         58773, 58773, 58773, 58773, 58773, 58773, 58773, 58773, 58773, 43499,\n         43499, 43499, 43499, 43499, 43499, 43499, 43499, 43499, 43499, 43499,\n         43499, 43499, 43499, 43499, 43499, 43499, 43499, 43499, 43499, 43499,\n         43499, 43499, 43499, 43499, 62554, 62554, 62554, 50319, 50319, 43499,\n         43499, 43499, 43499, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 40098, 40098, 40098, 40098, 40098,\n         40098, 40098, 40098, 40098, 40098, 40098, 61650, 61650, 61650, 61650,\n         61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650,\n         61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650,\n         61650, 61650, 61650, 61650, 61650, 61650]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n14.765625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132,    13,    13,    13,    13, 34113, 56802, 60647,\n         50957, 28669, 28669, 28669, 28669, 63762, 63762, 64715, 64715, 64715,\n         64715, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662,\n         52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662, 52662,\n         52662, 52662, 52662, 52662, 48705, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         43499, 59583, 59583, 59583, 59583, 59583, 59583, 59583, 59583, 59583,\n         59583, 59583, 59583, 59583, 59583, 59583, 59583, 59583, 62554, 62554,\n         62554, 62554, 59583, 62554, 62554, 62554, 62554, 59583, 59583, 59583,\n         59583, 59583, 59583, 59583, 59583, 59583, 59583, 59583, 59583, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 54267, 54267,\n         54267, 54267, 54267, 54267, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         64715, 64715, 61650, 61650, 64715, 64715, 64715, 64715, 64715, 64715,\n         64715, 64715, 64715, 64715, 64715, 61650]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n15.015625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955,    13,    13, 31155, 31155, 50957, 50957,\n         60647, 50957, 50957, 28669, 27991, 27991, 27991, 27991, 27991, 60999,\n         60999, 60999, 60999, 60999, 60999, 60999, 60999, 60999, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249,    13,    13,    13,    13,    13, 62249, 62249,\n         48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 48705, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 40518, 40518, 40518, 62249, 62249, 62249,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 62554, 62554, 62554, 62554, 62554, 62554,\n         62554, 62554, 62554, 62554, 62554, 62554, 62554, 62554, 62554, 62554,\n         62554, 62554, 62554, 62554, 62554, 62554, 62554, 62554, 62554, 62554,\n         62554, 62554, 62554, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 59801, 59801, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 59801, 59801, 59801,\n         59801, 54267, 59801, 59801, 59801, 54267, 59801, 59801, 59801, 59801,\n         59801, 59801, 61650, 61650, 61650, 61650, 61650, 61650, 61650, 61650,\n         61650, 61650, 61650, 61650, 61650, 61650]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n14.9140625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955,    13,    13, 31155, 31155, 57679,\n         50957, 60647, 60647, 60647, 27991, 46316, 46316, 46316, 27991, 27991,\n         63248, 58751, 58751, 60999, 60999, 63517, 63517, 63517, 60999, 52662,\n         52929, 52929, 52929, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249,    13,    13,    13,    13,\n            13,    13,    13,    13,    13, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 62554, 62554, 62554, 62554, 62554, 62554, 62554, 62554,\n         62554, 62554, 62554, 62554, 62554, 62554, 62554, 62554, 62554, 62554,\n         62554, 62554, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 59801, 54267, 62924,\n         62924, 62924, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 62924, 62924, 62924, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 59801, 62924, 62924, 54267, 54267, 54267, 54267,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 61650, 61650, 61650, 61650, 61650]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n14.9921875 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132,    13,    13,    13, 31155,\n         57679, 50957, 60647, 60647, 60647, 46316, 46316, 46316, 46316, 46316,\n         58745, 58745, 58751, 58751, 58751, 63517, 63517, 63517, 47339, 47339,\n         60999, 58650, 52929, 52929, 52929, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249,    13,    13,    13,    13,    13,\n            13,    13,    13,    13,    13,    13, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 43499, 27991,\n         27991, 27991, 27991, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 54267, 54267, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 59801, 59801, 59801, 59801, 59801, 59801, 59801,\n         59801, 59801, 59801, 59801, 59801, 59801, 59801, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 44585, 44585,\n         44585, 44585, 44585, 44585, 44585, 44585, 59801, 59801, 59801, 59801,\n         44585, 44585, 59801, 59801, 59801, 44585, 44585, 44585, 59801, 59801,\n         59801, 59801, 44585, 44585, 44585, 44585, 44585, 44585, 44585, 44585,\n         44585, 44585, 44585, 44585, 44585, 44585]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n15.0234375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         31155, 57679, 50957, 50957, 58631, 60647, 58631, 58631, 41030, 41030,\n         41030, 41030, 41030, 58751, 58751, 58751, 58751, 63517, 47339, 47339,\n         60999, 60999, 46316, 63517, 63517, 62495, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249,    13,    13,    13,\n            13,    13,    13,    13,    13,    13,    13, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 46316, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 27991,\n         27991, 27991, 27991, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         59801, 59801, 59801, 62924, 62924, 62924, 62924, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 44585, 44585, 44585, 44585,\n         44585, 44585, 44585, 44585, 44585, 44585, 44585, 44585, 44585, 44585,\n         44585, 44585, 44585, 44585, 44585, 44585, 44585, 44585, 44585, 44585,\n         61814, 44585, 44585, 44585, 44585, 44585, 44585, 44585, 44585, 44585,\n         44585, 44585, 44585, 44585, 44585, 44585]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n15.09375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13, 31404,\n            13, 31155, 49168, 55977, 56498, 58631, 60647, 60647, 41030, 41030,\n         41030, 41030, 41030, 41030, 58751, 58751, 60999, 58751, 58751, 60999,\n         62495, 63762, 63762, 63762, 63762, 63762, 62495, 62495, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249,    13,    13, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 46316, 46316, 46316, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 63196,\n         63196, 63196, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 54267, 54267, 54267, 54267, 54267, 62924, 62924, 54267, 54267,\n         54267, 44585, 44585, 44585, 44585, 44585, 44585, 62924, 62924, 44585,\n         44585, 44585, 44585, 62495, 62495, 44585, 44585, 44585, 62924, 62924,\n         62924, 62924, 62924, 62924, 62495, 61814, 61814, 61814, 44585, 44585,\n         62495, 62495, 62495, 62924, 62924, 62495]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n15.1015625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         31404,    13, 31155, 49168, 56498, 56498, 56498, 57679, 50180, 41030,\n         41030, 41030, 41030, 41030, 41030, 41030, 58751, 58751, 58751, 58751,\n         62495, 62495, 59942, 63762, 63762, 63762, 62495, 62495, 62495, 62495,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 46316, 43499, 43499,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 43499, 63196,\n         63196, 63196, 63196, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         43499, 43499, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 54267, 54267, 54267, 54267, 62924, 62924, 62924, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 62924, 62924, 62495,\n         62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495,\n         62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495,\n         62495, 62495, 62495, 62495, 62495, 62495]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n15.1171875 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         31404, 31404,    13, 56802, 49168, 56498,    13, 56498, 57679, 50180,\n         41030, 41030, 41030, 41030, 59237, 41030, 58751, 58751, 58751, 58751,\n         62495, 62495, 62495, 59942, 63762, 63762, 63762, 63517, 62495, 62495,\n         62495, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 43499,\n         43499, 43499, 43499, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 40518, 58650, 58650, 40518, 40518, 40518,\n         40518, 40518, 40518, 40518, 57636, 57636, 57636, 43499, 43499, 43499,\n         63196, 63196, 63196, 63196, 62924, 63196, 63196, 63196, 62924, 43499,\n         43499, 43499, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924, 62924,\n         62924, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 62495, 62495, 62495, 62495,\n         62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495,\n         62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495, 62495,\n         62495, 62495, 62495, 62495, 62495, 62495]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.0234375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13, 31123, 31123, 14094, 32371,    13, 58706, 58706, 60647,\n         60647, 60647, 60647, 60159, 64775, 60647, 60647, 60647, 60647, 60647,\n         56177, 39517, 39517, 39517, 39517, 41820, 41820, 63762, 54172, 54172,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 54157, 47723, 47723,\n         47723, 47723, 47723, 47723, 47723, 47723, 47723, 47723, 47723, 41340,\n         41340, 58650, 58650, 58650, 58650, 58650, 58650, 58650, 58650, 58650,\n         58650, 58650, 58650, 58650, 58650, 58650, 58650, 43499, 43499, 43499,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.4375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,    13, 31123,    13,    13,    13,    13,    13, 16143,\n         60647, 60647, 60647, 60647, 48895, 48895, 60647, 60647, 60647, 60647,\n         60647, 57519, 59982, 28912, 39517, 39517, 41820, 39517, 39517, 54172,\n         54172, 28912, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 58593, 48539, 48539, 54157, 54157, 54157,\n         47723, 47723, 47723, 47723, 47723, 47723, 47723, 47723, 41340, 41340,\n         41340, 41340, 41340, 58650, 58650, 58650, 58650, 58650, 58650, 58650,\n         58650, 58650, 58650, 58650, 58650, 42713, 42713, 42713, 42713, 42713,\n         53319, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.4609375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2,    13, 31123,    13,    13, 61598,    13,    13,\n         16143, 60647, 60647, 60647, 60647, 48895, 48895, 26840, 60647, 60647,\n         60647, 60647, 59982, 28912, 28912, 35275, 35275, 35275, 28912, 28912,\n         41186, 28912, 58791, 27991, 27991, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249,    13,    13, 62249, 62249,\n         62249, 62249, 62249, 62249, 58593, 48539, 48539, 48539, 48539, 54157,\n         54157, 54157, 54157, 54157, 54157, 54157, 54157, 54157, 54157, 54157,\n         54157, 54157, 54157, 54157, 54157, 58650, 58650, 58650, 58650, 58650,\n         58650, 58650, 58650, 53319, 53319, 53319, 42713, 42713, 53319, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13, 31123,    13, 33338, 64706,    13,\n            13,    13, 60647, 60647, 60647, 60647, 48895, 48895, 26840, 60647,\n         60647, 60647, 60647, 59982, 28912, 35275, 35275, 35275, 35275, 35275,\n         28912, 28912, 58446, 27991, 27991, 27991, 27991, 27991, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 43499, 43499, 48539, 48539, 48539, 48539,\n         48539, 54157, 54157, 54157, 54157, 54157, 54157, 54157, 54157, 54157,\n         54157, 54157, 54157, 54157, 54157, 54157, 54157, 54157, 62862, 62862,\n         62862, 62862, 62862, 62862, 62862, 62862, 42713, 42713, 42713, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.515625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,    13,    13,    13, 33338, 64706,\n            13,    13,    13, 46127, 60647, 60647, 61449, 52293, 52293, 63762,\n         60647, 48014, 48014, 60647, 63762, 63762, 35275, 35275, 35275, 35275,\n         35275, 28912, 64715, 64715, 64715, 27991, 27991, 27991, 27991, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 42713, 42713, 43499, 43499, 43499, 43499,\n         43499, 43499, 43499, 58723, 58723, 58723, 58723, 54157, 54157, 54157,\n         54157, 54157, 54157, 54157, 54157, 54157, 54157, 54157, 54157, 62862,\n         62862, 60048, 60048, 62862, 62862, 62862, 62862, 42713, 42713, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.765625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,    13,    13,    13, 50957,\n         64706,    13,    13,    13, 46127, 60647, 60647, 63762, 63762, 63762,\n         62495, 62495, 48014, 48014, 60647, 63762, 63762, 35275, 35275, 35275,\n         35275, 35275, 39517, 58791, 64715, 64715, 64715, 27991, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 42713, 42713, 42713, 42713, 42713, 42713,\n         43499, 43499, 43499, 43499, 58723, 58723, 58723, 58723, 58723, 58723,\n         58723, 58723, 58723, 54157, 54157, 54157, 54157, 54157, 60048, 60048,\n         60048, 60048, 60048, 60048, 60048, 60048, 62862, 42713, 42713, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319,\n         53319, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n14.015625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,    13,     2, 56802,\n          5995, 16143,    13,    13, 28529, 56589, 46127, 63762, 63762, 63762,\n         62495, 62495, 42302, 48014, 48014, 48014, 60647, 63762, 35275, 35275,\n         35275, 35275, 35275, 35275, 58791, 64715, 64715, 64715, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 42713, 42713, 42713, 42713, 42713,\n         43499, 43499, 43499, 43499, 43499, 58723, 58723, 58723, 58723, 58723,\n         58723, 58723, 58723, 58723, 58723, 58723, 58723, 60048, 60048, 60048,\n         60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713, 42713,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n14.015625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,  6512,\n         57679,  5995, 16143,    13, 31404, 28529, 56589, 46127, 63762, 63762,\n         63762, 62495, 42302, 42302, 42302, 48014, 48014, 60647, 63762, 35275,\n         35275, 35275, 35275, 35275, 35275, 58791, 64715, 64715, 64715, 27991,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 42713, 42713, 42713, 42713,\n         43499, 43499, 43499, 43499, 43499, 43499, 43499, 58723, 58723, 58723,\n         58723, 58723, 58723, 58723, 58723, 58723, 60048, 60048, 60048, 60048,\n         60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 63634,\n         63634, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n14.078125 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n          6512,    13,  5995,    13, 54693, 31404, 28529, 56589, 47867, 63762,\n         63762, 63762, 42302, 42302, 42302, 42302, 19103, 48014, 52738, 63762,\n         35275, 35275, 35275, 35275, 35275, 35275, 62495, 64715, 64715, 64715,\n         27991, 27991, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 42713, 42713,\n         42713, 43499, 43499, 43499, 43499, 43499, 43499, 43499, 58593, 58723,\n         58723, 58723, 58723, 58723, 58723, 58723, 60048, 60048, 60048, 60048,\n         60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048,\n         60048, 60048, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n14.015625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n            13,  6512,    13,  4559,    13, 54693, 54693, 28529, 31695,   236,\n         14143, 38352, 38352, 63762, 42302, 42302, 19103, 19103, 19103, 52738,\n         48620, 35275, 35275, 35275, 35275, 35275, 35275, 26512, 64715, 64715,\n         64715, 64715, 27991, 27991, 27991, 27991, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 42713,\n         42713, 42713, 43499, 43499, 43499, 43499, 43499, 55382, 58593, 58593,\n         58723, 58723, 58723, 58723, 58723, 58723, 58723, 60048, 60048, 60048,\n         60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048,\n         60048, 60048, 60048, 53319, 53319, 53319, 53319, 53319, 53319, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.8984375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n             2,    13,  6512,    13,  4559, 56707, 54693, 48027, 28529,   775,\n           236,   236, 38352, 57220, 58773,    13,    13,    13, 19103, 19103,\n         56177, 48620, 48620, 35275, 35275, 35275, 35275, 35275, 26512, 64715,\n         64715, 64715, 64715, 27991, 27991, 38352, 27991, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 18472, 62249, 62249,\n         42713, 42713, 42713, 42713, 42713, 40715, 55382, 55382, 55382, 55382,\n         58723, 58723, 58723, 58723, 58723, 58723, 58723, 58723, 60048, 60048,\n         60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048,\n         60048, 60048, 60048, 60048, 53319, 53319, 53319, 53319, 53319, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13,    13,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.796875 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n             2,     2,    13, 54622,    13,  4559, 37070, 30338, 53209,    13,\n           775,   236,   236, 57220, 57220,    13,    13,    13,    13,    13,\n            13, 56177, 48620, 48620, 35275, 35275, 35275, 35275, 35275, 26512,\n         62495, 64715, 64715, 64715, 38352, 38352, 38352, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 18472, 18472, 18472, 62249,\n         62249, 42713, 42713, 42713, 42713, 40715, 40715, 40715, 40715, 40715,\n         55382, 58723, 58723, 58723, 58723, 58723, 58723, 58723, 58723, 58723,\n         60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048,\n         60048, 60048, 60048, 60048, 60048, 53319, 53319, 53319, 53319, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13,    13,    13,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.703125 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n             2,     2,    13,    13, 54622,    13,  4559, 37070, 30338, 49074,\n            13, 31695,   236, 57220, 57220, 57220,    13,    13,    13,    13,\n            13,    13, 56177, 48620, 48620, 35275, 35275, 35275, 35275, 35275,\n         26512, 62495, 64715, 64715, 38352, 38352, 38352, 38352, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 18472, 62249, 62249, 62249,\n         62249, 62249, 42713, 42713, 42713, 40715, 40715, 40715, 40715, 40715,\n         40715, 40715, 58723, 58723, 58723, 58723, 58723, 58723, 58723, 58723,\n         58723, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048,\n         60048, 60048, 60048, 60048, 60048, 60048, 60048, 53319, 53319, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13,    13,    13,    13,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.5859375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n             2,     2,    13,    13,    13, 54622,    13,  4559, 56707, 30338,\n         49074, 55353, 31695, 31695, 57220, 57220, 57220, 57220,    13,    13,\n            13,    13,    13,    13, 42713, 48620, 43852, 43852, 35275, 35275,\n         51439, 60623, 43852, 64715, 38352, 38352, 38352, 38352, 38352, 62249,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 18472, 18472, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 40715, 40715, 40715, 40715, 40715,\n         40715, 27410, 27410, 58723, 58723, 58723, 58723, 58723, 58723, 58723,\n         58723, 58723, 60048, 60048, 60048, 60048, 60048, 60048, 60048, 60048,\n         60048, 60048, 60048, 60048, 60048, 60048, 60048, 53319, 53319, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13,    13,    13,    13,    13,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.40625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n             2,     2,    13,    13,    13,    13, 54622,    13,  2723, 56707,\n         30992, 30992, 55353, 31695, 31695, 57220, 57220, 57220, 57220, 57220,\n            13,    13,    13,    13,    13, 42713, 48620, 43852, 43852, 43852,\n         43852, 43852, 43852, 43852, 38352, 38352, 38352, 38352, 38352, 38352,\n         62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 18472, 18472, 18472, 18472, 62249,\n         62249, 18472, 18472, 62249, 54245, 54245, 40715, 40715, 40715, 40715,\n         40715, 27410, 27410, 27410, 58723, 58723, 58723, 58723, 58723, 58723,\n         58723, 58723, 58723, 60048, 60048, 60048, 60048, 60048, 60048, 60048,\n         60048, 60048, 60048, 60048, 60048, 59490, 59490, 59490, 59490, 53319,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13,    13,    13,    13,    13,    13,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n13.15625 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n             2,     2,    13,    13,    13,    13,    13, 54622,    13,  2723,\n         54798, 30992, 54693, 28529, 30932, 31695, 57220, 57220, 57220, 57220,\n         57220, 57220,    13,    13,    13,    13,    13, 48620, 43852, 43852,\n         43852, 43852, 43852, 43852, 43852, 38352, 38352, 38352, 38352, 38352,\n         38352, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 62249, 62249, 18472, 18472, 18472, 54245, 54245,\n         54245, 18472, 18472, 54157, 54245, 54245, 54245, 54245, 40715, 40715,\n         40715, 27410, 27410, 27410, 27410, 58723, 58723, 58723, 58723, 58723,\n         58723, 58723, 58723, 34163, 34163, 34163, 34163, 34163, 60048, 60048,\n         60048, 60048, 60048, 60048, 59490, 59490, 59490, 59490, 59490, 59490,\n         53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 53319, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13,    13,    13,    13,    13,    13,    13,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n12.8984375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n             2,     2,    13,    13,    13,    13,    13,    13, 54622,    13,\n          2723, 54798, 55746,  1267, 28529, 30932, 22659, 57220, 57220, 57220,\n         57220, 57220,    13,    13,    13,    13,    13,    13, 18472, 43852,\n         43852, 43852, 43852, 43852, 43852, 54245, 54245, 54245, 38352, 38352,\n         38352, 38352, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 62249, 54245, 54245, 54245, 18472, 54245, 54245, 54245,\n         54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245,\n         54245, 40715, 27410, 27410, 27410, 58723, 58723, 58723, 58723, 58723,\n         58723, 58723, 58723, 34163, 34163, 34163, 34163, 34163, 34163, 34163,\n         34163, 60048, 60048, 60048, 59490, 59490, 59490, 59490, 59490, 59490,\n         59490, 59490, 53319, 59490, 59490, 53319, 53319, 53319, 53319, 53319,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13,    13,    13,    13,    13,    13,    13,    13,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n12.6953125 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n             2,     2,    13,    13,    13,    13,    13,    13,    13, 37474,\n            13,  2723, 54798, 55746, 30992, 30932, 30932, 22659, 57220, 57220,\n         57220, 57220,    13,    13,    13,    13,    13,    13,    13,    13,\n         43852, 43852, 43852, 43852, 54245, 54245, 54245, 54245, 54245, 54245,\n         54245, 54245, 62249, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245,\n         54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245,\n         54245, 54245, 54245, 54245, 54245, 54245, 54245, 58723, 58723, 58723,\n         58723, 58723, 34163, 34163, 34163, 34163, 34163, 34163, 34163, 34163,\n         34163, 34163, 34163, 34163, 34163, 59490, 59490, 59490, 59490, 59490,\n         59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490,\n         59490, 59490, 59490, 59490, 59490, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13,    13,    13,    13,    13,    13,    13,    13,    13,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n12.609375 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n             2,     2,    13,    13,    13,    13,    13,    13,    13,    13,\n         37474, 31822,  2723, 42108, 55746,  5768, 30932, 30932, 22659, 57220,\n         57220, 57220, 57220,    13,    13,    13,    13,    13,    13,    13,\n            13, 38163, 43852, 43852, 43852, 54245, 54245, 54245, 54245, 54245,\n         54245, 54245, 54245, 62249, 62249, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245,\n         54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245,\n         54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 58723,\n         58723, 58723, 34163, 34163, 34163, 34163, 34163, 34163, 34163, 34163,\n         34163, 34163, 34163, 34163, 34163, 34163, 59490, 59490, 59490, 59490,\n         59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490,\n         59490, 59490, 59490, 59490, 59490, 59490, 59490, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n每一个轮次的输入 tensor([[64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n         54761, 31211, 47132, 54623, 56754,    13,    13, 55437, 31211,     2,\n         30954,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n         31404,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n            13,    13,    13,    13,    13,    13,    13,    13,    13,    13,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n12.4921875 8888888888888888888888888888\ntensor([[64790,   267,  1856,  1856, 30910, 30939, 30973, 50619, 50619, 50619,\n         30954, 30943, 31755, 55811,    13,    13, 47132, 30954, 30910,  1856,\n         30910,    13, 47132, 30955, 30955, 47132, 47132,    13,    13,    13,\n         30995,    13,     2, 47132,    13,     2,     2,     2,    13,    13,\n             2,     2,    13,    13,    13,    13,    13,    13,    13,    13,\n            13, 37474, 31822,  2723, 42108, 55746, 30992, 30932, 30932, 57220,\n         57220, 57220, 57220, 57220,    13,    13,    13,    13,    13,    13,\n            13, 38163, 38163, 43852, 43852, 54245, 54245, 54245, 54245, 54245,\n         54245, 54245, 54245, 54245, 54245, 62249, 62249, 62249, 62249, 62249,\n         62249, 62249, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245,\n         54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245,\n         54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245, 54245,\n         58723, 34163, 34163, 34163, 34163, 34163, 34163, 34163, 34163, 34163,\n         34163, 34163, 34163, 34163, 34163, 34163, 34163, 59490, 59490, 59490,\n         59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490,\n         59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490, 59490, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880,\n         57880, 57880, 57880, 57880, 57880, 57880, 57880, 57880, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267, 54267,\n         54267, 54267, 54267, 54267, 54267, 54267]], device='cuda:0') 中间过程\n[Round 1]\n\n问：梦中情炉\n\n答：:\n\n\n\n\n\n\n\n\n！\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nover\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.decode([13,    13,    13,    13,    13,\n         31404,])","metadata":{"execution":{"iopub.status.busy":"2023-08-17T06:26:36.773956Z","iopub.execute_input":"2023-08-17T06:26:36.774489Z","iopub.status.idle":"2023-08-17T06:26:36.785163Z","shell.execute_reply.started":"2023-08-17T06:26:36.774440Z","shell.execute_reply":"2023-08-17T06:26:36.784020Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"'\\n\\n\\n\\n\\n！'"},"metadata":{}}]}]}