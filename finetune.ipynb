{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kJN94Ed5DsqY",
        "outputId": "ecd25ab5-7e80-4c5c-c2e9-4d208e7f9fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ChatGLM-Tuning'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 163 (delta 74), reused 64 (delta 60), pack-reused 51\u001b[K\n",
            "Receiving objects: 100% (163/163), 8.03 MiB | 11.14 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "/content/ChatGLM-Tuning\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/peft.git (from -r requirements.txt (line 15))\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-lttlqent\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-lttlqent\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 4fd374e80d670781c0d82c96ce94d1215ff23306\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes==0.37.1 (from -r requirements.txt (line 2))\n",
            "  Downloading bitsandbytes-0.37.1-py3-none-any.whl (76.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.17.1 (from -r requirements.txt (line 3))\n",
            "  Downloading accelerate-0.17.1-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20.1,>=3.19.5 (from -r requirements.txt (line 6))\n",
            "  Downloading protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.27.1 (from -r requirements.txt (line 7))\n",
            "  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting icetk (from -r requirements.txt (line 8))\n",
            "  Downloading icetk-0.0.7-py3-none-any.whl (16 kB)\n",
            "Collecting cpm_kernels==1.0.11 (from -r requirements.txt (line 9))\n",
            "  Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.0.0+cu118)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.12.2)\n",
            "Collecting datasets==2.10.1 (from -r requirements.txt (line 14))\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.27.1->-r requirements.txt (line 7))\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.1->-r requirements.txt (line 7))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r requirements.txt (line 14)) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.10.1->-r requirements.txt (line 14))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r requirements.txt (line 14)) (1.5.3)\n",
            "Collecting xxhash (from datasets==2.10.1->-r requirements.txt (line 14))\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.10.1->-r requirements.txt (line 14))\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r requirements.txt (line 14)) (2023.4.0)\n",
            "Collecting aiohttp (from datasets==2.10.1->-r requirements.txt (line 14))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets==2.10.1->-r requirements.txt (line 14))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from icetk->-r requirements.txt (line 8)) (0.15.1+cu118)\n",
            "Collecting sentencepiece (from icetk->-r requirements.txt (line 8))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of icetk to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting icetk (from -r requirements.txt (line 8))\n",
            "  Downloading icetk-0.0.6-py3-none-any.whl (15 kB)\n",
            "  Downloading icetk-0.0.5-py3-none-any.whl (15 kB)\n",
            "  Downloading icetk-0.0.4-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 10)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 10)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 10)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 10)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 10)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.1->-r requirements.txt (line 10)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.1->-r requirements.txt (line 10)) (16.0.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.4.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.40.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 14)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 14)) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.10.1->-r requirements.txt (line 14))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets==2.10.1->-r requirements.txt (line 14))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets==2.10.1->-r requirements.txt (line 14))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets==2.10.1->-r requirements.txt (line 14))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets==2.10.1->-r requirements.txt (line 14))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 11)) (2.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 14)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 14)) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->-r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->icetk->-r requirements.txt (line 8)) (8.4.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 11)) (3.2.2)\n",
            "Building wheels for collected packages: peft\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.4.0.dev0-py3-none-any.whl size=56306 sha256=7584558ff43437800b4f674155e6fc21bc5772b4bf81df8eba1ba35a7dd1eaff\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sj5ylols/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "Successfully built peft\n",
            "Installing collected packages: tokenizers, sentencepiece, cpm_kernels, bitsandbytes, xxhash, protobuf, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, accelerate, peft, icetk\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery 3.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.19.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.15.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.17.1 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bitsandbytes-0.37.1 cpm_kernels-1.0.11 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 icetk-0.0.4 multidict-6.0.4 multiprocess-0.70.14 peft-0.4.0.dev0 protobuf-3.20.0 responses-0.18.0 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.27.1 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!git clone https://github.com/mymusise/ChatGLM-Tuning.git\n",
        "%cd  ChatGLM-Tuning\n",
        "!pip install -r requirements.txt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UF3YkxMMDsqc",
        "outputId": "165b3f6c-c478-4950-fc0b-5b69561d912a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting..: 100% 52002/52002 [00:00<00:00, 68841.85it/s]\n"
          ]
        }
      ],
      "source": [
        "!python cover_alpaca2jsonl.py \\\n",
        "    --data_path data/alpaca_data.json \\\n",
        "    --save_path data/alpaca_data.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rem5_CEdDsqd",
        "outputId": "5b1844f8-ac00-46dc-c858-eee178fc2e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset generator/default to /root/.cache/huggingface/datasets/generator/default-b6b8095638fbee26/0.0.0...\n",
            "Generating train split: 0 examples [00:00, ? examples/s]\n",
            "Downloading (…)okenizer_config.json: 100% 441/441 [00:00<00:00, 2.70MB/s]\n",
            "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
            "\n",
            "Downloading (…)enization_chatglm.py: 100% 17.0k/17.0k [00:00<00:00, 55.5MB/s]\n",
            "\n",
            "Downloading ice_text.model: 100% 2.71M/2.71M [00:00<00:00, 50.0MB/s]\n",
            "\n",
            "Downloading (…)lve/main/config.json: 100% 773/773 [00:00<00:00, 4.63MB/s]\n",
            "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
            "\n",
            "Downloading (…)iguration_chatglm.py: 100% 4.28k/4.28k [00:00<00:00, 13.1MB/s]\n",
            "\n",
            "Generating train split: 22 examples [00:11,  2.75 examples/s]\n",
            "  0% 22/52002 [00:00<07:45, 111.55it/s]\u001b[A\n",
            "Generating train split: 80 examples [00:11, 13.02 examples/s]\n",
            "Generating train split: 152 examples [00:11, 30.52 examples/s]\n",
            "Generating train split: 215 examples [00:11, 50.98 examples/s]\n",
            "Generating train split: 279 examples [00:11, 78.33 examples/s]\n",
            "Generating train split: 342 examples [00:11, 112.56 examples/s]\n",
            "Generating train split: 409 examples [00:11, 158.03 examples/s]\n",
            "Generating train split: 499 examples [00:11, 222.90 examples/s]\n",
            "Generating train split: 562 examples [00:12, 272.89 examples/s]\n",
            "Generating train split: 628 examples [00:12, 329.65 examples/s]\n",
            "Generating train split: 715 examples [00:12, 389.51 examples/s]\n",
            "  1% 720/52002 [00:01<01:25, 599.40it/s]\u001b[A\n",
            "Generating train split: 789 examples [00:12, 415.11 examples/s]\n",
            "Generating train split: 850 examples [00:12, 373.77 examples/s]\n",
            "Generating train split: 907 examples [00:12, 315.04 examples/s]\n",
            "Generating train split: 958 examples [00:13, 283.59 examples/s]\n",
            "Generating train split: 997 examples [00:13, 275.25 examples/s]\n",
            "Generating train split: 1030 examples [00:13, 221.11 examples/s]\n",
            "Generating train split: 1090 examples [00:13, 282.74 examples/s]\n",
            "Generating train split: 1185 examples [00:13, 408.73 examples/s]\n",
            "Generating train split: 1289 examples [00:13, 541.10 examples/s]\n",
            "Generating train split: 1391 examples [00:13, 651.56 examples/s]\n",
            "Generating train split: 1495 examples [00:14, 747.10 examples/s]\n",
            "Generating train split: 1596 examples [00:14, 814.81 examples/s]\n",
            "Generating train split: 1696 examples [00:14, 863.65 examples/s]\n",
            "Generating train split: 1800 examples [00:14, 911.19 examples/s]\n",
            "Generating train split: 1906 examples [00:14, 951.93 examples/s]\n",
            "  4% 1919/52002 [00:03<00:51, 969.73it/s]\u001b[A\n",
            "Generating train split: 2049 examples [00:14, 949.39 examples/s]\n",
            "Generating train split: 2158 examples [00:14, 983.04 examples/s]\n",
            "Generating train split: 2273 examples [00:14, 1024.50 examples/s]\n",
            "Generating train split: 2383 examples [00:14, 1043.89 examples/s]\n",
            "Generating train split: 2526 examples [00:15, 1002.34 examples/s]\n",
            "  5% 2567/52002 [00:04<00:50, 970.54it/s] \u001b[A\n",
            "Generating train split: 2674 examples [00:15, 992.55 examples/s] \n",
            "Generating train split: 2782 examples [00:15, 1009.74 examples/s]\n",
            "Generating train split: 2886 examples [00:15, 1015.66 examples/s]\n",
            "Generating train split: 2995 examples [00:15, 1030.89 examples/s]\n",
            "Generating train split: 3142 examples [00:15, 1007.23 examples/s]\n",
            "Generating train split: 3251 examples [00:15, 1024.38 examples/s]\n",
            "Generating train split: 3391 examples [00:15, 989.61 examples/s] \n",
            "Generating train split: 3495 examples [00:16, 1000.69 examples/s]\n",
            "  7% 3517/52002 [00:05<00:47, 1011.21it/s]\u001b[A\n",
            "Generating train split: 3640 examples [00:16, 982.44 examples/s] \n",
            "Generating train split: 3742 examples [00:16, 988.94 examples/s]\n",
            "Generating train split: 3848 examples [00:16, 1003.97 examples/s]\n",
            "Generating train split: 3958 examples [00:16, 1026.46 examples/s]\n",
            "Generating train split: 4094 examples [00:16, 976.36 examples/s] \n",
            "Generating train split: 4201 examples [00:16, 997.76 examples/s]\n",
            "Generating train split: 4310 examples [00:16, 1017.40 examples/s]\n",
            "Generating train split: 4415 examples [00:16, 1019.53 examples/s]\n",
            "Generating train split: 4521 examples [00:17, 1029.07 examples/s]\n",
            "Generating train split: 4661 examples [00:17, 986.20 examples/s] \n",
            "Generating train split: 4778 examples [00:17, 1032.20 examples/s]\n",
            "  9% 4802/52002 [00:06<00:44, 1049.15it/s]\u001b[A\n",
            "Generating train split: 4933 examples [00:17, 1030.29 examples/s]\n",
            "Generating train split: 5081 examples [00:17, 1013.62 examples/s]\n",
            " 10% 5117/52002 [00:06<00:46, 1010.37it/s]\u001b[A\n",
            "Generating train split: 5232 examples [00:17, 1008.40 examples/s]\n",
            "Generating train split: 5383 examples [00:17, 1004.26 examples/s]\n",
            "Generating train split: 5496 examples [00:18, 1031.31 examples/s]\n",
            "Generating train split: 5636 examples [00:18, 994.93 examples/s] \n",
            "Generating train split: 5743 examples [00:18, 1010.71 examples/s]\n",
            " 11% 5746/52002 [00:07<00:45, 1020.78it/s]\u001b[A\n",
            "Generating train split: 5888 examples [00:18, 992.84 examples/s] \n",
            "Generating train split: 6033 examples [00:18, 981.84 examples/s]\n",
            " 12% 6050/52002 [00:07<00:47, 960.98it/s]\u001b[A\n",
            "Generating train split: 6178 examples [00:18, 973.66 examples/s]\n",
            "Generating train split: 6286 examples [00:18, 984.65 examples/s]\n",
            "Generating train split: 6387 examples [00:18, 987.42 examples/s]\n",
            "Generating train split: 6532 examples [00:19, 974.72 examples/s]\n",
            " 13% 6556/52002 [00:08<00:48, 941.02it/s]\u001b[A\n",
            "Generating train split: 6656 examples [00:19, 922.35 examples/s]\n",
            "Generating train split: 6757 examples [00:19, 940.92 examples/s]\n",
            "Generating train split: 6861 examples [00:19, 960.33 examples/s]\n",
            "Generating train split: 6965 examples [00:19, 979.81 examples/s]\n",
            "Generating train split: 7106 examples [00:19, 940.22 examples/s]\n",
            "Generating train split: 7207 examples [00:19, 953.52 examples/s]\n",
            "Generating train split: 7314 examples [00:19, 981.69 examples/s]\n",
            "Generating train split: 7452 examples [00:20, 957.04 examples/s]\n",
            "Generating train split: 7560 examples [00:20, 984.24 examples/s]\n",
            "Generating train split: 7662 examples [00:20, 991.19 examples/s]\n",
            "Generating train split: 7768 examples [00:20, 1001.98 examples/s]\n",
            " 15% 7779/52002 [00:09<00:44, 1001.20it/s]\u001b[A\n",
            "Generating train split: 7906 examples [00:20, 968.30 examples/s] \n",
            "Generating train split: 8046 examples [00:20, 948.15 examples/s]\n",
            "Generating train split: 8147 examples [00:20, 961.97 examples/s]\n",
            "Generating train split: 8249 examples [00:20, 972.89 examples/s]\n",
            " 16% 8290/52002 [00:09<00:45, 956.47it/s]\u001b[A\n",
            "Generating train split: 8393 examples [00:21, 964.72 examples/s]\n",
            "Generating train split: 8506 examples [00:21, 1003.67 examples/s]\n",
            "Generating train split: 8641 examples [00:21, 963.93 examples/s] \n",
            "Generating train split: 8747 examples [00:21, 985.00 examples/s]\n",
            "Generating train split: 8867 examples [00:21, 1037.91 examples/s]\n",
            "Generating train split: 8973 examples [00:21, 1039.19 examples/s]\n",
            "Generating train split: 9110 examples [00:21, 986.59 examples/s] \n",
            "Generating train split: 9213 examples [00:21, 995.64 examples/s]\n",
            " 18% 9235/52002 [00:10<00:42, 1000.67it/s]\u001b[A\n",
            "Generating train split: 9368 examples [00:21, 1007.57 examples/s]\n",
            "Generating train split: 9481 examples [00:22, 1036.56 examples/s]\n",
            "Generating train split: 9611 examples [00:22, 975.14 examples/s] \n",
            "Generating train split: 9712 examples [00:22, 980.93 examples/s]\n",
            "Generating train split: 9858 examples [00:22, 974.21 examples/s]\n",
            "Generating train split: 9965 examples [00:22, 996.25 examples/s]\n",
            " 19% 9966/52002 [00:11<00:42, 993.85it/s]\u001b[A\n",
            "Generating train split: 10105 examples [00:22, 972.19 examples/s]\n",
            "Generating train split: 10218 examples [00:22, 1009.13 examples/s]\n",
            "Generating train split: 10326 examples [00:22, 1026.44 examples/s]\n",
            "Generating train split: 10475 examples [00:23, 1010.47 examples/s]\n",
            "Generating train split: 10592 examples [00:23, 1046.87 examples/s]\n",
            " 20% 10610/52002 [00:12<00:39, 1042.64it/s]\u001b[A\n",
            "Generating train split: 10728 examples [00:23, 992.90 examples/s] \n",
            "Generating train split: 10844 examples [00:23, 1027.72 examples/s]\n",
            "Generating train split: 10979 examples [00:23, 981.44 examples/s] \n",
            "Generating train split: 11098 examples [00:23, 818.75 examples/s]\n",
            "Generating train split: 11188 examples [00:23, 742.95 examples/s]\n",
            " 22% 11203/52002 [00:13<00:58, 702.64it/s]\u001b[A\n",
            "Generating train split: 11296 examples [00:24, 665.25 examples/s]\n",
            "Generating train split: 11384 examples [00:24, 642.45 examples/s]\n",
            "Generating train split: 11452 examples [00:24, 648.68 examples/s]\n",
            "Generating train split: 11539 examples [00:24, 621.41 examples/s]\n",
            " 22% 11541/52002 [00:13<01:07, 599.30it/s]\u001b[A\n",
            "Generating train split: 11621 examples [00:24, 591.25 examples/s]\n",
            "Generating train split: 11685 examples [00:24, 597.32 examples/s]\n",
            "Generating train split: 11767 examples [00:24, 576.94 examples/s]\n",
            "Generating train split: 11827 examples [00:25, 575.50 examples/s]\n",
            " 23% 11849/52002 [00:14<01:09, 578.71it/s]\u001b[A\n",
            "Generating train split: 11915 examples [00:25, 578.36 examples/s]\n",
            "Generating train split: 11976 examples [00:25, 582.67 examples/s]\n",
            "Generating train split: 12066 examples [00:25, 571.79 examples/s]\n",
            " 23% 12081/52002 [00:14<01:12, 553.30it/s]\u001b[A\n",
            "Generating train split: 12150 examples [00:25, 563.98 examples/s]\n",
            "Generating train split: 12237 examples [00:25, 564.68 examples/s]\n",
            "Generating train split: 12307 examples [00:25, 594.51 examples/s]\n",
            " 24% 12329/52002 [00:14<01:05, 605.25it/s]\u001b[A\n",
            "Generating train split: 12395 examples [00:26, 590.81 examples/s]\n",
            "Generating train split: 12456 examples [00:26, 593.64 examples/s]\n",
            "Generating train split: 12523 examples [00:26, 611.76 examples/s]\n",
            "Generating train split: 12607 examples [00:26, 585.03 examples/s]\n",
            "Generating train split: 12674 examples [00:26, 604.58 examples/s]\n",
            "Generating train split: 12764 examples [00:26, 597.83 examples/s]\n",
            " 25% 12764/52002 [00:15<01:05, 600.40it/s]\u001b[A\n",
            "Generating train split: 12850 examples [00:26, 587.70 examples/s]\n",
            "Generating train split: 12917 examples [00:26, 605.26 examples/s]\n",
            "Generating train split: 13000 examples [00:27, 569.65 examples/s]\n",
            " 25% 13010/52002 [00:16<01:09, 557.74it/s]\u001b[A\n",
            "Generating train split: 13092 examples [00:27, 578.85 examples/s]\n",
            "Generating train split: 13162 examples [00:27, 603.06 examples/s]\n",
            "Generating train split: 13258 examples [00:27, 612.24 examples/s]\n",
            " 26% 13270/52002 [00:16<01:02, 618.19it/s]\u001b[A\n",
            "Generating train split: 13344 examples [00:27, 595.30 examples/s]\n",
            "Generating train split: 13407 examples [00:27, 598.28 examples/s]\n",
            "Generating train split: 13471 examples [00:27, 605.47 examples/s]\n",
            "Generating train split: 13538 examples [00:27, 618.47 examples/s]\n",
            "Generating train split: 13624 examples [00:28, 597.95 examples/s]\n",
            "Generating train split: 13685 examples [00:28, 599.45 examples/s]\n",
            "Generating train split: 13774 examples [00:28, 595.62 examples/s]\n",
            "Generating train split: 13868 examples [00:28, 678.56 examples/s]\n",
            "Generating train split: 13971 examples [00:28, 768.54 examples/s]\n",
            "Generating train split: 14051 examples [00:28, 772.18 examples/s]\n",
            "Generating train split: 14148 examples [00:28, 826.41 examples/s]\n",
            "Generating train split: 14246 examples [00:28, 867.38 examples/s]\n",
            "Generating train split: 14357 examples [00:28, 934.29 examples/s]\n",
            "Generating train split: 14465 examples [00:29, 974.53 examples/s]\n",
            "Generating train split: 14570 examples [00:29, 992.99 examples/s]\n",
            " 28% 14570/52002 [00:18<00:37, 998.62it/s]\u001b[A\n",
            "Generating train split: 14715 examples [00:29, 977.51 examples/s]\n",
            "Generating train split: 14857 examples [00:29, 963.74 examples/s]\n",
            "Generating train split: 14959 examples [00:29, 977.44 examples/s]\n",
            " 29% 14971/52002 [00:18<00:37, 984.39it/s]\u001b[A\n",
            "Generating train split: 15103 examples [00:29, 962.56 examples/s]\n",
            "Generating train split: 15209 examples [00:29, 983.87 examples/s]\n",
            "Generating train split: 15351 examples [00:30, 966.93 examples/s]\n",
            "Generating train split: 15456 examples [00:30, 983.83 examples/s]\n",
            " 30% 15487/52002 [00:19<00:37, 984.81it/s]\u001b[A\n",
            "Generating train split: 15604 examples [00:30, 979.26 examples/s]\n",
            "Generating train split: 15745 examples [00:30, 963.26 examples/s]\n",
            " 30% 15783/52002 [00:19<00:37, 967.97it/s]\u001b[A\n",
            "Generating train split: 15890 examples [00:30, 963.42 examples/s]\n",
            "Generating train split: 15997 examples [00:30, 986.42 examples/s]\n",
            "Generating train split: 16151 examples [00:30, 994.85 examples/s]\n",
            " 31% 16188/52002 [00:19<00:36, 990.24it/s]\u001b[A\n",
            "Generating train split: 16301 examples [00:30, 993.18 examples/s]\n",
            "Generating train split: 16405 examples [00:31, 1003.08 examples/s]\n",
            "Generating train split: 16563 examples [00:31, 1018.99 examples/s]\n",
            "Generating train split: 16671 examples [00:31, 1029.46 examples/s]\n",
            "Generating train split: 16789 examples [00:31, 1064.94 examples/s]\n",
            "Generating train split: 16920 examples [00:31, 995.83 examples/s] \n",
            " 33% 16939/52002 [00:20<00:35, 1001.34it/s]\u001b[A\n",
            "Generating train split: 17064 examples [00:31, 981.42 examples/s]\n",
            "Generating train split: 17219 examples [00:31, 992.57 examples/s]\n",
            "Generating train split: 17331 examples [00:31, 1020.82 examples/s]\n",
            " 33% 17358/52002 [00:21<00:33, 1026.42it/s]\u001b[A\n",
            "Generating train split: 17476 examples [00:32, 1000.04 examples/s]\n",
            "Generating train split: 17594 examples [00:32, 1040.90 examples/s]\n",
            "Generating train split: 17701 examples [00:32, 1045.52 examples/s]\n",
            "Generating train split: 17856 examples [00:32, 1036.28 examples/s]\n",
            " 34% 17895/52002 [00:21<00:33, 1012.33it/s]\u001b[A\n",
            "Generating train split: 17998 examples [00:32, 1003.11 examples/s]\n",
            "Generating train split: 18145 examples [00:32, 994.60 examples/s] \n",
            "Generating train split: 18251 examples [00:32, 895.23 examples/s]\n",
            "Generating train split: 18347 examples [00:33, 727.95 examples/s]\n",
            "Generating train split: 18444 examples [00:33, 635.68 examples/s]\n",
            "Generating train split: 18518 examples [00:33, 593.62 examples/s]\n",
            "Generating train split: 18587 examples [00:33, 552.60 examples/s]\n",
            "Generating train split: 18649 examples [00:33, 566.44 examples/s]\n",
            "Generating train split: 18717 examples [00:33, 588.21 examples/s]\n",
            "Generating train split: 18778 examples [00:33, 591.83 examples/s]\n",
            " 36% 18778/52002 [00:22<00:56, 584.47it/s]\u001b[A\n",
            "Generating train split: 18841 examples [00:34, 599.39 examples/s]\n",
            "Generating train split: 18934 examples [00:34, 602.17 examples/s]\n",
            "Generating train split: 19007 examples [00:34, 562.37 examples/s]\n",
            "Generating train split: 19074 examples [00:34, 517.90 examples/s]\n",
            " 37% 19078/52002 [00:23<01:04, 507.48it/s]\u001b[A\n",
            "Generating train split: 19134 examples [00:34, 324.78 examples/s]\n",
            "Generating train split: 19184 examples [00:35, 249.39 examples/s]\n",
            "Generating train split: 19227 examples [00:35, 251.52 examples/s]\n",
            "Generating train split: 19266 examples [00:35, 251.63 examples/s]\n",
            " 37% 19266/52002 [00:24<02:16, 239.85it/s]\u001b[A\n",
            "Generating train split: 19306 examples [00:35, 272.05 examples/s]\n",
            "Generating train split: 19350 examples [00:35, 301.78 examples/s]\n",
            "Generating train split: 19390 examples [00:35, 316.24 examples/s]\n",
            "Generating train split: 19427 examples [00:36, 218.47 examples/s]\n",
            "Generating train split: 19462 examples [00:36, 198.24 examples/s]\n",
            "Generating train split: 19494 examples [00:36, 195.36 examples/s]\n",
            " 37% 19499/52002 [00:25<02:45, 195.94it/s]\u001b[A\n",
            "Generating train split: 19527 examples [00:36, 196.31 examples/s]\n",
            "Generating train split: 19571 examples [00:36, 241.66 examples/s]\n",
            "Generating train split: 19619 examples [00:36, 286.61 examples/s]\n",
            "Generating train split: 19675 examples [00:37, 272.95 examples/s]\n",
            "Generating train split: 19706 examples [00:37, 224.91 examples/s]\n",
            "Generating train split: 19734 examples [00:37, 213.78 examples/s]\n",
            "Generating train split: 19758 examples [00:37, 192.87 examples/s]\n",
            " 38% 19760/52002 [00:26<02:53, 186.28it/s]\u001b[A\n",
            "Generating train split: 19782 examples [00:37, 173.00 examples/s]\n",
            "Generating train split: 19814 examples [00:38, 181.57 examples/s]\n",
            "Generating train split: 19854 examples [00:38, 225.13 examples/s]\n",
            "Generating train split: 19958 examples [00:38, 406.43 examples/s]\n",
            "Generating train split: 20050 examples [00:38, 528.02 examples/s]\n",
            "Generating train split: 20145 examples [00:38, 561.55 examples/s]\n",
            "Generating train split: 20207 examples [00:38, 570.46 examples/s]\n",
            " 39% 20216/52002 [00:27<00:53, 591.75it/s]\u001b[A\n",
            "Generating train split: 20293 examples [00:38, 568.82 examples/s]\n",
            "Generating train split: 20356 examples [00:38, 582.05 examples/s]\n",
            "Generating train split: 20420 examples [00:39, 595.32 examples/s]\n",
            "Generating train split: 20504 examples [00:39, 579.76 examples/s]\n",
            "Generating train split: 20564 examples [00:39, 583.18 examples/s]\n",
            "Generating train split: 20628 examples [00:39, 594.31 examples/s]\n",
            "Generating train split: 20703 examples [00:39, 632.15 examples/s]\n",
            "Generating train split: 20771 examples [00:39, 642.07 examples/s]\n",
            "Generating train split: 20845 examples [00:39, 666.42 examples/s]\n",
            " 40% 20861/52002 [00:28<00:47, 650.21it/s]\u001b[A\n",
            "Generating train split: 20939 examples [00:39, 644.63 examples/s]\n",
            "Generating train split: 21034 examples [00:39, 617.76 examples/s]\n",
            " 40% 21058/52002 [00:29<00:51, 595.20it/s]\u001b[A\n",
            "Generating train split: 21129 examples [00:40, 619.11 examples/s]\n",
            "Generating train split: 21223 examples [00:40, 609.05 examples/s]\n",
            "Generating train split: 21285 examples [00:40, 610.40 examples/s]\n",
            "Generating train split: 21369 examples [00:40, 589.40 examples/s]\n",
            "Generating train split: 21435 examples [00:40, 600.94 examples/s]\n",
            "Generating train split: 21498 examples [00:40, 607.74 examples/s]\n",
            " 41% 21511/52002 [00:29<00:49, 614.52it/s]\u001b[A\n",
            "Generating train split: 21583 examples [00:40, 587.62 examples/s]\n",
            "Generating train split: 21646 examples [00:41, 588.43 examples/s]\n",
            "Generating train split: 21708 examples [00:41, 593.62 examples/s]\n",
            "Generating train split: 21796 examples [00:41, 588.02 examples/s]\n",
            " 42% 21814/52002 [00:30<00:51, 588.49it/s]\u001b[A\n",
            "Generating train split: 21883 examples [00:41, 581.91 examples/s]\n",
            "Generating train split: 21944 examples [00:41, 588.03 examples/s]\n",
            "Generating train split: 22033 examples [00:41, 568.03 examples/s]\n",
            "Generating train split: 22098 examples [00:41, 585.05 examples/s]\n",
            " 43% 22122/52002 [00:30<00:51, 584.35it/s]\u001b[A\n",
            "Generating train split: 22185 examples [00:41, 580.37 examples/s]\n",
            "Generating train split: 22273 examples [00:42, 579.39 examples/s]\n",
            "Generating train split: 22360 examples [00:42, 574.26 examples/s]\n",
            " 43% 22360/52002 [00:31<00:52, 569.95it/s]\u001b[A\n",
            "Generating train split: 22427 examples [00:42, 593.03 examples/s]\n",
            "Generating train split: 22515 examples [00:42, 587.40 examples/s]\n",
            "Generating train split: 22580 examples [00:42, 597.68 examples/s]\n",
            "Generating train split: 22655 examples [00:42, 555.31 examples/s]\n",
            "Generating train split: 22714 examples [00:42, 557.02 examples/s]\n",
            "Generating train split: 22771 examples [00:42, 558.82 examples/s]\n",
            " 44% 22783/52002 [00:32<00:52, 555.52it/s]\u001b[A\n",
            "Generating train split: 22852 examples [00:43, 548.78 examples/s]\n",
            "Generating train split: 22914 examples [00:43, 564.03 examples/s]\n",
            "Generating train split: 23000 examples [00:43, 632.31 examples/s]\n",
            "Generating train split: 23108 examples [00:43, 752.00 examples/s]\n",
            "Generating train split: 23202 examples [00:43, 803.60 examples/s]\n",
            "Generating train split: 23308 examples [00:43, 874.80 examples/s]\n",
            "Generating train split: 23416 examples [00:43, 931.87 examples/s]\n",
            "Generating train split: 23524 examples [00:43, 972.83 examples/s]\n",
            "Generating train split: 23665 examples [00:43, 953.82 examples/s]\n",
            "Generating train split: 23770 examples [00:44, 976.21 examples/s]\n",
            " 46% 23795/52002 [00:33<00:28, 973.46it/s]\u001b[A\n",
            "Generating train split: 23921 examples [00:44, 985.72 examples/s]\n",
            "Generating train split: 24062 examples [00:44, 969.45 examples/s]\n",
            "Generating train split: 24164 examples [00:44, 980.98 examples/s]\n",
            " 47% 24201/52002 [00:33<00:28, 966.79it/s]\u001b[A\n",
            "Generating train split: 24320 examples [00:44, 996.74 examples/s]\n",
            "Generating train split: 24429 examples [00:44, 1015.29 examples/s]\n",
            "Generating train split: 24587 examples [00:44, 1025.58 examples/s]\n",
            "Generating train split: 24728 examples [00:45, 993.17 examples/s] \n",
            " 48% 24731/52002 [00:34<00:27, 994.68it/s] \u001b[A\n",
            "Generating train split: 24875 examples [00:45, 984.83 examples/s]\n",
            "Generating train split: 24978 examples [00:45, 993.26 examples/s]\n",
            "Generating train split: 25114 examples [00:45, 963.08 examples/s]\n",
            "Generating train split: 25216 examples [00:45, 974.01 examples/s]\n",
            "Generating train split: 25316 examples [00:45, 975.25 examples/s]\n",
            "Generating train split: 25416 examples [00:45, 979.35 examples/s]\n",
            "Generating train split: 25520 examples [00:45, 994.15 examples/s]\n",
            "Generating train split: 25631 examples [00:45, 1025.89 examples/s]\n",
            " 49% 25655/52002 [00:35<00:26, 992.16it/s]\u001b[A\n",
            "Generating train split: 25759 examples [00:46, 957.21 examples/s] \n",
            "Generating train split: 25861 examples [00:46, 971.36 examples/s]\n",
            "Generating train split: 26000 examples [00:46, 923.96 examples/s]\n",
            "Generating train split: 26118 examples [00:46, 985.95 examples/s]\n",
            "Generating train split: 26223 examples [00:46, 998.70 examples/s]\n",
            " 51% 26263/52002 [00:35<00:25, 995.99it/s]\u001b[A\n",
            "Generating train split: 26372 examples [00:46, 994.24 examples/s]\n",
            "Generating train split: 26515 examples [00:46, 977.94 examples/s]\n",
            "Generating train split: 26619 examples [00:46, 987.35 examples/s]\n",
            "Generating train split: 26751 examples [00:47, 949.35 examples/s]\n",
            " 51% 26771/52002 [00:36<00:26, 936.99it/s]\u001b[A\n",
            "Generating train split: 26898 examples [00:47, 955.21 examples/s]\n",
            "Generating train split: 27000 examples [00:47, 950.67 examples/s]\n",
            "Generating train split: 27113 examples [00:47, 994.25 examples/s]\n",
            "Generating train split: 27262 examples [00:47, 988.66 examples/s]\n",
            "Generating train split: 27364 examples [00:47, 995.10 examples/s]\n",
            "Generating train split: 27469 examples [00:47, 1003.80 examples/s]\n",
            " 53% 27486/52002 [00:36<00:24, 1012.06it/s]\u001b[A\n",
            "Generating train split: 27605 examples [00:48, 965.09 examples/s] \n",
            "Generating train split: 27746 examples [00:48, 949.94 examples/s]\n",
            "Generating train split: 27843 examples [00:48, 951.64 examples/s]\n",
            "Generating train split: 27950 examples [00:48, 979.02 examples/s]\n",
            "Generating train split: 28084 examples [00:48, 945.70 examples/s]\n",
            " 54% 28091/52002 [00:37<00:25, 940.92it/s]\u001b[A\n",
            "Generating train split: 28223 examples [00:48, 936.12 examples/s]\n",
            "Generating train split: 28321 examples [00:48, 943.14 examples/s]\n",
            "Generating train split: 28419 examples [00:48, 952.28 examples/s]\n",
            "Generating train split: 28523 examples [00:48, 969.00 examples/s]\n",
            "Generating train split: 28649 examples [00:49, 917.60 examples/s]\n",
            "Generating train split: 28760 examples [00:49, 965.68 examples/s]\n",
            "Generating train split: 28873 examples [00:49, 1006.38 examples/s]\n",
            "Generating train split: 28976 examples [00:49, 1011.24 examples/s]\n",
            " 56% 28995/52002 [00:38<00:22, 1013.36it/s]\u001b[A\n",
            "Generating train split: 29123 examples [00:49, 996.85 examples/s] \n",
            "Generating train split: 29274 examples [00:49, 992.43 examples/s]\n",
            "Generating train split: 29378 examples [00:49, 999.71 examples/s]\n",
            "Generating train split: 29486 examples [00:49, 1018.18 examples/s]\n",
            " 57% 29509/52002 [00:38<00:22, 1007.57it/s]\u001b[A\n",
            "Generating train split: 29635 examples [00:50, 1000.93 examples/s]\n",
            "Generating train split: 29761 examples [00:50, 942.78 examples/s] \n",
            "Generating train split: 29903 examples [00:50, 941.18 examples/s]\n",
            "Generating train split: 30000 examples [00:50, 938.61 examples/s]\n",
            "Generating train split: 30101 examples [00:50, 952.82 examples/s]\n",
            "Generating train split: 30199 examples [00:50, 956.99 examples/s]\n",
            "Generating train split: 30312 examples [00:50, 998.99 examples/s]\n",
            " 58% 30318/52002 [00:39<00:21, 1005.32it/s]\u001b[A\n",
            "Generating train split: 30455 examples [00:50, 979.09 examples/s]\n",
            "Generating train split: 30588 examples [00:51, 939.52 examples/s]\n",
            "Generating train split: 30689 examples [00:51, 952.78 examples/s]\n",
            "Generating train split: 30795 examples [00:51, 977.84 examples/s]\n",
            "Generating train split: 30896 examples [00:51, 986.05 examples/s]\n",
            "Generating train split: 30997 examples [00:51, 989.43 examples/s]\n",
            " 60% 31030/52002 [00:40<00:21, 957.70it/s]\u001b[A\n",
            "Generating train split: 31140 examples [00:51, 971.43 examples/s]\n",
            "Generating train split: 31279 examples [00:51, 953.65 examples/s]\n",
            "Generating train split: 31380 examples [00:51, 963.35 examples/s]\n",
            "Generating train split: 31489 examples [00:52, 992.26 examples/s]\n",
            "Generating train split: 31630 examples [00:52, 969.31 examples/s]\n",
            "Generating train split: 31750 examples [00:52, 1026.40 examples/s]\n",
            "Generating train split: 31865 examples [00:52, 1057.94 examples/s]\n",
            "Generating train split: 31977 examples [00:52, 1073.82 examples/s]\n",
            " 62% 31993/52002 [00:41<00:18, 1090.61it/s]\u001b[A\n",
            "Generating train split: 32120 examples [00:52, 1025.16 examples/s]\n",
            "Generating train split: 32258 examples [00:52, 979.85 examples/s] \n",
            "Generating train split: 32360 examples [00:52, 986.65 examples/s]\n",
            "Generating train split: 32463 examples [00:52, 990.92 examples/s]\n",
            "Generating train split: 32575 examples [00:53, 1021.46 examples/s]\n",
            "Generating train split: 32711 examples [00:53, 974.13 examples/s] \n",
            "Generating train split: 32813 examples [00:53, 866.72 examples/s]\n",
            " 63% 32819/52002 [00:42<00:22, 850.56it/s]\u001b[A\n",
            "Generating train split: 32913 examples [00:53, 796.60 examples/s]\n",
            "Generating train split: 33000 examples [00:53, 696.29 examples/s]\n",
            "Generating train split: 33074 examples [00:53, 703.16 examples/s]\n",
            "Generating train split: 33161 examples [00:53, 657.46 examples/s]\n",
            "Generating train split: 33249 examples [00:54, 631.54 examples/s]\n",
            " 64% 33266/52002 [00:43<00:30, 621.43it/s]\u001b[A\n",
            "Generating train split: 33330 examples [00:54, 600.02 examples/s]\n",
            "Generating train split: 33418 examples [00:54, 592.87 examples/s]\n",
            "Generating train split: 33481 examples [00:54, 599.25 examples/s]\n",
            "Generating train split: 33544 examples [00:54, 603.49 examples/s]\n",
            "Generating train split: 33608 examples [00:54, 599.55 examples/s]\n",
            "Generating train split: 33671 examples [00:54, 605.74 examples/s]\n",
            "Generating train split: 33732 examples [00:54, 604.49 examples/s]\n",
            "Generating train split: 33817 examples [00:55, 582.96 examples/s]\n",
            "Generating train split: 33879 examples [00:55, 589.61 examples/s]\n",
            "Generating train split: 33943 examples [00:55, 597.31 examples/s]\n",
            " 65% 33949/52002 [00:44<00:30, 595.67it/s]\u001b[A\n",
            "Generating train split: 34030 examples [00:55, 567.38 examples/s]\n",
            "Generating train split: 34091 examples [00:55, 576.00 examples/s]\n",
            "Generating train split: 34172 examples [00:55, 560.59 examples/s]\n",
            "Generating train split: 34238 examples [00:55, 583.71 examples/s]\n",
            " 66% 34247/52002 [00:44<00:30, 589.90it/s]\u001b[A\n",
            "Generating train split: 34325 examples [00:55, 578.86 examples/s]\n",
            "Generating train split: 34388 examples [00:56, 589.74 examples/s]\n",
            "Generating train split: 34471 examples [00:56, 568.87 examples/s]\n",
            "Generating train split: 34536 examples [00:56, 585.53 examples/s]\n",
            " 66% 34545/52002 [00:45<00:30, 578.91it/s]\u001b[A\n",
            "Generating train split: 34624 examples [00:56, 584.87 examples/s]\n",
            "Generating train split: 34685 examples [00:56, 585.88 examples/s]\n",
            "Generating train split: 34747 examples [00:56, 588.33 examples/s]\n",
            "Generating train split: 34835 examples [00:56, 582.23 examples/s]\n",
            "Generating train split: 34897 examples [00:56, 587.51 examples/s]\n",
            " 67% 34909/52002 [00:45<00:28, 592.15it/s]\u001b[A\n",
            "Generating train split: 34984 examples [00:57, 581.03 examples/s]\n",
            "Generating train split: 35060 examples [00:57, 553.55 examples/s]\n",
            "Generating train split: 35122 examples [00:57, 566.81 examples/s]\n",
            "Generating train split: 35206 examples [00:57, 562.02 examples/s]\n",
            " 68% 35207/52002 [00:46<00:29, 568.00it/s]\u001b[A\n",
            "Generating train split: 35267 examples [00:57, 567.57 examples/s]\n",
            "Generating train split: 35357 examples [00:57, 572.91 examples/s]\n",
            "Generating train split: 35422 examples [00:57, 590.80 examples/s]\n",
            "Generating train split: 35493 examples [00:57, 617.41 examples/s]\n",
            "Generating train split: 35587 examples [00:58, 700.07 examples/s]\n",
            "Generating train split: 35695 examples [00:58, 801.81 examples/s]\n",
            "Generating train split: 35796 examples [00:58, 855.04 examples/s]\n",
            "Generating train split: 35894 examples [00:58, 887.98 examples/s]\n",
            "Generating train split: 36005 examples [00:58, 826.56 examples/s]\n",
            "Generating train split: 36098 examples [00:58, 852.02 examples/s]\n",
            "Generating train split: 36200 examples [00:58, 784.57 examples/s]\n",
            "Generating train split: 36296 examples [00:58, 827.87 examples/s]\n",
            "Generating train split: 36395 examples [00:58, 869.04 examples/s]\n",
            "Generating train split: 36496 examples [00:59, 906.26 examples/s]\n",
            "Generating train split: 36599 examples [00:59, 939.61 examples/s]\n",
            " 70% 36600/52002 [00:48<00:16, 941.30it/s]\u001b[A\n",
            "Generating train split: 36749 examples [00:59, 957.32 examples/s]\n",
            "Generating train split: 36854 examples [00:59, 978.69 examples/s]\n",
            "Generating train split: 36959 examples [00:59, 990.34 examples/s]\n",
            "Generating train split: 37107 examples [00:59, 967.07 examples/s]\n",
            "Generating train split: 37207 examples [00:59, 973.04 examples/s]\n",
            "Generating train split: 37317 examples [00:59, 1005.11 examples/s]\n",
            "Generating train split: 37419 examples [00:59, 1007.53 examples/s]\n",
            " 72% 37425/52002 [00:49<00:14, 1015.07it/s]\u001b[A\n",
            "Generating train split: 37560 examples [01:00, 980.20 examples/s] \n",
            "Generating train split: 37661 examples [01:00, 987.38 examples/s]\n",
            "Generating train split: 37766 examples [01:00, 1002.24 examples/s]\n",
            "Generating train split: 37904 examples [01:00, 965.06 examples/s] \n",
            " 73% 37939/52002 [00:49<00:14, 965.26it/s]\u001b[A\n",
            "Generating train split: 38047 examples [01:00, 952.82 examples/s]\n",
            "Generating train split: 38157 examples [01:00, 986.11 examples/s]\n",
            "Generating train split: 38263 examples [01:00, 1002.89 examples/s]\n",
            "Generating train split: 38409 examples [01:01, 985.86 examples/s] \n",
            "Generating train split: 38518 examples [01:01, 1010.78 examples/s]\n",
            " 74% 38547/52002 [00:50<00:13, 979.16it/s]\u001b[A\n",
            "Generating train split: 38661 examples [01:01, 986.53 examples/s] \n",
            "Generating train split: 38774 examples [01:01, 904.83 examples/s]\n",
            "Generating train split: 38882 examples [01:01, 761.16 examples/s]\n",
            "Generating train split: 38973 examples [01:01, 713.46 examples/s]\n",
            "Generating train split: 39062 examples [01:01, 643.27 examples/s]\n",
            " 75% 39078/52002 [00:50<00:20, 625.90it/s]\u001b[A\n",
            "Generating train split: 39150 examples [01:02, 624.29 examples/s]\n",
            "Generating train split: 39234 examples [01:02, 600.97 examples/s]\n",
            "Generating train split: 39315 examples [01:02, 577.03 examples/s]\n",
            " 76% 39330/52002 [00:51<00:23, 549.98it/s]\u001b[A\n",
            "Generating train split: 39396 examples [01:02, 562.90 examples/s]\n",
            "Generating train split: 39471 examples [01:02, 541.38 examples/s]\n",
            "Generating train split: 39532 examples [01:02, 494.43 examples/s]\n",
            "Generating train split: 39586 examples [01:02, 501.89 examples/s]\n",
            "Generating train split: 39644 examples [01:03, 519.05 examples/s]\n",
            "Generating train split: 39707 examples [01:03, 542.65 examples/s]\n",
            " 76% 39721/52002 [00:52<00:23, 533.90it/s]\u001b[A\n",
            "Generating train split: 39792 examples [01:03, 523.93 examples/s]\n",
            "Generating train split: 39894 examples [01:03, 639.99 examples/s]\n",
            "Generating train split: 39989 examples [01:03, 717.76 examples/s]\n",
            "Generating train split: 40077 examples [01:03, 759.08 examples/s]\n",
            "Generating train split: 40182 examples [01:03, 837.71 examples/s]\n",
            "Generating train split: 40290 examples [01:03, 903.60 examples/s]\n",
            "Generating train split: 40386 examples [01:03, 916.76 examples/s]\n",
            "Generating train split: 40530 examples [01:04, 929.07 examples/s]\n",
            "Generating train split: 40637 examples [01:04, 962.59 examples/s]\n",
            "Generating train split: 40744 examples [01:04, 990.36 examples/s]\n",
            "Generating train split: 40854 examples [01:04, 1018.27 examples/s]\n",
            "Generating train split: 40965 examples [01:04, 1039.24 examples/s]\n",
            " 79% 40982/52002 [00:53<00:10, 1041.68it/s]\u001b[A\n",
            "Generating train split: 41102 examples [01:04, 988.65 examples/s] \n",
            "Generating train split: 41260 examples [01:04, 1010.37 examples/s]\n",
            "Generating train split: 41363 examples [01:04, 1013.86 examples/s]\n",
            " 80% 41399/52002 [00:53<00:10, 1010.32it/s]\u001b[A\n",
            "Generating train split: 41510 examples [01:05, 999.08 examples/s] \n",
            "Generating train split: 41617 examples [01:05, 1015.07 examples/s]\n",
            "Generating train split: 41757 examples [01:05, 982.71 examples/s] \n",
            "Generating train split: 41902 examples [01:05, 973.89 examples/s]\n",
            " 81% 41909/52002 [00:54<00:10, 973.74it/s]\u001b[A\n",
            "Generating train split: 42044 examples [01:05, 938.32 examples/s]\n",
            "Generating train split: 42145 examples [01:05, 952.64 examples/s]\n",
            "Generating train split: 42247 examples [01:05, 966.95 examples/s]\n",
            "Generating train split: 42345 examples [01:05, 967.59 examples/s]\n",
            "Generating train split: 42447 examples [01:06, 979.20 examples/s]\n",
            "Generating train split: 42552 examples [01:06, 993.65 examples/s]\n",
            "Generating train split: 42654 examples [01:06, 999.26 examples/s]\n",
            "Generating train split: 42792 examples [01:06, 965.83 examples/s]\n",
            "Generating train split: 42895 examples [01:06, 978.21 examples/s]\n",
            "Generating train split: 43018 examples [01:06, 919.33 examples/s]\n",
            "Generating train split: 43126 examples [01:06, 958.75 examples/s]\n",
            " 83% 43131/52002 [00:55<00:09, 957.87it/s]\u001b[A\n",
            "Generating train split: 43267 examples [01:06, 948.33 examples/s]\n",
            "Generating train split: 43405 examples [01:07, 932.24 examples/s]\n",
            "Generating train split: 43510 examples [01:07, 956.15 examples/s]\n",
            "Generating train split: 43608 examples [01:07, 958.75 examples/s]\n",
            "Generating train split: 43714 examples [01:07, 981.68 examples/s]\n",
            "Generating train split: 43816 examples [01:07, 988.80 examples/s]\n",
            "Generating train split: 43924 examples [01:07, 1013.62 examples/s]\n",
            " 84% 43935/52002 [00:56<00:07, 1015.98it/s]\u001b[A\n",
            "Generating train split: 44060 examples [01:07, 968.79 examples/s] \n",
            "Generating train split: 44199 examples [01:07, 950.44 examples/s]\n",
            "Generating train split: 44313 examples [01:07, 995.69 examples/s]\n",
            " 85% 44336/52002 [00:57<00:07, 982.21it/s]\u001b[A\n",
            "Generating train split: 44441 examples [01:08, 837.94 examples/s]\n",
            "Generating train split: 44537 examples [01:08, 771.51 examples/s]\n",
            "Generating train split: 44635 examples [01:08, 732.00 examples/s]\n",
            "Generating train split: 44733 examples [01:08, 705.43 examples/s]\n",
            " 86% 44748/52002 [00:57<00:10, 672.65it/s]\u001b[A\n",
            "Generating train split: 44822 examples [01:08, 669.21 examples/s]\n",
            "Generating train split: 44892 examples [01:08, 671.62 examples/s]\n",
            "Generating train split: 44985 examples [01:09, 650.68 examples/s]\n",
            "Generating train split: 45071 examples [01:09, 622.58 examples/s]\n",
            " 87% 45082/52002 [00:58<00:11, 614.00it/s]\u001b[A\n",
            "Generating train split: 45159 examples [01:09, 610.16 examples/s]\n",
            "Generating train split: 45228 examples [01:09, 625.64 examples/s]\n",
            "Generating train split: 45320 examples [01:09, 619.90 examples/s]\n",
            "Generating train split: 45391 examples [01:09, 637.51 examples/s]\n",
            " 87% 45406/52002 [00:58<00:10, 618.69it/s]\u001b[A\n",
            "Generating train split: 45482 examples [01:09, 625.39 examples/s]\n",
            "Generating train split: 45548 examples [01:09, 629.82 examples/s]\n",
            "Generating train split: 45615 examples [01:10, 637.89 examples/s]\n",
            "Generating train split: 45683 examples [01:10, 646.81 examples/s]\n",
            "Generating train split: 45773 examples [01:10, 628.18 examples/s]\n",
            "Generating train split: 45841 examples [01:10, 639.95 examples/s]\n",
            "Generating train split: 45926 examples [01:10, 604.66 examples/s]\n",
            " 88% 45926/52002 [00:59<00:10, 604.98it/s]\u001b[A\n",
            "Generating train split: 45989 examples [01:10, 607.30 examples/s]\n",
            "Generating train split: 46060 examples [01:10, 555.19 examples/s]\n",
            "Generating train split: 46117 examples [01:10, 556.27 examples/s]\n",
            "Generating train split: 46180 examples [01:11, 574.39 examples/s]\n",
            "Generating train split: 46239 examples [01:11, 576.32 examples/s]\n",
            "Generating train split: 46321 examples [01:11, 556.62 examples/s]\n",
            "Generating train split: 46385 examples [01:11, 574.37 examples/s]\n",
            "Generating train split: 46447 examples [01:11, 581.76 examples/s]\n",
            "Generating train split: 46510 examples [01:11, 587.83 examples/s]\n",
            "Generating train split: 46571 examples [01:11, 589.70 examples/s]\n",
            " 90% 46591/52002 [01:00<00:09, 580.02it/s]\u001b[A\n",
            "Generating train split: 46655 examples [01:11, 577.07 examples/s]\n",
            "Generating train split: 46719 examples [01:11, 590.30 examples/s]\n",
            "Generating train split: 46785 examples [01:12, 606.05 examples/s]\n",
            "Generating train split: 46849 examples [01:12, 613.72 examples/s]\n",
            "Generating train split: 46939 examples [01:12, 607.02 examples/s]\n",
            "Generating train split: 47031 examples [01:12, 568.87 examples/s]\n",
            "Generating train split: 47098 examples [01:12, 591.35 examples/s]\n",
            "Generating train split: 47161 examples [01:12, 597.78 examples/s]\n",
            " 91% 47162/52002 [01:01<00:08, 594.09it/s]\u001b[A\n",
            "Generating train split: 47255 examples [01:12, 601.22 examples/s]\n",
            "Generating train split: 47362 examples [01:12, 714.53 examples/s]\n",
            "Generating train split: 47457 examples [01:13, 774.09 examples/s]\n",
            "Generating train split: 47556 examples [01:13, 828.72 examples/s]\n",
            "Generating train split: 47657 examples [01:13, 877.53 examples/s]\n",
            "Generating train split: 47758 examples [01:13, 913.67 examples/s]\n",
            "Generating train split: 47886 examples [01:13, 889.54 examples/s]\n",
            "Generating train split: 47996 examples [01:13, 942.13 examples/s]\n",
            " 92% 48000/52002 [01:02<00:04, 919.63it/s]\u001b[A\n",
            "Generating train split: 48139 examples [01:13, 943.13 examples/s]\n",
            "Generating train split: 48239 examples [01:13, 951.94 examples/s]\n",
            "Generating train split: 48380 examples [01:13, 943.45 examples/s]\n",
            "Generating train split: 48484 examples [01:14, 965.77 examples/s]\n",
            "Generating train split: 48586 examples [01:14, 977.16 examples/s]\n",
            "Generating train split: 48688 examples [01:14, 987.41 examples/s]\n",
            " 94% 48709/52002 [01:03<00:03, 995.90it/s]\u001b[A\n",
            "Generating train split: 48847 examples [01:14, 1009.61 examples/s]\n",
            "Generating train split: 48954 examples [01:14, 1023.03 examples/s]\n",
            "Generating train split: 49100 examples [01:14, 978.01 examples/s] \n",
            "Generating train split: 49210 examples [01:14, 1006.47 examples/s]\n",
            " 95% 49237/52002 [01:03<00:02, 1023.57it/s]\u001b[A\n",
            "Generating train split: 49357 examples [01:14, 989.95 examples/s] \n",
            "Generating train split: 49464 examples [01:15, 1007.92 examples/s]\n",
            "Generating train split: 49592 examples [01:15, 951.11 examples/s] \n",
            "Generating train split: 49745 examples [01:15, 973.03 examples/s]\n",
            "Generating train split: 49851 examples [01:15, 990.69 examples/s]\n",
            " 96% 49854/52002 [01:04<00:02, 986.72it/s]\u001b[A\n",
            "Generating train split: 49993 examples [01:15, 970.54 examples/s]\n",
            "Generating train split: 50131 examples [01:15, 948.60 examples/s]\n",
            "Generating train split: 50231 examples [01:15, 960.26 examples/s]\n",
            " 97% 50249/52002 [01:04<00:01, 945.53it/s]\u001b[A\n",
            "Generating train split: 50376 examples [01:16, 957.98 examples/s]\n",
            "Generating train split: 50515 examples [01:16, 946.96 examples/s]\n",
            "Generating train split: 50623 examples [01:16, 976.34 examples/s]\n",
            " 97% 50647/52002 [01:05<00:01, 975.12it/s]\u001b[A\n",
            "Generating train split: 50769 examples [01:16, 970.78 examples/s]\n",
            "Generating train split: 50889 examples [01:16, 1024.57 examples/s]\n",
            "Generating train split: 51024 examples [01:16, 978.10 examples/s] \n",
            "Generating train split: 51128 examples [01:16, 992.19 examples/s]\n",
            "Generating train split: 51238 examples [01:16, 1015.27 examples/s]\n",
            "Generating train split: 51372 examples [01:17, 967.22 examples/s] \n",
            "Generating train split: 51471 examples [01:17, 972.04 examples/s]\n",
            "Generating train split: 51572 examples [01:17, 981.18 examples/s]\n",
            "Generating train split: 51684 examples [01:17, 1015.75 examples/s]\n",
            "Generating train split: 51788 examples [01:17, 1018.61 examples/s]\n",
            "100% 51798/52002 [01:06<00:00, 1026.21it/s]\u001b[A\n",
            "Generating train split: 51921 examples [01:17, 964.54 examples/s] \n",
            "100% 52002/52002 [01:06<00:00, 779.56it/s]\n",
            "Dataset generator downloaded and prepared to /root/.cache/huggingface/datasets/generator/default-b6b8095638fbee26/0.0.0. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "!python tokenize_dataset_rows.py \\\n",
        "    --jsonl_path data/alpaca_data.jsonl \\\n",
        "    --save_path data/alpaca \\\n",
        "    --max_seq_length 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZnEVtBwDsqd"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GG96b9RKDsqd",
        "outputId": "a5fcc1a3-0336-46b3-d4d0-1947994f9860"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda-11.6/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
            "CUDA SETUP: Detected CUDA version 116\n",
            "CUDA SETUP: Loading binary /home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda116.so...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 8/8 [00:07<00:00,  1.04it/s]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, TrainingArguments, AutoConfig\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "\n",
        "class CastOutputToFloat(nn.Sequential):\n",
        "    def forward(self, x): return super().forward(x).to(torch.float32)\n",
        "\n",
        "\n",
        "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", load_in_8bit=True, trust_remote_code=True, device_map='auto')\n",
        "model.supports_gradient_checkpointing = True\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()\n",
        "model.lm_head = CastOutputToFloat(model.lm_head)\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP-zgp-GDsqf",
        "outputId": "4830a91b-844a-42ed-e9ae-1b487d2579e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcXM0HJ8Dsqf"
      },
      "source": [
        "## Test before finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0NmId9BDsqh",
        "outputId": "ceb0d139-f20f-405a-9bbb-5765b9b28520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction: Give three tips for staying healthy.\n",
            "Answer: I'm sorry, but I'm not sure what you're asking for. Could you please provide more context or clarify your question?\n",
            "### 1.Answer:\n",
            " 1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n",
            "2. Exercise regularly to keep your body active and strong. \n",
            "3. Get enough sleep and maintain a consistent sleep schedule. \n",
            "\n",
            "\n",
            "Instruction: What are the three primary colors?\n",
            "Answer: The three primary colors in painting are red, blue, and green. These colors are often used in combination to create more complex and vibrant colors.\n",
            "### 2.Answer:\n",
            " The three primary colors are red, blue, and yellow. \n",
            "\n",
            "\n",
            "Instruction: Describe the structure of an atom.\n",
            "Answer: The原子是构成物质的基本单位,由带正电荷的质子和不带电荷的电子组成。原子核由带正电荷的质子和不带电荷的中子组成,它们之间通过核力相互吸引。\n",
            "\n",
            "原子的化学性质取决于其组成和结构,以及化学反应中所涉及的因素。例如,氧原子是化学反应中最常见的原子之一,因为它具有两个电子,可以与许多其他原子形成化合物。\n",
            "\n",
            "物质是由原子和分子组成的,而原子是物质的基本单位。了解原子的结构、性质以及化学反应,可以帮助我们更好地理解物质世界,并更好地利用这些物质来制造产品、治疗疾病。\n",
            "### 3.Answer:\n",
            " An atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom. \n",
            "\n",
            "\n",
            "Instruction: How can we reduce air pollution?\n",
            "Answer: I'm sorry, but I'm not sure what you're asking. Could you please provide more context or clarify your question?\n",
            "### 4.Answer:\n",
            " There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances. \n",
            "\n",
            "\n",
            "Instruction: Describe a time when you had to make a difficult decision.\n",
            "Answer: I'm sorry, but I'm not sure what you're asking for. Could you please provide more context or clarify your question?\n",
            "### 5.Answer:\n",
            " I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities. \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from cover_alpaca2jsonl import format_example\n",
        "import json\n",
        "\n",
        "\n",
        "instructions = json.load(open(\"data/alpaca_data.json\"))\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, item in enumerate(instructions[:5]):\n",
        "        feature = format_example(item)\n",
        "        input_text = feature[\"context\"]\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "        out = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=150,\n",
        "            temperature=0\n",
        "        )\n",
        "        answer = tokenizer.decode(out[0])\n",
        "        print(answer)\n",
        "        item['infer_answer'] = answer\n",
        "        print(f\"### {idx+1}.Answer:\\n\", item.get('output'), '\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiNhlRndDsqi"
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM, inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=32, lora_dropout=0.1,\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.is_parallelizable = True\n",
        "model.model_parallel = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3ilctqdDsqj"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "\n",
        "dataset_path = \"data/alpaca/\"\n",
        "\n",
        "dataset = datasets.load_from_disk(dataset_path)\n",
        "\n",
        "train_num = 500\n",
        "\n",
        "mini_train_dataset = datasets.Dataset.from_dict(dataset[:train_num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-_tGM1LDsqk"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, HfArgumentParser\n",
        "\n",
        "\n",
        "def data_collator(features: list) -> dict:\n",
        "    len_ids = [len(feature[\"input_ids\"]) for feature in features]\n",
        "    longest = max(len_ids)\n",
        "    input_ids = []\n",
        "    labels_list = []\n",
        "    for ids_l, feature in sorted(zip(len_ids, features), key=lambda x: -x[0]):\n",
        "        ids = feature[\"input_ids\"]\n",
        "        seq_len = feature[\"seq_len\"]\n",
        "        labels = (\n",
        "            [-100] * (seq_len - 1) + ids[(seq_len - 1) :] + [-100] * (longest - ids_l)\n",
        "        )\n",
        "        ids = ids + [tokenizer.pad_token_id] * (longest - ids_l)\n",
        "        _ids = torch.LongTensor(ids)\n",
        "        labels_list.append(torch.LongTensor(labels))\n",
        "        input_ids.append(_ids)\n",
        "    input_ids = torch.stack(input_ids)\n",
        "    labels = torch.stack(labels_list)\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"labels\": labels,\n",
        "    }\n",
        "\n",
        "class ModifiedTrainer(Trainer):\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        return model(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            labels=inputs[\"labels\"],\n",
        "        ).loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqSqjpxtDsql",
        "outputId": "7bd50f79-2987-4f2e-ae18-d467b48253d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 07:54, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.091900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.787700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.673600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.978900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.534500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.611100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.620300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.778000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.493800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.479100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>1.205300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.375400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.489700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.614800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>1.405900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.440500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>1.468200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.071200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>1.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.942300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>1.184100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.970900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>1.262800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.108000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>1.203000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.265900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>1.715500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.326100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1500, training_loss=1.4622032979329427, metrics={'train_runtime': 474.9934, 'train_samples_per_second': 3.158, 'train_steps_per_second': 3.158, 'total_flos': 3781851053211648.0, 'train_loss': 1.4622032979329427, 'epoch': 3.0})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    \"output\",\n",
        "    fp16 =True,\n",
        "    gradient_accumulation_steps=1,\n",
        "    per_device_train_batch_size = 1,\n",
        "    learning_rate = 1e-4,\n",
        "    max_steps=1500,\n",
        "    logging_steps=50,\n",
        "    remove_unused_columns=False,\n",
        "    seed=0,\n",
        "    data_seed=0,\n",
        "    group_by_length=False,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = ModifiedTrainer(\n",
        "    model=model,\n",
        "    train_dataset=mini_train_dataset,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY32UuwNDsqn"
      },
      "source": [
        "## Test After finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbv9JsgQDsqn",
        "outputId": "51c077ec-62f0-43c8-9d7a-2845ee95dc4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/transformers-4.27.0.dev0-py3.8.egg/transformers/generation/utils.py:1374: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction: Give three tips for staying healthy.\n",
            "Answer: 1. Eat a balanced diet. \n",
            "2. Get regular exercise. \n",
            "3. Stay hydrated by drinking plenty of water.\n",
            "### 1.Answer:\n",
            " 1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n",
            "2. Exercise regularly to keep your body active and strong. \n",
            "3. Get enough sleep and maintain a consistent sleep schedule. \n",
            "\n",
            "\n",
            "Instruction: What are the three primary colors?\n",
            "Answer: The three primary colors are red, blue, and yellow.\n",
            "### 2.Answer:\n",
            " The three primary colors are red, blue, and yellow. \n",
            "\n",
            "\n",
            "Instruction: Describe the structure of an atom.\n",
            "Answer: An atom is a small particle of a chemical element, with a central electron surrounded by other electrons, which form a cloud around the central electron. The cloud of electrons is surrounded by a cloud of positive ions, which make up the原子's positive charge. The positive ions and negative ions are attracted to each other, and the atoms form a cloud of ions and electrons.\n",
            "### 3.Answer:\n",
            " An atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom. \n",
            "\n",
            "\n",
            "Instruction: How can we reduce air pollution?\n",
            "Answer: There are several ways to reduce air pollution, including reducing energy consumption, improving transportation, reducing waste and reducing the use of harmful chemicals. Additionally, increasing public awareness and education, implementing policies, and increasing funding for research can also help reduce air pollution.\n",
            "### 4.Answer:\n",
            " There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances. \n",
            "\n",
            "\n",
            "Instruction: Describe a time when you had to make a difficult decision.\n",
            "Answer: I had to make a difficult decision when I was in my 20s. I had to choose between my career and my studies. I knew that my studies were more important, but I also knew that I wanted to be a teacher. I had to make a decision based on my values and my future plans. I decided to pursue my studies and became a teacher. It was a difficult decision, but I was determined to make the right choice.\n",
            "### 5.Answer:\n",
            " I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities. \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from cover_alpaca2jsonl import format_example\n",
        "import json\n",
        "\n",
        "\n",
        "instructions = json.load(open(\"data/alpaca_data.json\"))\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, item in enumerate(instructions[:5]):\n",
        "        feature = format_example(item)\n",
        "        input_text = feature[\"context\"]\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "        out = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=150,\n",
        "            temperature=0\n",
        "        )\n",
        "        answer = tokenizer.decode(out[0])\n",
        "        print(answer)\n",
        "        item['infer_answer'] = answer\n",
        "        print(f\"### {idx+1}.Answer:\\n\", item.get('output'), '\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNcLZQ8ADsqo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "def save_tunable_parameters(model, path):\n",
        "    saved_params = {\n",
        "        k: v.to(\"cpu\")\n",
        "        for k, v in model.named_parameters()\n",
        "        if v.requires_grad\n",
        "    }\n",
        "    torch.save(saved_params, path)\n",
        "\n",
        "\n",
        "save_tunable_parameters(model, os.path.join(\"output\", \"chatglm-lora.pt\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Feb  7 2022, 13:32:35) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "25273a2a68c96ebac13d7fb9e0db516f9be0772777a0507fe06d682a441a3ba7"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}