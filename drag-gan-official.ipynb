{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/XingangPan/DragGAN","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-26T06:27:37.318756Z","iopub.execute_input":"2023-06-26T06:27:37.319019Z","iopub.status.idle":"2023-06-26T06:27:45.619732Z","shell.execute_reply.started":"2023-06-26T06:27:37.318996Z","shell.execute_reply":"2023-06-26T06:27:45.618545Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'DragGAN'...\nremote: Enumerating objects: 268, done.\u001b[K\nremote: Counting objects: 100% (35/35), done.\u001b[K\nremote: Compressing objects: 100% (24/24), done.\u001b[K\nremote: Total 268 (delta 14), reused 20 (delta 11), pack-reused 233\u001b[K\nReceiving objects: 100% (268/268), 34.05 MiB | 5.29 MiB/s, done.\nResolving deltas: 100% (72/72), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"cd DragGAN","metadata":{"execution":{"iopub.status.busy":"2023-06-26T06:28:21.449557Z","iopub.execute_input":"2023-06-26T06:28:21.450554Z","iopub.status.idle":"2023-06-26T06:28:21.458241Z","shell.execute_reply.started":"2023-06-26T06:28:21.450517Z","shell.execute_reply":"2023-06-26T06:28:21.457113Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/DragGAN\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-06-26T06:29:01.198078Z","iopub.execute_input":"2023-06-26T06:29:01.198489Z","iopub.status.idle":"2023-06-26T06:29:17.715096Z","shell.execute_reply.started":"2023-06-26T06:29:01.198455Z","shell.execute_reply":"2023-06-26T06:29:17.713982Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.15.1)\nRequirement already satisfied: Ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.11.1)\nCollecting gradio (from -r requirements.txt (line 4))\n  Downloading gradio-3.35.2-py3-none-any.whl (19.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.15.1)\nCollecting hf_transfer (from -r requirements.txt (line 6))\n  Downloading hf_transfer-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 2)) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 2)) (2.28.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 2)) (9.5.0)\nRequirement already satisfied: aiofiles in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (22.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (3.8.4)\nRequirement already satisfied: altair>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (5.0.1)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (0.95.1)\nCollecting ffmpy (from gradio->-r requirements.txt (line 4))\n  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client>=0.2.7 (from gradio->-r requirements.txt (line 4))\n  Downloading gradio_client-0.2.7-py3-none-any.whl (288 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 4))\n  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (2.2.0)\nRequirement already satisfied: markupsafe in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (2.1.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (3.6.3)\nCollecting mdit-py-plugins<=0.3.3 (from gradio->-r requirements.txt (line 4))\n  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: orjson in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (3.8.12)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (1.5.3)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (1.10.7)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (0.25.1)\nRequirement already satisfied: pygments>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (2.15.1)\nCollecting python-multipart (from gradio->-r requirements.txt (line 4))\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (5.4.1)\nCollecting semantic-version (from gradio->-r requirements.txt (line 4))\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (0.22.0)\nRequirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 4)) (11.0.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->-r requirements.txt (line 5)) (2023.6.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->-r requirements.txt (line 5)) (4.64.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->-r requirements.txt (line 5)) (21.3)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 4)) (4.17.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 4)) (0.12.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 4)) (0.1.2)\nRequirement already satisfied: linkify-it-py<3,>=1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 4)) (2.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->-r requirements.txt (line 5)) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio->-r requirements.txt (line 4)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio->-r requirements.txt (line 4)) (2023.3)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 4)) (8.1.3)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 4)) (0.14.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 4)) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 4)) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 4)) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 4)) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 4)) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 4)) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 4)) (1.3.1)\nRequirement already satisfied: starlette<0.27.0,>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio->-r requirements.txt (line 4)) (0.26.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->gradio->-r requirements.txt (line 4)) (2023.5.7)\nCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio->-r requirements.txt (line 4))\n  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->gradio->-r requirements.txt (line 4)) (3.4)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio->-r requirements.txt (line 4)) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio->-r requirements.txt (line 4)) (1.0.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio->-r requirements.txt (line 4)) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio->-r requirements.txt (line 4)) (4.39.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio->-r requirements.txt (line 4)) (1.4.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.15)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 4)) (3.6.2)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 4)) (0.19.3)\nRequirement already satisfied: uc-micro-py in /opt/conda/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 4)) (1.0.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->gradio->-r requirements.txt (line 4)) (1.16.0)\nBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=22ea221cf2b2ac044b5af3b41b3a16359373cc2cc7bdf9e6b2d8cc0963c660e2\n  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\nSuccessfully built ffmpy\nInstalling collected packages: ffmpy, semantic-version, python-multipart, hf_transfer, mdit-py-plugins, httpcore, httpx, gradio-client, gradio\n  Attempting uninstall: mdit-py-plugins\n    Found existing installation: mdit-py-plugins 0.3.5\n    Uninstalling mdit-py-plugins-0.3.5:\n      Successfully uninstalled mdit-py-plugins-0.3.5\nSuccessfully installed ffmpy-0.3.0 gradio-3.35.2 gradio-client-0.2.7 hf_transfer-0.1.3 httpcore-0.17.2 httpx-0.24.1 mdit-py-plugins-0.3.3 python-multipart-0.0.6 semantic-version-2.10.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2023-06-26T06:46:26.453019Z","iopub.execute_input":"2023-06-26T06:46:26.453439Z","iopub.status.idle":"2023-06-26T06:46:27.402319Z","shell.execute_reply.started":"2023-06-26T06:46:26.453390Z","shell.execute_reply":"2023-06-26T06:46:27.401044Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"/kaggle/working/DragGAN\n","output_type":"stream"}]},{"cell_type":"code","source":"ls scripts/","metadata":{"execution":{"iopub.status.busy":"2023-06-26T06:52:22.587596Z","iopub.execute_input":"2023-06-26T06:52:22.588012Z","iopub.status.idle":"2023-06-26T06:52:23.526958Z","shell.execute_reply.started":"2023-06-26T06:52:22.587978Z","shell.execute_reply":"2023-06-26T06:52:23.525550Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"download_model.sh  gui.sh\n","output_type":"stream"}]},{"cell_type":"code","source":"!sh scripts/download_model.sh","metadata":{"execution":{"iopub.status.busy":"2023-06-26T06:53:05.913253Z","iopub.execute_input":"2023-06-26T06:53:05.914256Z","iopub.status.idle":"2023-06-26T06:53:24.372038Z","shell.execute_reply.started":"2023-06-26T06:53:05.914217Z","shell.execute_reply":"2023-06-26T06:53:24.370835Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"--2023-06-26 06:53:06--  https://storage.googleapis.com/self-distilled-stylegan/lions_512_pytorch.pkl\nResolving storage.googleapis.com (storage.googleapis.com)... 142.250.107.128, 74.125.20.128, 108.177.98.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.250.107.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 363965313 (347M) [application/octet-stream]\nSaving to: ‘lions_512_pytorch.pkl’\n\nlions_512_pytorch.p 100%[===================>] 347.10M   236MB/s    in 1.5s    \n\n2023-06-26 06:53:08 (236 MB/s) - ‘lions_512_pytorch.pkl’ saved [363965313/363965313]\n\n--2023-06-26 06:53:08--  https://storage.googleapis.com/self-distilled-stylegan/dogs_1024_pytorch.pkl\nResolving storage.googleapis.com (storage.googleapis.com)... 142.250.107.128, 74.125.20.128, 108.177.98.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.250.107.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 381630441 (364M) [application/octet-stream]\nSaving to: ‘dogs_1024_pytorch.pkl’\n\ndogs_1024_pytorch.p 100%[===================>] 363.95M   174MB/s    in 2.1s    \n\n2023-06-26 06:53:10 (174 MB/s) - ‘dogs_1024_pytorch.pkl’ saved [381630441/381630441]\n\n--2023-06-26 06:53:10--  https://storage.googleapis.com/self-distilled-stylegan/horses_256_pytorch.pkl\nResolving storage.googleapis.com (storage.googleapis.com)... 142.250.107.128, 74.125.20.128, 108.177.98.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.250.107.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 357336721 (341M) [application/octet-stream]\nSaving to: ‘horses_256_pytorch.pkl’\n\nhorses_256_pytorch. 100%[===================>] 340.78M   242MB/s    in 1.4s    \n\n2023-06-26 06:53:11 (242 MB/s) - ‘horses_256_pytorch.pkl’ saved [357336721/357336721]\n\n--2023-06-26 06:53:11--  https://storage.googleapis.com/self-distilled-stylegan/elephants_512_pytorch.pkl\nResolving storage.googleapis.com (storage.googleapis.com)... 142.250.107.128, 74.125.20.128, 108.177.98.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.250.107.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 363965313 (347M) [application/octet-stream]\nSaving to: ‘elephants_512_pytorch.pkl’\n\nelephants_512_pytor 100%[===================>] 347.10M   259MB/s    in 1.3s    \n\n2023-06-26 06:53:13 (259 MB/s) - ‘elephants_512_pytorch.pkl’ saved [363965313/363965313]\n\n--2023-06-26 06:53:13--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan2/versions/1/files/stylegan2-ffhq-512x512.pkl\nResolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 35.160.252.113, 52.12.123.121\nConnecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|35.160.252.113|:443... connected.\nHTTP request sent, awaiting response... 302 \nLocation: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan2/versions/1/files/stylegan2-ffhq-512x512.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan2-ffhq-512x512.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230626T065313Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=AKIA3PSNVSIZUODK3WZL%2F20230626%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=7b26866d066acec2e4abdb87eabd6f54444cd566838dd629ab11f316d83e52fb [following]\n--2023-06-26 06:53:13--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan2/versions/1/files/stylegan2-ffhq-512x512.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan2-ffhq-512x512.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230626T065313Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=AKIA3PSNVSIZUODK3WZL%2F20230626%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=7b26866d066acec2e4abdb87eabd6f54444cd566838dd629ab11f316d83e52fb\nResolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 52.218.180.225, 3.5.76.168, 52.218.144.53, ...\nConnecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|52.218.180.225|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 363939580 (347M) [application/octet-stream]\nSaving to: ‘stylegan2-ffhq-512x512.pkl’\n\nstylegan2-ffhq-512x 100%[===================>] 347.08M  95.3MB/s    in 3.6s    \n\n2023-06-26 06:53:17 (97.0 MB/s) - ‘stylegan2-ffhq-512x512.pkl’ saved [363939580/363939580]\n\n--2023-06-26 06:53:17--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan2/versions/1/files/stylegan2-afhqcat-512x512.pkl\nResolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 52.12.123.121, 35.160.252.113\nConnecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|52.12.123.121|:443... connected.\nHTTP request sent, awaiting response... 302 \nLocation: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan2/versions/1/files/stylegan2-afhqcat-512x512.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan2-afhqcat-512x512.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230626T065317Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=AKIA3PSNVSIZUODK3WZL%2F20230626%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=6f1b69115ff4c6593e34e5b018a60841adecaed51c463fcabdd193658beaded8 [following]\n--2023-06-26 06:53:17--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan2/versions/1/files/stylegan2-afhqcat-512x512.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan2-afhqcat-512x512.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230626T065317Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=AKIA3PSNVSIZUODK3WZL%2F20230626%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=6f1b69115ff4c6593e34e5b018a60841adecaed51c463fcabdd193658beaded8\nResolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 3.5.80.178, 52.92.225.2, 52.218.221.81, ...\nConnecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|3.5.80.178|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 363939583 (347M) [application/octet-stream]\nSaving to: ‘stylegan2-afhqcat-512x512.pkl’\n\nstylegan2-afhqcat-5 100%[===================>] 347.08M  95.9MB/s    in 3.6s    \n\n2023-06-26 06:53:21 (97.1 MB/s) - ‘stylegan2-afhqcat-512x512.pkl’ saved [363939583/363939583]\n\n--2023-06-26 06:53:21--  http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-car-config-f.pkl\nResolving d36zk2xti64re0.cloudfront.net (d36zk2xti64re0.cloudfront.net)... 18.65.227.160, 18.65.227.32, 18.65.227.14, ...\nConnecting to d36zk2xti64re0.cloudfront.net (d36zk2xti64re0.cloudfront.net)|18.65.227.160|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 364027523 (347M) [application/x-www-form-urlencoded]\nSaving to: ‘stylegan2-car-config-f.pkl’\n\nstylegan2-car-confi 100%[===================>] 347.16M   324MB/s    in 1.1s    \n\n2023-06-26 06:53:22 (324 MB/s) - ‘stylegan2-car-config-f.pkl’ saved [364027523/364027523]\n\n--2023-06-26 06:53:22--  http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-cat-config-f.pkl\nResolving d36zk2xti64re0.cloudfront.net (d36zk2xti64re0.cloudfront.net)... 18.65.227.160, 18.65.227.32, 18.65.227.14, ...\nConnecting to d36zk2xti64re0.cloudfront.net (d36zk2xti64re0.cloudfront.net)|18.65.227.160|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 357418027 (341M) [application/x-www-form-urlencoded]\nSaving to: ‘stylegan2-cat-config-f.pkl’\n\nstylegan2-cat-confi 100%[===================>] 340.86M   320MB/s    in 1.1s    \n\n2023-06-26 06:53:24 (320 MB/s) - ‘stylegan2-cat-config-f.pkl’ saved [357418027/357418027]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport os.path as osp\nfrom argparse import ArgumentParser\nfrom functools import partial\n\nimport gradio as gr\nimport numpy as np\nimport torch\nfrom PIL import Image\n\nimport dnnlib\nfrom gradio_utils import (ImageMask, draw_mask_on_image, draw_points_on_image,\n                          get_latest_points_pair, get_valid_mask,\n                          on_change_single_global_state)\nfrom viz.renderer import Renderer, add_watermark_np\n\nparser = ArgumentParser('')\nparser.add_argument('--share', action='store_true')\nparser.add_argument('--cache-dir', type=str, default='./checkpoints')\nargs=parser.parse_known_args()[0]\nargs.share=True\n\ncache_dir = args.cache_dir\n\ndevice = 'cuda'\n\n\ndef reverse_point_pairs(points):\n    new_points = []\n    for p in points:\n        new_points.append([p[1], p[0]])\n    return new_points\n\n\ndef clear_state(global_state, target=None):\n    \"\"\"Clear target history state from global_state\n    If target is not defined, points and mask will be both removed.\n    1. set global_state['points'] as empty dict\n    2. set global_state['mask'] as full-one mask.\n    \"\"\"\n    if target is None:\n        target = ['point', 'mask']\n    if not isinstance(target, list):\n        target = [target]\n    if 'point' in target:\n        global_state['points'] = dict()\n        print('Clear Points State!')\n    if 'mask' in target:\n        image_raw = global_state[\"images\"][\"image_raw\"]\n        global_state['mask'] = np.ones((image_raw.size[1], image_raw.size[0]),\n                                       dtype=np.uint8)\n        print('Clear mask State!')\n\n    return global_state\n\n\ndef init_images(global_state):\n    \"\"\"This function is called only ones with Gradio App is started.\n    0. pre-process global_state, unpack value from global_state of need\n    1. Re-init renderer\n    2. run `renderer._render_drag_impl` with `is_drag=False` to generate\n       new image\n    3. Assign images to global state and re-generate mask\n    \"\"\"\n\n    if isinstance(global_state, gr.State):\n        state = global_state.value\n    else:\n        state = global_state\n\n    state['renderer'].init_network(\n        state['generator_params'],  # res\n        valid_checkpoints_dict[state['pretrained_weight']],  # pkl\n        state['params']['seed'],  # w0_seed,\n        None,  # w_load\n        state['params']['latent_space'] == 'w+',  # w_plus\n        'const',\n        state['params']['trunc_psi'],  # trunc_psi,\n        state['params']['trunc_cutoff'],  # trunc_cutoff,\n        None,  # input_transform\n        state['params']['lr']  # lr,\n    )\n\n    state['renderer']._render_drag_impl(state['generator_params'],\n                                        is_drag=False,\n                                        to_pil=True)\n\n    init_image = state['generator_params'].image\n    state['images']['image_orig'] = init_image\n    state['images']['image_raw'] = init_image\n    state['images']['image_show'] = Image.fromarray(\n        add_watermark_np(np.array(init_image)))\n    state['mask'] = np.ones((init_image.size[1], init_image.size[0]),\n                            dtype=np.uint8)\n    return global_state\n\n\ndef update_image_draw(image, points, mask, show_mask, global_state=None):\n\n    image_draw = draw_points_on_image(image, points)\n    if show_mask and mask is not None and not (mask == 0).all() and not (\n            mask == 1).all():\n        image_draw = draw_mask_on_image(image_draw, mask)\n\n    image_draw = Image.fromarray(add_watermark_np(np.array(image_draw)))\n    if global_state is not None:\n        global_state['images']['image_show'] = image_draw\n    return image_draw\n\n\ndef preprocess_mask_info(global_state, image):\n    \"\"\"Function to handle mask information.\n    1. last_mask is None: Do not need to change mask, return mask\n    2. last_mask is not None:\n        2.1 global_state is remove_mask:\n        2.2 global_state is add_mask:\n    \"\"\"\n    if isinstance(image, dict):\n        last_mask = get_valid_mask(image['mask'])\n    else:\n        last_mask = None\n    mask = global_state['mask']\n\n    # mask in global state is a placeholder with all 1.\n    if (mask == 1).all():\n        mask = last_mask\n\n    # last_mask = global_state['last_mask']\n    editing_mode = global_state['editing_state']\n\n    if last_mask is None:\n        return global_state\n\n    if editing_mode == 'remove_mask':\n        updated_mask = np.clip(mask - last_mask, 0, 1)\n        print(f'Last editing_state is {editing_mode}, do remove.')\n    elif editing_mode == 'add_mask':\n        updated_mask = np.clip(mask + last_mask, 0, 1)\n        print(f'Last editing_state is {editing_mode}, do add.')\n    else:\n        updated_mask = mask\n        print(f'Last editing_state is {editing_mode}, '\n              'do nothing to mask.')\n\n    global_state['mask'] = updated_mask\n    # global_state['last_mask'] = None  # clear buffer\n    return global_state\n\n\nvalid_checkpoints_dict = {\n    f.split('/')[-1].split('.')[0]: osp.join(cache_dir, f)\n    for f in os.listdir(cache_dir)\n    if (f.endswith('pkl') and osp.exists(osp.join(cache_dir, f)))\n}\nprint(f'File under cache_dir ({cache_dir}):')\nprint(os.listdir(cache_dir))\nprint('Valid checkpoint file:')\nprint(valid_checkpoints_dict)\n\ninit_pkl = 'stylegan_human_v2_512'\ninit_pkl = 'stylegan2-ffhq-512x512'\n\nwith gr.Blocks() as app:\n\n    # renderer = Renderer()\n    global_state = gr.State({\n        \"images\": {\n            # image_orig: the original image, change with seed/model is changed\n            # image_raw: image with mask and points, change durning optimization\n            # image_show: image showed on screen\n        },\n        \"temporal_params\": {\n            # stop\n        },\n        'mask':\n        None,  # mask for visualization, 1 for editing and 0 for unchange\n        'last_mask': None,  # last edited mask\n        'show_mask': True,  # add button\n        \"generator_params\": dnnlib.EasyDict(),\n        \"params\": {\n            \"seed\": 0,\n            \"motion_lambda\": 20,\n            \"r1_in_pixels\": 3,\n            \"r2_in_pixels\": 12,\n            \"magnitude_direction_in_pixels\": 1.0,\n            \"latent_space\": \"w+\",\n            \"trunc_psi\": 0.7,\n            \"trunc_cutoff\": None,\n            \"lr\": 0.001,\n        },\n        \"device\": device,\n        \"draw_interval\": 1,\n        \"renderer\": Renderer(disable_timing=True),\n        \"points\": {},\n        \"curr_point\": None,\n        \"curr_type_point\": \"start\",\n        'editing_state': 'add_points',\n        'pretrained_weight': init_pkl\n    })\n\n    # init image\n    global_state = init_images(global_state)\n\n    with gr.Row():\n\n        with gr.Row():\n\n            # Left --> tools\n            with gr.Column(scale=3):\n\n                # Pickle\n                with gr.Row():\n\n                    with gr.Column(scale=1, min_width=10):\n                        gr.Markdown(value='Pickle', show_label=False)\n\n                    with gr.Column(scale=4, min_width=10):\n                        form_pretrained_dropdown = gr.Dropdown(\n                            choices=list(valid_checkpoints_dict.keys()),\n                            label=\"Pretrained Model\",\n                            value=init_pkl,\n                        )\n\n                # Latent\n                with gr.Row():\n                    with gr.Column(scale=1, min_width=10):\n                        gr.Markdown(value='Latent', show_label=False)\n\n                    with gr.Column(scale=4, min_width=10):\n                        form_seed_number = gr.Number(\n                            value=global_state.value['params']['seed'],\n                            interactive=True,\n                            label=\"Seed\",\n                        )\n                        form_lr_number = gr.Number(\n                            value=global_state.value[\"params\"][\"lr\"],\n                            interactive=True,\n                            label=\"Step Size\")\n\n                        with gr.Row():\n                            with gr.Column(scale=2, min_width=10):\n                                form_reset_image = gr.Button(\"Reset Image\")\n                            with gr.Column(scale=3, min_width=10):\n                                form_latent_space = gr.Radio(\n                                    ['w', 'w+'],\n                                    value=global_state.value['params']\n                                    ['latent_space'],\n                                    interactive=True,\n                                    label='Latent space to optimize',\n                                    show_label=False,\n                                )\n\n                # Drag\n                with gr.Row():\n                    with gr.Column(scale=1, min_width=10):\n                        gr.Markdown(value='Drag', show_label=False)\n                    with gr.Column(scale=4, min_width=10):\n                        with gr.Row():\n                            with gr.Column(scale=1, min_width=10):\n                                enable_add_points = gr.Button('Add Points')\n                            with gr.Column(scale=1, min_width=10):\n                                undo_points = gr.Button('Reset Points')\n                        with gr.Row():\n                            with gr.Column(scale=1, min_width=10):\n                                form_start_btn = gr.Button(\"Start\")\n                            with gr.Column(scale=1, min_width=10):\n                                form_stop_btn = gr.Button(\"Stop\")\n\n                        form_steps_number = gr.Number(value=0,\n                                                      label=\"Steps\",\n                                                      interactive=False)\n\n                # Mask\n                with gr.Row():\n                    with gr.Column(scale=1, min_width=10):\n                        gr.Markdown(value='Mask', show_label=False)\n                    with gr.Column(scale=4, min_width=10):\n                        enable_add_mask = gr.Button('Edit Flexible Area')\n                        with gr.Row():\n                            with gr.Column(scale=1, min_width=10):\n                                form_reset_mask_btn = gr.Button(\"Reset mask\")\n                            with gr.Column(scale=1, min_width=10):\n                                show_mask = gr.Checkbox(\n                                    label='Show Mask',\n                                    value=global_state.value['show_mask'],\n                                    show_label=False)\n\n                        with gr.Row():\n                            form_lambda_number = gr.Number(\n                                value=global_state.value[\"params\"]\n                                [\"motion_lambda\"],\n                                interactive=True,\n                                label=\"Lambda\",\n                            )\n\n                form_draw_interval_number = gr.Number(\n                    value=global_state.value[\"draw_interval\"],\n                    label=\"Draw Interval (steps)\",\n                    interactive=True,\n                    visible=False)\n\n            # Right --> Image\n            with gr.Column(scale=8):\n                form_image = ImageMask(\n                    value=global_state.value['images']['image_show'],\n                    brush_radius=20).style(\n                        width=768,\n                        height=768)  # NOTE: hard image size code here.\n    gr.Markdown(\"\"\"\n        ## Quick Start\n\n        1. Select desired `Pretrained Model` and adjust `Seed` to generate an\n           initial image.\n        2. Click on image to add control points.\n        3. Click `Start` and enjoy it!\n\n        ## Advance Usage\n\n        1. Change `Step Size` to adjust learning rate in drag optimization.\n        2. Select `w` or `w+` to change latent space to optimize:\n        * Optimize on `w` space may cause greater influence to the image.\n        * Optimize on `w+` space may work slower than `w`, but usually achieve\n          better results.\n        * Note that changing the latent space will reset the image, points and\n          mask (this has the same effect as `Reset Image` button).\n        3. Click `Edit Flexible Area` to create a mask and constrain the\n           unmasked region to remain unchanged.\n        \"\"\")\n    gr.HTML(\"\"\"\n        <style>\n            .container {\n                position: absolute;\n                height: 50px;\n                text-align: center;\n                line-height: 50px;\n                width: 100%;\n            }\n        </style>\n        <div class=\"container\">\n        Gradio demo supported by\n        <img src=\"https://avatars.githubusercontent.com/u/10245193?s=200&v=4\" height=\"20\" width=\"20\" style=\"display:inline;\">\n        <a href=\"https://github.com/open-mmlab/mmagic\">OpenMMLab MMagic</a>\n        </div>\n        \"\"\")\n\n    # Network & latents tab listeners\n    def on_change_pretrained_dropdown(pretrained_value, global_state):\n        \"\"\"Function to handle model change.\n        1. Set pretrained value to global_state\n        2. Re-init images and clear all states\n        \"\"\"\n\n        global_state['pretrained_weight'] = pretrained_value\n        init_images(global_state)\n        clear_state(global_state)\n\n        return global_state, global_state[\"images\"]['image_show']\n\n    form_pretrained_dropdown.change(\n        on_change_pretrained_dropdown,\n        inputs=[form_pretrained_dropdown, global_state],\n        outputs=[global_state, form_image],\n    )\n\n    def on_click_reset_image(global_state):\n        \"\"\"Reset image to the original one and clear all states\n        1. Re-init images\n        2. Clear all states\n        \"\"\"\n\n        init_images(global_state)\n        clear_state(global_state)\n\n        return global_state, global_state['images']['image_show']\n\n    form_reset_image.click(\n        on_click_reset_image,\n        inputs=[global_state],\n        outputs=[global_state, form_image],\n    )\n\n    # Update parameters\n    def on_change_update_image_seed(seed, global_state):\n        \"\"\"Function to handle generation seed change.\n        1. Set seed to global_state\n        2. Re-init images and clear all states\n        \"\"\"\n\n        global_state[\"params\"][\"seed\"] = int(seed)\n        init_images(global_state)\n        clear_state(global_state)\n\n        return global_state, global_state['images']['image_show']\n\n    form_seed_number.change(\n        on_change_update_image_seed,\n        inputs=[form_seed_number, global_state],\n        outputs=[global_state, form_image],\n    )\n\n    def on_click_latent_space(latent_space, global_state):\n        \"\"\"Function to reset latent space to optimize.\n        NOTE: this function we reset the image and all controls\n        1. Set latent-space to global_state\n        2. Re-init images and clear all state\n        \"\"\"\n\n        global_state['params']['latent_space'] = latent_space\n        init_images(global_state)\n        clear_state(global_state)\n\n        return global_state, global_state['images']['image_show']\n\n    form_latent_space.change(on_click_latent_space,\n                             inputs=[form_latent_space, global_state],\n                             outputs=[global_state, form_image])\n\n    # ==== Params\n    form_lambda_number.change(\n        partial(on_change_single_global_state, [\"params\", \"motion_lambda\"]),\n        inputs=[form_lambda_number, global_state],\n        outputs=[global_state],\n    )\n\n    def on_change_lr(lr, global_state):\n        if lr == 0:\n            print('lr is 0, do nothing.')\n            return global_state\n        else:\n            global_state[\"params\"][\"lr\"] = lr\n            renderer = global_state['renderer']\n            renderer.update_lr(lr)\n            print('New optimizer: ')\n            print(renderer.w_optim)\n        return global_state\n\n    form_lr_number.change(\n        on_change_lr,\n        inputs=[form_lr_number, global_state],\n        outputs=[global_state],\n    )\n\n    def on_click_start(global_state, image):\n        p_in_pixels = []\n        t_in_pixels = []\n        valid_points = []\n\n        # handle of start drag in mask editing mode\n        global_state = preprocess_mask_info(global_state, image)\n\n        # Prepare the points for the inference\n        if len(global_state[\"points\"]) == 0:\n            # yield on_click_start_wo_points(global_state, image)\n            image_raw = global_state['images']['image_raw']\n            update_image_draw(\n                image_raw,\n                global_state['points'],\n                global_state['mask'],\n                global_state['show_mask'],\n                global_state,\n            )\n\n            yield (\n                global_state,\n                0,\n                global_state['images']['image_show'],\n                # gr.File.update(visible=False),\n                gr.Button.update(interactive=True),\n                gr.Button.update(interactive=True),\n                gr.Button.update(interactive=True),\n                gr.Button.update(interactive=True),\n                gr.Button.update(interactive=True),\n                # latent space\n                gr.Radio.update(interactive=True),\n                gr.Button.update(interactive=True),\n                # NOTE: disable stop button\n                gr.Button.update(interactive=False),\n\n                # update other comps\n                gr.Dropdown.update(interactive=True),\n                gr.Number.update(interactive=True),\n                gr.Number.update(interactive=True),\n                gr.Button.update(interactive=True),\n                gr.Button.update(interactive=True),\n                gr.Checkbox.update(interactive=True),\n                # gr.Number.update(interactive=True),\n                gr.Number.update(interactive=True),\n            )\n        else:\n\n            # Transform the points into torch tensors\n            for key_point, point in global_state[\"points\"].items():\n                try:\n                    p_start = point.get(\"start_temp\", point[\"start\"])\n                    p_end = point[\"target\"]\n\n                    if p_start is None or p_end is None:\n                        continue\n\n                except KeyError:\n                    continue\n\n                p_in_pixels.append(p_start)\n                t_in_pixels.append(p_end)\n                valid_points.append(key_point)\n\n            mask = torch.tensor(global_state['mask']).float()\n            drag_mask = 1 - mask\n\n            renderer: Renderer = global_state[\"renderer\"]\n            global_state['temporal_params']['stop'] = False\n            global_state['editing_state'] = 'running'\n\n            # reverse points order\n            p_to_opt = reverse_point_pairs(p_in_pixels)\n            t_to_opt = reverse_point_pairs(t_in_pixels)\n            print('Running with:')\n            print(f'    Source: {p_in_pixels}')\n            print(f'    Target: {t_in_pixels}')\n            step_idx = 0\n            while True:\n                if global_state[\"temporal_params\"][\"stop\"]:\n                    break\n\n                # do drage here!\n                renderer._render_drag_impl(\n                    global_state['generator_params'],\n                    p_to_opt,  # point\n                    t_to_opt,  # target\n                    drag_mask,  # mask,\n                    global_state['params']['motion_lambda'],  # lambda_mask\n                    reg=0,\n                    feature_idx=5,  # NOTE: do not support change for now\n                    r1=global_state['params']['r1_in_pixels'],  # r1\n                    r2=global_state['params']['r2_in_pixels'],  # r2\n                    # random_seed     = 0,\n                    # noise_mode      = 'const',\n                    trunc_psi=global_state['params']['trunc_psi'],\n                    # force_fp32      = False,\n                    # layer_name      = None,\n                    # sel_channels    = 3,\n                    # base_channel    = 0,\n                    # img_scale_db    = 0,\n                    # img_normalize   = False,\n                    # untransform     = False,\n                    is_drag=True,\n                    to_pil=True)\n\n                if step_idx % global_state['draw_interval'] == 0:\n                    print('Current Source:')\n                    for key_point, p_i, t_i in zip(valid_points, p_to_opt,\n                                                   t_to_opt):\n                        global_state[\"points\"][key_point][\"start_temp\"] = [\n                            p_i[1],\n                            p_i[0],\n                        ]\n                        global_state[\"points\"][key_point][\"target\"] = [\n                            t_i[1],\n                            t_i[0],\n                        ]\n                        start_temp = global_state[\"points\"][key_point][\n                            \"start_temp\"]\n                        print(f'    {start_temp}')\n\n                    image_result = global_state['generator_params']['image']\n                    image_draw = update_image_draw(\n                        image_result,\n                        global_state['points'],\n                        global_state['mask'],\n                        global_state['show_mask'],\n                        global_state,\n                    )\n                    global_state['images']['image_raw'] = image_result\n\n                yield (\n                    global_state,\n                    step_idx,\n                    global_state['images']['image_show'],\n                    # gr.File.update(visible=False),\n                    gr.Button.update(interactive=False),\n                    gr.Button.update(interactive=False),\n                    gr.Button.update(interactive=False),\n                    gr.Button.update(interactive=False),\n                    gr.Button.update(interactive=False),\n                    # latent space\n                    gr.Radio.update(interactive=False),\n                    gr.Button.update(interactive=False),\n                    # enable stop button in loop\n                    gr.Button.update(interactive=True),\n\n                    # update other comps\n                    gr.Dropdown.update(interactive=False),\n                    gr.Number.update(interactive=False),\n                    gr.Number.update(interactive=False),\n                    gr.Button.update(interactive=False),\n                    gr.Button.update(interactive=False),\n                    gr.Checkbox.update(interactive=False),\n                    # gr.Number.update(interactive=False),\n                    gr.Number.update(interactive=False),\n                )\n\n                # increate step\n                step_idx += 1\n\n            image_result = global_state['generator_params']['image']\n            global_state['images']['image_raw'] = image_result\n            image_draw = update_image_draw(image_result,\n                                           global_state['points'],\n                                           global_state['mask'],\n                                           global_state['show_mask'],\n                                           global_state)\n\n            # fp = NamedTemporaryFile(suffix=\".png\", delete=False)\n            # image_result.save(fp, \"PNG\")\n\n            global_state['editing_state'] = 'add_points'\n\n            yield (\n                global_state,\n                0,  # reset step to 0 after stop.\n                global_state['images']['image_show'],\n                # gr.File.update(visible=True, value=fp.name),\n                gr.Button.update(interactive=True),\n                gr.Button.update(interactive=True),\n                gr.Button.update(interactive=True),\n                gr.Button.update(interactive=True),\n                gr.Button.update(interactive=True),\n                # latent space\n                gr.Radio.update(interactive=True),\n                gr.Button.update(interactive=True),\n                # NOTE: disable stop button with loop finish\n                gr.Button.update(interactive=False),\n\n                # update other comps\n                gr.Dropdown.update(interactive=True),\n                gr.Number.update(interactive=True),\n                gr.Number.update(interactive=True),\n                gr.Checkbox.update(interactive=True),\n                gr.Number.update(interactive=True),\n            )\n\n    form_start_btn.click(\n        on_click_start,\n        inputs=[global_state, form_image],\n        outputs=[\n            global_state,\n            form_steps_number,\n            form_image,\n            # form_download_result_file,\n            # >>> buttons\n            form_reset_image,\n            enable_add_points,\n            enable_add_mask,\n            undo_points,\n            form_reset_mask_btn,\n            form_latent_space,\n            form_start_btn,\n            form_stop_btn,\n            # <<< buttonm\n            # >>> inputs comps\n            form_pretrained_dropdown,\n            form_seed_number,\n            form_lr_number,\n            show_mask,\n            form_lambda_number,\n        ],\n    )\n\n    def on_click_stop(global_state):\n        \"\"\"Function to handle stop button is clicked.\n        1. send a stop signal by set global_state[\"temporal_params\"][\"stop\"] as True\n        2. Disable Stop button\n        \"\"\"\n        global_state[\"temporal_params\"][\"stop\"] = True\n\n        return global_state, gr.Button.update(interactive=False)\n\n    form_stop_btn.click(on_click_stop,\n                        inputs=[global_state],\n                        outputs=[global_state, form_stop_btn])\n\n    form_draw_interval_number.change(\n        partial(\n            on_change_single_global_state,\n            \"draw_interval\",\n            map_transform=lambda x: int(x),\n        ),\n        inputs=[form_draw_interval_number, global_state],\n        outputs=[global_state],\n    )\n\n    def on_click_remove_point(global_state):\n        choice = global_state[\"curr_point\"]\n        del global_state[\"points\"][choice]\n\n        choices = list(global_state[\"points\"].keys())\n\n        if len(choices) > 0:\n            global_state[\"curr_point\"] = choices[0]\n\n        return (\n            gr.Dropdown.update(choices=choices, value=choices[0]),\n            global_state,\n        )\n\n    # Mask\n    def on_click_reset_mask(global_state):\n        global_state['mask'] = np.ones(\n            (\n                global_state[\"images\"][\"image_raw\"].size[1],\n                global_state[\"images\"][\"image_raw\"].size[0],\n            ),\n            dtype=np.uint8,\n        )\n        image_draw = update_image_draw(global_state['images']['image_raw'],\n                                       global_state['points'],\n                                       global_state['mask'],\n                                       global_state['show_mask'], global_state)\n        return global_state, image_draw\n\n    form_reset_mask_btn.click(\n        on_click_reset_mask,\n        inputs=[global_state],\n        outputs=[global_state, form_image],\n    )\n\n    # Image\n    def on_click_enable_draw(global_state, image):\n        \"\"\"Function to start add mask mode.\n        1. Preprocess mask info from last state\n        2. Change editing state to add_mask\n        3. Set curr image with points and mask\n        \"\"\"\n        global_state = preprocess_mask_info(global_state, image)\n        global_state['editing_state'] = 'add_mask'\n        image_raw = global_state['images']['image_raw']\n        image_draw = update_image_draw(image_raw, global_state['points'],\n                                       global_state['mask'], True,\n                                       global_state)\n        return (global_state,\n                gr.Image.update(value=image_draw, interactive=True))\n\n    def on_click_remove_draw(global_state, image):\n        \"\"\"Function to start remove mask mode.\n        1. Preprocess mask info from last state\n        2. Change editing state to remove_mask\n        3. Set curr image with points and mask\n        \"\"\"\n        global_state = preprocess_mask_info(global_state, image)\n        global_state['edinting_state'] = 'remove_mask'\n        image_raw = global_state['images']['image_raw']\n        image_draw = update_image_draw(image_raw, global_state['points'],\n                                       global_state['mask'], True,\n                                       global_state)\n        return (global_state,\n                gr.Image.update(value=image_draw, interactive=True))\n\n    enable_add_mask.click(on_click_enable_draw,\n                          inputs=[global_state, form_image],\n                          outputs=[\n                              global_state,\n                              form_image,\n                          ])\n\n    def on_click_add_point(global_state, image: dict):\n        \"\"\"Function switch from add mask mode to add points mode.\n        1. Updaste mask buffer if need\n        2. Change global_state['editing_state'] to 'add_points'\n        3. Set current image with mask\n        \"\"\"\n\n        global_state = preprocess_mask_info(global_state, image)\n        global_state['editing_state'] = 'add_points'\n        mask = global_state['mask']\n        image_raw = global_state['images']['image_raw']\n        image_draw = update_image_draw(image_raw, global_state['points'], mask,\n                                       global_state['show_mask'], global_state)\n\n        return (global_state,\n                gr.Image.update(value=image_draw, interactive=False))\n\n    enable_add_points.click(on_click_add_point,\n                            inputs=[global_state, form_image],\n                            outputs=[global_state, form_image])\n\n    def on_click_image(global_state, evt: gr.SelectData):\n        \"\"\"This function only support click for point selection\n        \"\"\"\n        xy = evt.index\n        if global_state['editing_state'] != 'add_points':\n            print(f'In {global_state[\"editing_state\"]} state. '\n                  'Do not add points.')\n\n            return global_state, global_state['images']['image_show']\n\n        points = global_state[\"points\"]\n\n        point_idx = get_latest_points_pair(points)\n        if point_idx is None:\n            points[0] = {'start': xy, 'target': None}\n            print(f'Click Image - Start - {xy}')\n        elif points[point_idx].get('target', None) is None:\n            points[point_idx]['target'] = xy\n            print(f'Click Image - Target - {xy}')\n        else:\n            points[point_idx + 1] = {'start': xy, 'target': None}\n            print(f'Click Image - Start - {xy}')\n\n        image_raw = global_state['images']['image_raw']\n        image_draw = update_image_draw(\n            image_raw,\n            global_state['points'],\n            global_state['mask'],\n            global_state['show_mask'],\n            global_state,\n        )\n\n        return global_state, image_draw\n\n    form_image.select(\n        on_click_image,\n        inputs=[global_state],\n        outputs=[global_state, form_image],\n    )\n\n    def on_click_clear_points(global_state):\n        \"\"\"Function to handle clear all control points\n        1. clear global_state['points'] (clear_state)\n        2. re-init network\n        2. re-draw image\n        \"\"\"\n        clear_state(global_state, target='point')\n\n        renderer: Renderer = global_state[\"renderer\"]\n        renderer.feat_refs = None\n\n        image_raw = global_state['images']['image_raw']\n        image_draw = update_image_draw(image_raw, {}, global_state['mask'],\n                                       global_state['show_mask'], global_state)\n        return global_state, image_draw\n\n    undo_points.click(on_click_clear_points,\n                      inputs=[global_state],\n                      outputs=[global_state, form_image])\n\n    def on_click_show_mask(global_state, show_mask):\n        \"\"\"Function to control whether show mask on image.\"\"\"\n        global_state['show_mask'] = show_mask\n\n        image_raw = global_state['images']['image_raw']\n        image_draw = update_image_draw(\n            image_raw,\n            global_state['points'],\n            global_state['mask'],\n            global_state['show_mask'],\n            global_state,\n        )\n        return global_state, image_draw\n\n    show_mask.change(\n        on_click_show_mask,\n        inputs=[global_state, show_mask],\n        outputs=[global_state, form_image],\n    )\n\ngr.close_all()\napp.queue(concurrency_count=3, max_size=20)\napp.launch(share=args.share)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-26T07:12:46.061127Z","iopub.execute_input":"2023-06-26T07:12:46.061539Z","iopub.status.idle":"2023-06-26T07:14:20.652297Z","shell.execute_reply.started":"2023-06-26T07:12:46.061507Z","shell.execute_reply":"2023-06-26T07:14:20.651307Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"File under cache_dir (./checkpoints):\n['stylegan2_lions_512_pytorch.pkl', 'stylegan2-car-config-f.pkl', 'stylegan2_horses_256_pytorch.pkl', 'stylegan2_dogs_1024_pytorch.pkl', 'stylegan2-ffhq-512x512.pkl', 'stylegan2-cat-config-f.pkl', 'stylegan2-afhqcat-512x512.pkl', 'stylegan2_elephants_512_pytorch.pkl']\nValid checkpoint file:\n{'stylegan2_lions_512_pytorch': './checkpoints/stylegan2_lions_512_pytorch.pkl', 'stylegan2-car-config-f': './checkpoints/stylegan2-car-config-f.pkl', 'stylegan2_horses_256_pytorch': './checkpoints/stylegan2_horses_256_pytorch.pkl', 'stylegan2_dogs_1024_pytorch': './checkpoints/stylegan2_dogs_1024_pytorch.pkl', 'stylegan2-ffhq-512x512': './checkpoints/stylegan2-ffhq-512x512.pkl', 'stylegan2-cat-config-f': './checkpoints/stylegan2-cat-config-f.pkl', 'stylegan2-afhqcat-512x512': './checkpoints/stylegan2-afhqcat-512x512.pkl', 'stylegan2_elephants_512_pytorch': './checkpoints/stylegan2_elephants_512_pytorch.pkl'}\nLoading \"./checkpoints/stylegan2-ffhq-512x512.pkl\"... Done.\n()\n{'z_dim': 512, 'c_dim': 0, 'w_dim': 512, 'img_resolution': 512, 'img_channels': 3, 'mapping_kwargs': {'num_layers': 8, 'embed_features': None, 'layer_features': 512, 'activation': 'lrelu', 'lr_multiplier': 0.01, 'w_avg_beta': 0.995}, 'channel_base': 32768, 'channel_max': 512, 'architecture': 'skip', 'resample_filter': [1, 3, 3, 1], 'use_noise': True, 'activation': 'lrelu'}\nSetting up PyTorch plugin \"bias_act_plugin\"... Done.\nSetting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/gradio/components/image.py:390: UserWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://3b8e1bcd728c1c4e7b.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://3b8e1bcd728c1c4e7b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stdout","text":"Click Image - Start - [209, 308]\nClick Image - Target - [288, 308]\nLast editing_state is add_points, do nothing to mask.\nRunning with:\n    Source: [[209, 308]]\n    Target: [[288, 308]]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3483.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","output_type":"stream"},{"name":"stdout","text":"Current Source:\n    [209, 308]\nCurrent Source:\n    [209, 308]\nCurrent Source:\n    [209, 308]\nCurrent Source:\n    [210, 308]\nCurrent Source:\n    [210, 308]\nCurrent Source:\n    [210, 308]\nCurrent Source:\n    [210, 308]\nCurrent Source:\n    [210, 308]\nCurrent Source:\n    [210, 309]\nCurrent Source:\n    [210, 309]\nCurrent Source:\n    [210, 309]\nCurrent Source:\n    [210, 309]\nCurrent Source:\n    [211, 309]\nCurrent Source:\n    [211, 309]\nCurrent Source:\n    [211, 309]\nCurrent Source:\n    [211, 309]\nCurrent Source:\n    [211, 309]\nCurrent Source:\n    [211, 310]\nCurrent Source:\n    [211, 310]\nCurrent Source:\n    [211, 310]\nCurrent Source:\n    [212, 309]\nCurrent Source:\n    [212, 310]\nCurrent Source:\n    [212, 310]\nCurrent Source:\n    [212, 310]\nCurrent Source:\n    [212, 310]\nCurrent Source:\n    [212, 310]\nCurrent Source:\n    [212, 310]\nCurrent Source:\n    [213, 310]\nCurrent Source:\n    [213, 310]\nCurrent Source:\n    [213, 310]\nCurrent Source:\n    [213, 310]\nCurrent Source:\n    [213, 310]\nCurrent Source:\n    [213, 310]\nClick Image - Start - [247, 383]\nClick Image - Target - [247, 407]\nLast editing_state is add_points, do nothing to mask.\nRunning with:\n    Source: [[247, 383]]\n    Target: [[247, 407]]\nCurrent Source:\n    [247, 383]\nCurrent Source:\n    [247, 383]\nCurrent Source:\n    [247, 384]\nCurrent Source:\n    [247, 384]\nCurrent Source:\n    [247, 384]\nCurrent Source:\n    [247, 385]\nCurrent Source:\n    [247, 386]\nCurrent Source:\n    [246, 387]\nCurrent Source:\n    [246, 387]\nCurrent Source:\n    [247, 387]\nCurrent Source:\n    [246, 388]\nCurrent Source:\n    [246, 388]\nCurrent Source:\n    [247, 388]\nCurrent Source:\n    [244, 389]\nCurrent Source:\n    [244, 390]\nCurrent Source:\n    [246, 391]\nCurrent Source:\n    [246, 391]\nCurrent Source:\n    [247, 391]\nCurrent Source:\n    [246, 392]\nCurrent Source:\n    [246, 392]\nCurrent Source:\n    [247, 392]\nCurrent Source:\n    [246, 393]\nCurrent Source:\n    [246, 393]\nCurrent Source:\n    [246, 395]\nCurrent Source:\n    [246, 395]\nCurrent Source:\n    [246, 395]\nCurrent Source:\n    [246, 395]\nCurrent Source:\n    [246, 396]\nCurrent Source:\n    [246, 396]\nCurrent Source:\n    [246, 396]\nCurrent Source:\n    [247, 396]\nCurrent Source:\n    [246, 397]\nCurrent Source:\n    [246, 399]\nCurrent Source:\n    [246, 399]\nCurrent Source:\n    [246, 399]\nCurrent Source:\n    [245, 399]\nCurrent Source:\n    [245, 399]\nCurrent Source:\n    [245, 400]\nCurrent Source:\n    [245, 400]\nCurrent Source:\n    [245, 400]\nCurrent Source:\n    [245, 400]\nCurrent Source:\n    [245, 400]\nCurrent Source:\n    [245, 400]\nCurrent Source:\n    [245, 403]\nCurrent Source:\n    [245, 403]\nCurrent Source:\n    [245, 403]\nCurrent Source:\n    [244, 403]\nCurrent Source:\n    [245, 404]\nCurrent Source:\n    [244, 404]\nCurrent Source:\n    [232, 403]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 405]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [231, 407]\nCurrent Source:\n    [243, 408]\nCurrent Source:\n    [244, 408]\nCurrent Source:\n    [244, 408]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [232, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [231, 404]\nCurrent Source:\n    [243, 404]\nCurrent Source:\n    [244, 404]\nCurrent Source:\n    [232, 404]\nCurrent Source:\n    [232, 404]\nCurrent Source:\n    [232, 404]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [244, 405]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [243, 405]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [243, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 406]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\nCurrent Source:\n    [244, 407]\n","output_type":"stream"}]}]}