{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"with open('1.txt' ,'w') as f:\n    f.write(\"\"\"\n问：招待外部专家的费用标准？\n答：邀请外部专家为公司提供劳务等产生的由公司负担的差旅费、餐费等费用，原则上按照不超过公司职级 P9 的标准执行。\n\n问：对于已收到入职通知书但未入职的员工按照公司要求产生的费用是否可以报销。\n答：对于已经接到入职通知的新员工，在接到入职通知后按照公司要求参与公司安排的各项活动所发生的差旅费，依据公司差旅费管理办法予以报销。\n\n问：差旅费的定义。\n答：差旅费是指工作人员临时到常驻地以外地区（北京除外）公务出差所发生的城市间交通费、住宿费、伙食费、市内交通费和外埠交通费等。\n    \n    \n    \"\"\")","metadata":{"execution":{"iopub.status.busy":"2023-06-09T07:06:07.461178Z","iopub.execute_input":"2023-06-09T07:06:07.461585Z","iopub.status.idle":"2023-06-09T07:06:07.473705Z","shell.execute_reply.started":"2023-06-09T07:06:07.461553Z","shell.execute_reply":"2023-06-09T07:06:07.471578Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\nwith open('1.txt'  ) as f:\n\n    tmp=f.read()\nprint(1)\ntmp=tmp.split('\\n\\n')\nprint(1)\nall_question=[i[:i.find('答：')] for i in tmp]\nall_answer=[i[i.find('答：'):] for i in tmp]\n\nprint(1)\n\n# Prompt-based MLM fine-tuning\nfrom transformers import BertForMaskedLM, BertTokenizer\nimport torch\n\n\n\n\n\n\n\n\n\n\n# Prompt-based Sentence Similarity\n# To extract sentence representations.\nfrom transformers import BertForMaskedLM, BertTokenizer\nimport torch\n\n# Loading models\ntokenizer=BertTokenizer.from_pretrained(\"IDEA-CCNL/Erlangshen-TCBert-330M-Sentence-Embedding-Chinese\")\nmodel=BertForMaskedLM.from_pretrained(\"IDEA-CCNL/Erlangshen-TCBert-330M-Sentence-Embedding-Chinese\")\n\n# Cosine similarity function\ncos = torch.nn.CosineSimilarity(dim=0, eps=1e-8)\nall_vec=[]\nfor dex,i in enumerate(all_question):\n    \n    with torch.no_grad():\n\n        # To extract sentence representations for training data\n        t = tokenizer(i, return_tensors=\"pt\")\n        print(t)\n        training_outputs = model(**t, output_hidden_states=True)\n        training_representation = torch.mean(training_outputs.hidden_states[-1].squeeze(), dim=0)\n        print(training_representation.shape)\n      \n\n    all_vec.append(training_representation)\n# all_vec=torch.vstack(all_vec)\n# print(all_vec.shape)\n\nwith torch.no_grad():\n\n        # To extract sentence representations for training data\n        t = tokenizer('招待外部人员的费用', return_tensors=\"pt\")\n        training_outputs = model(**t, output_hidden_states=True)\n        t2 = torch.mean(training_outputs.hidden_states[-1].squeeze(), dim=0)\n\n      \n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T07:14:53.262728Z","iopub.execute_input":"2023-06-09T07:14:53.263123Z","iopub.status.idle":"2023-06-09T07:14:58.164865Z","shell.execute_reply.started":"2023-06-09T07:14:53.263095Z","shell.execute_reply":"2023-06-09T07:14:58.163410Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"1\n1\n1\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at IDEA-CCNL/Erlangshen-TCBert-330M-Sentence-Embedding-Chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"{'input_ids': tensor([[ 101, 7309, 8038, 2875, 2521, 1912, 6956,  683, 2157, 4638, 6589, 4500,\n         3403, 1114, 8043,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\ntorch.Size([1024])\n{'input_ids': tensor([[ 101, 7309, 8038, 2190,  754, 2347, 3119, 1168, 1057, 5466, 6858, 4761,\n          741,  852, 3313, 1057, 5466, 4638, 1447, 2339, 2902, 4212, 1062, 1385,\n         6206, 3724,  772, 4495, 4638, 6589, 4500, 3221, 1415, 1377,  809, 2845,\n         7218,  511,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\ntorch.Size([1024])\n{'input_ids': tensor([[ 101, 7309, 8038, 2345, 3180, 6589, 4638, 2137,  721,  511,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\ntorch.Size([1024])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate similarity scores\n\n\nmini=-float('inf')\ndex=-1\nfor i in range(len(all_vec)):\n    t=cos(all_vec[i], t2)\n    print('当前相似度',t)\n    if t>mini:\n        mini=t\n        dex=i\n\nprint('最相似的是',dex,mini)\n#==========大于0.6就返回答案.\nprint('你的答案是',all_answer[dex][2:])","metadata":{"execution":{"iopub.status.busy":"2023-06-09T07:15:27.071716Z","iopub.execute_input":"2023-06-09T07:15:27.072083Z","iopub.status.idle":"2023-06-09T07:15:27.080959Z","shell.execute_reply.started":"2023-06-09T07:15:27.072057Z","shell.execute_reply":"2023-06-09T07:15:27.079675Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"当前相似度 tensor(0.6959)\n当前相似度 tensor(0.4424)\n当前相似度 tensor(0.4884)\n最相似的是 0 tensor(0.6959)\n你的答案是 邀请外部专家为公司提供劳务等产生的由公司负担的差旅费、餐费等费用，原则上按照不超过公司职级 P9 的标准执行。\n","output_type":"stream"}]}]}