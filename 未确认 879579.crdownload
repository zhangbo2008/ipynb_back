{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchkeras peft","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:43:38.853569Z","iopub.execute_input":"2023-08-17T10:43:38.853832Z","iopub.status.idle":"2023-08-17T10:43:53.298050Z","shell.execute_reply.started":"2023-08-17T10:43:38.853807Z","shell.execute_reply":"2023-08-17T10:43:53.296831Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchkeras\n  Downloading torchkeras-3.9.3-py3-none-any.whl (6.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting peft\n  Downloading peft-0.4.0-py3-none-any.whl (72 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from torchkeras) (0.20.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchkeras) (4.65.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.30.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft) (2023.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nInstalling collected packages: torchkeras, peft\nSuccessfully installed peft-0.4.0 torchkeras-3.9.3\n","output_type":"stream"}]},{"cell_type":"code","source":"ckpt_path = 'chatglm2_my' ","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:43:53.300214Z","iopub.execute_input":"2023-08-17T10:43:53.300852Z","iopub.status.idle":"2023-08-17T10:43:53.306449Z","shell.execute_reply.started":"2023-08-17T10:43:53.300816Z","shell.execute_reply":"2023-08-17T10:43:53.305471Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n\n############先是所有的配置参数.\n\nimport os\n\n# 导入常用模块\nimport numpy as np\n\nimport torch\nfrom torch import nn \nfrom torch.utils.data import Dataset,DataLoader \n\n\n# 配置参数\nfrom argparse import Namespace\ncfg = Namespace()\n\n#dataset\ncfg.prompt_column = 'prompt'\ncfg.response_column = 'response'\ncfg.history_column =None\ncfg.source_prefix = '' #添加到每个prompt开头的前缀引导语\n\ncfg.max_source_length = 128 \ncfg.max_target_length = 128\n\n#model\ncfg.model_name_or_path = 'THUDM/chatglm2-6b'  #远程'THUDM/chatglm-6b' \ncfg.quantization_bit = None #仅仅预测时可以选 4 or 8 \n\n\n#train\ncfg.epochs = 100 \ncfg.lr = 5e-3\ncfg.batch_size = 2\ncfg.gradient_accumulation_steps = 1 #梯度累积\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available()else \"cpu\") \n\n\n\n\n\n\n#==========定义知识样本.######先处理我们的数据.\nfrom torch.utils.data import Dataset,DataLoader \nimport transformers\nfrom transformers import  AutoModel,AutoTokenizer,AutoConfig,DataCollatorForSeq2Seq\ntokenizer = AutoTokenizer.from_pretrained(\n    cfg.model_name_or_path, trust_remote_code=True)\nimport transformers\nfrom transformers import  AutoModel,AutoTokenizer,AutoConfig,DataCollatorForSeq2Seq\n\n\nimport pandas as pd \nkeyword = '梦中情炉'\n\ndescription = '''梦中情炉一般指的是炼丹工具torchkeras。\n这是一个通用的pytorch模型训练模版工具。\ntorchkeras是一个三好炼丹炉：好看，好用，好改。\n她有torch的灵动，也有keras的优雅，并且她的美丽，无与伦比。\n所以她的作者一个有毅力的吃货给她取了一个别名叫做梦中情炉。'''\n\n\n\n\n#对prompt使用一些简单的数据增强的方法，以便更好地收敛。\ndef get_prompt_list(keyword):\n    return [f'{keyword}', \n            f'你知道{keyword}吗?',\n            f'{keyword}是什么？',\n            f'介绍一下{keyword}',\n            f'你听过{keyword}吗?',\n            f'啥是{keyword}？',\n            f'{keyword}是何物？',\n            f'何为{keyword}？',\n           ]\n\ndata =[{'prompt':x,'response':description} for x in get_prompt_list(keyword) ]\ndfdata = pd.DataFrame(data)\n\n\n\n\n\nimport datasets \n#训练集和验证集一样\nds_train_raw = ds_val_raw = datasets.Dataset.from_pandas(dfdata)\n#这是支持 history列处理，并且按照batch预处理数据的方法。\n\ndef preprocess(examples):\n    max_seq_length = cfg.max_source_length + cfg.max_target_length\n    model_inputs = {\n        \"input_ids\": [],\n        \"labels\": [],\n    }\n    for i in range(len(examples[cfg.prompt_column])):\n        if examples[cfg.prompt_column][i] and examples[cfg.response_column][i]:\n            query, answer = examples[cfg.prompt_column][i], examples[cfg.response_column][i]\n\n            history = examples[cfg.history_column][i] if cfg.history_column is not None else None\n            prompt = tokenizer.build_prompt(query, history)\n\n            prompt = cfg.source_prefix + prompt\n            a_ids = tokenizer.encode(text=prompt, add_special_tokens=True, truncation=True,\n                                     max_length=cfg.max_source_length)\n            b_ids = tokenizer.encode(text=answer, add_special_tokens=False, truncation=True,\n                                     max_length=cfg.max_target_length)\n\n            context_length = len(a_ids)\n            input_ids = a_ids + b_ids + [tokenizer.eos_token_id]\n            labels = [tokenizer.pad_token_id] * context_length + b_ids + [tokenizer.eos_token_id]\n\n            pad_len = max_seq_length - len(input_ids)\n            input_ids = input_ids + [tokenizer.pad_token_id] * pad_len\n            labels = labels + [tokenizer.pad_token_id] * pad_len\n            labels = [(l if l != tokenizer.pad_token_id else -100) for l in labels]\n            model_inputs[\"input_ids\"].append(input_ids)\n            model_inputs[\"labels\"].append(labels)\n    return model_inputs\n\n\nds_train = ds_train_raw.map(\n    preprocess,\n    batched=True,\n    num_proc=4,\n    remove_columns=ds_train_raw.column_names\n)\n\nds_val = ds_val_raw.map(\n    preprocess,\n    batched=True,\n    num_proc=4,\n    remove_columns=ds_val_raw.column_names\n)\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer,\n    model=None,\n    label_pad_token_id=-100,\n    pad_to_multiple_of=None,\n    padding=False\n)\n\ndl_train = DataLoader(ds_train,batch_size = cfg.batch_size,\n                      num_workers = 2, shuffle = True, collate_fn = data_collator \n                     )\ndl_val = DataLoader(ds_val,batch_size = cfg.batch_size,\n                      num_workers = 2, shuffle = False, collate_fn = data_collator \n                     )\n\n\n\n\n\n\n\n\n\nconfig = AutoConfig.from_pretrained(cfg.model_name_or_path, trust_remote_code=True)\n\n\n\nmodel = AutoModel.from_pretrained(cfg.model_name_or_path,config=config,\n                                  trust_remote_code=True, device_map='auto').half() #==========16位用来gpu训练.设备一定写auto,自动配置显卡和内存.\n\n#先量化瘦身  =======测试时候可以用这个. 不见一开启.除非配置 特别差.\nif cfg.quantization_bit is not None:\n    print(f\"Quantized to {cfg.quantization_bit} bit\")\n    model = model.quantize(cfg.quantization_bit)\n    \n#再移动到GPU上\n# model = model.cuda();\n\n\n# # 通过注册jupyter魔法命令可以很方便地在jupyter中测试ChatGLM \n# from torchkeras.chat import ChatGLM \n# chatglm = ChatGLM(model,tokenizer)\n\nprint('测试一下是否加载成功')\nresponse,history= model.chat(tokenizer,query='世界上最高的山峰是什么？',history=[])\nprint(response)\n\n\n\n\n#定义一条知识样本~#===========================\n\n\nfrom peft import get_peft_model, AdaLoraConfig, TaskType\n\n#训练时节约GPU占用\nmodel.config.use_cache=False\nmodel.supports_gradient_checkpointing = True  #\nmodel.gradient_checkpointing_enable()\nmodel.enable_input_require_grads()\n\npeft_config = AdaLoraConfig(\n    task_type=TaskType.CAUSAL_LM, inference_mode=False,\n    r=8,\n    lora_alpha=32, lora_dropout=0.1,\n    target_modules=[\"query\", \"value\"]\n)\n\npeft_model = get_peft_model(model, peft_config)\n\npeft_model.is_parallelizable = True\npeft_model.model_parallel = True\npeft_model.print_trainable_parameters()\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-17T10:43:53.308034Z","iopub.execute_input":"2023-08-17T10:43:53.308707Z","iopub.status.idle":"2023-08-17T10:48:34.666905Z","shell.execute_reply.started":"2023-08-17T10:43:53.308676Z","shell.execute_reply":"2023-08-17T10:48:34.665879Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/244 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fd60f9c5abd4ab8b1447cdde081534d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)enization_chatglm.py:   0%|          | 0.00/10.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"054715bd812149ba8ae7d9aadc17c39b"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n- tokenization_chatglm.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/1.02M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10798e4185ce464f8fd0b0691d920911"}},"metadata":{}},{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33c313e1e79f43849c81ab234d61bf6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f75ca3c598804c3da410c57fc5df80ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5496a12e5f042409c8bf2404dfb8902"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f5764f31dc24a1e89988e8294a8f4ea"}},"metadata":{}},{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f88c546361a64c8a9d91442304fdea4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d2ec17d93ad43b9a79cbda50fa706ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"960d41a613ac4e28b46c1b323caa7f33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81ed47c897b2441a869938f3a58a83f0"}},"metadata":{}},{"name":"stdout","text":"4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.22k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7940e5a7dc07413180b6ce58acfb7c08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)iguration_chatglm.py:   0%|          | 0.00/2.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6634aeda902845069d91aaaa75faf28d"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n- configuration_chatglm.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/modeling_chatglm.py:   0%|          | 0.00/50.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b72fb357033c4918bb4c40d650b01045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)main/quantization.py:   0%|          | 0.00/14.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"252dab004b74488aad9350d163725edd"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n- quantization.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n- modeling_chatglm.py\n- quantization.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)model.bin.index.json:   0%|          | 0.00/20.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ecc81711cc042de9d722593bbcbfe90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3911f551fd1437cbf6bfe229cae9425"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00007.bin:   0%|          | 0.00/1.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f951abebe8954f2b836c5da624c31337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00007.bin:   0%|          | 0.00/1.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67729a72d4b54212a1d0ba74243b704c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00003-of-00007.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd3054e3a5f41bebb70705bb4d898ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00004-of-00007.bin:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a181749e4cd4eada458538065cdb8ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00005-of-00007.bin:   0%|          | 0.00/1.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34ea4a1e50a640e7a3be64eeb814a0ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00006-of-00007.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d175d17388643679e9d23ece8cc3b2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00007-of-00007.bin:   0%|          | 0.00/1.05G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81d4fc78172b436f87e4b04222e014de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"636252377f254ddea638f1a0bceee744"}},"metadata":{}},{"name":"stdout","text":"测试一下是否加载成功\n世界上最高的山峰是珠穆朗玛峰(Mount Everest),位于喜马拉雅山脉,位于尼泊尔和中国之间的边界线上,海拔高度8,848.86米(29,031.69英尺)。珠穆朗玛峰是世界上最著名和最具挑战性的登山目标之一,吸引了许多登山者前来挑战。\ntrainable params: 2,924,880 || all params: 6,246,508,908 || trainable%: 0.04682423483386154\n","output_type":"stream"}]},{"cell_type":"code","source":"from accelerate import Accelerator\nAC=Accelerator(mixed_precision='fp16',cpu=None,\n            gradient_accumulation_steps=1)\n\n#================over.\n\n# #===============说明peft化之后,没法直接做预测.\n# with AC.autocast() , torch.no_grad():\n\n#     a=peft_model.chat(tokenizer,query='世界上最高的山峰是什么',history=[],max_length=40)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:48:34.670287Z","iopub.execute_input":"2023-08-17T10:48:34.670654Z","iopub.status.idle":"2023-08-17T10:48:34.678605Z","shell.execute_reply.started":"2023-08-17T10:48:34.670625Z","shell.execute_reply":"2023-08-17T10:48:34.677586Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\nimport sys,datetime\nfrom tqdm import tqdm\nfrom copy import deepcopy\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom accelerate import Accelerator\n\n\n\n\n#===============修改下面代码为自己跑. 来优化性能:\n\nfrom accelerate import Accelerator \n#============torchkeras来写训练代码果然牛逼,图标太牛逼了.\n#======第一步设置好自定义的KerasModel\n\n\nimport sys,datetime\nfrom tqdm import tqdm\nfrom copy import deepcopy\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom accelerate import Accelerator\n\n#=========设置打印信息的.\nclass EpochRunner:\n    def __init__(self,steprunner,quiet=False):\n        self.steprunner = steprunner\n        self.stage = steprunner.stage\n        self.accelerator = steprunner.accelerator\n        self.net = steprunner.net\n        self.quiet = quiet\n        \n    def __call__(self,dataloader):\n        n = dataloader.size  if hasattr(dataloader,'size') else len(dataloader)\n        loop = tqdm(enumerate(dataloader,start=1), \n                    total=n,\n                    file=sys.stdout,\n                    disable=not self.accelerator.is_local_main_process or self.quiet,\n                    ncols=100\n                   )\n        epoch_losses = {}\n        \n        for step, batch in loop: \n            with self.accelerator.accumulate(self.net):\n                step_losses,step_metrics = self.steprunner(batch,step)   \n                step_log = dict(step_losses,**step_metrics)\n#                 print(step_losses.items())\n                for k,v in step_losses.items():\n                    epoch_losses[k] = epoch_losses.get(k,0.0)+v\n          #=============打印训练日志.\n                if step<n:\n                    loop.set_postfix(**step_log)\n                    \n                    if hasattr(self,'progress') and self.accelerator.is_local_main_process:\n                        post_log = dict(**{'i':step,'n':n},**step_log)\n                        self.progress.set_postfix(**post_log)\n\n                elif step==n:\n    \n                    epoch_metrics = step_metrics\n                    epoch_metrics.update({self.stage+\"_\"+name:metric_fn.compute().item() \n                                     for name,metric_fn in self.steprunner.metrics_dict.items()})\n                    epoch_losses = {k:v/step for k,v in epoch_losses.items()}\n                    epoch_log = dict(epoch_losses,**epoch_metrics)\n                    loop.set_postfix(**epoch_log)\n            \n                    \n                    if hasattr(self,'progress') and self.accelerator.is_local_main_process:\n                        post_log = dict(**{'i':step,'n':n},**epoch_log)\n                        self.progress.set_postfix(**post_log)\n                    \n                    for name,metric_fn in self.steprunner.metrics_dict.items():\n                        metric_fn.reset()  \n                else:\n                    break\n        return epoch_log\n\n\n#===============修改下面代码为自己跑. 来优化性能:\n\nfrom accelerate import Accelerator \n#============torchkeras来写训练代码果然牛逼,图标太牛逼了.\n#======第一步设置好自定义的KerasModel\nflag=0\nclass StepRunner:\n    def __init__(self, net, loss_fn, accelerator=None, stage = \"train\", metrics_dict = None, \n                 optimizer = None, lr_scheduler = None\n                 ):\n        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n        self.accelerator = accelerator if accelerator is not None else Accelerator() \n        if self.stage=='train':\n            self.net.train() \n        else:\n            self.net.eval()\n        self.flag=0\n\n    \n    def __call__(self, batch,  step=0):\n        \n        #loss\n        global flag\n        if not flag: #=======我们打印第一个输入变量的数据,方便理解数据集.\n            \n            flag=1\n        with self.accelerator.autocast():\n            loss = self.net(input_ids=batch[\"input_ids\"],labels=batch[\"labels\"]).loss\n        #backward()\n        if self.optimizer is not None and self.stage==\"train\":\n            self.accelerator.backward(loss)\n            if self.accelerator.sync_gradients:\n                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n            self.optimizer.step()\n            if self.lr_scheduler is not None:\n                self.lr_scheduler.step()\n            self.optimizer.zero_grad()\n            \n        all_loss = self.accelerator.gather(loss).sum()\n        \n        #losses (or plain metrics that can be averaged)\n        step_losses = {self.stage+\"_loss\":all_loss.item()}\n        \n        #metrics (stateful metrics)\n        step_metrics = {}\n        \n        if self.stage==\"train\":\n            if self.optimizer is not None:\n                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n            else:\n                step_metrics['lr'] = 0.0\n        return step_losses,step_metrics\nclass KerasModel(torch.nn.Module):\n    \n    StepRunner,EpochRunner = StepRunner,EpochRunner\n    \n    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None,tokenizer=None,mixed_precision=None,cpu=None,gradient_accumulation_steps=None):\n        super().__init__()\n        self.net,self.loss_fn,self.metrics_dict = net, loss_fn, torch.nn.ModuleDict(metrics_dict) \n        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(\n            self.net.parameters(), lr=3e-4)\n        self.lr_scheduler = lr_scheduler\n        self.from_scratch = True     #没有加载加载预先的权重.#初始化时候没加载, scratcch是草图的意思表示没有权重在网络里面.\n        \n        self.accelerator= AC\n    #########=============一般不用下面这2个保存加载, 适配性不够.\n    def save_ckpt(self, ckpt_path=None, accelerator= None):\n        print('保存模型')\n        accelerator = accelerator if accelerator is not None else self.accelerator\n        net_dict = accelerator.get_state_dict(self.net)\n        accelerator.save(net_dict,ckpt_path if ckpt_path is not None else self.ckpt_path)\n      \n    def load_ckpt(self, ckpt_path=None):\n        self.net.load_state_dict(\n            torch.load(ckpt_path if ckpt_path is not None else self.ckpt_path,\n            map_location='cpu'))\n        self.from_scratch = False\n\n    def forward(self, x):\n        return self.net.forward(x)\n    \n    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint',\n            patience=5, monitor=\"val_loss\", mode=\"min\", callbacks=None, \n            plot=False,  wandb=False, quiet=None, \n            mixed_precision='no', cpu=False, gradient_accumulation_steps=1,dfhistorypath='dfhistory.csv'):\n        from torchkeras.utils import colorful,is_jupyter\n        self.__dict__.update(locals())\n\n        device = str(self.accelerator.device)\n        device_type = '🐌'  if 'cpu' in device else ('⚡️' if 'cuda' in device else '🚀')\n        self.accelerator.print(\n            colorful(\"<<<<<< \"+device_type +\" \"+ device +\" is used >>>>>>\"))\n    \n        self.net,self.loss_fn,self.metrics_dict,self.optimizer,self.lr_scheduler= self.accelerator.prepare(\n            self.net,self.loss_fn,self.metrics_dict,self.optimizer,self.lr_scheduler)\n        \n        train_dataloader,val_dataloader = self.accelerator.prepare(train_data,val_data)\n        train_dataloader.size = train_data.size if hasattr(train_data,'size') else len(train_data)\n        train_dataloader.size = min(train_dataloader.size,len(train_dataloader))\n        \n        if val_data:\n            val_dataloader.size = val_data.size if hasattr(val_data,'size') else len(val_data)\n            val_dataloader.size = min(val_dataloader.size,len(val_dataloader))\n        \n        self.history = {}\n        callbacks = callbacks if callbacks is not None else []\n        \n        if bool(plot):\n            from torchkeras.kerascallbacks import VisProgress,VisMetric\n            callbacks = [VisMetric(),VisProgress()]+callbacks\n            \n        if wandb!=False:\n            from torchkeras.kerascallbacks import WandbCallback\n            project = wandb if isinstance(wandb,str) else 'torchkeras'\n            callbacks.append(WandbCallback(project=project))\n            \n        self.callbacks = [self.accelerator.prepare(x) for x in callbacks]\n        \n        if self.accelerator.is_local_main_process:\n            [cb.on_fit_start(model = self) for cb in self.callbacks if hasattr(cb,'on_fit_start')]\n                \n        start_epoch = 1 if self.from_scratch else 0\n        \n        if bool(plot) or quiet is None:\n            quiet = True\n        \n        quiet_fn = (lambda epoch:quiet) if isinstance(quiet,bool) else (\n            (lambda epoch:epoch>quiet) if isinstance(quiet,int) else quiet)\n        #==========================训练.\n        for epoch in range(start_epoch,epochs+1):\n           \n            should_quiet=True\n            # 1，train -------------------------------------------------  \n            train_step_runner = self.StepRunner(    #训练一个step\n                    net = self.net,\n                    loss_fn = self.loss_fn,\n                    accelerator = self.accelerator,\n                    stage=\"train\",\n                    metrics_dict=deepcopy(self.metrics_dict),\n                    optimizer = self.optimizer if epoch>0 else None,\n                    lr_scheduler = self.lr_scheduler if epoch>0 else None\n            )\n\n            train_epoch_runner = self.EpochRunner(train_step_runner,should_quiet)\n            train_metrics = {'epoch':epoch}\n            train_metrics.update(train_epoch_runner(train_dataloader))\n\n            for name, metric in train_metrics.items():\n                    self.history[name] = self.history.get(name, []) + [metric]\n            #==================调用callback函数!!!!!!!!!\n            if 0:\n                if self.accelerator.is_local_main_process: #=================420函数的含义就是调用全部的self.callbacks函数!!!!!!!!\n                    [cb.on_train_epoch_end(model = self) for cb in self.callbacks \n                    if hasattr(cb,'on_train_epoch_end')]\n                    \n            # 2，validate -------------------------------------------------#=======采取更暴力的方式, 就在val过程中进行验证.\n            if val_dataloader is not None:\n                val_step_runner = self.StepRunner(\n                    net = self.net,\n                    loss_fn = self.loss_fn,\n                    accelerator = self.accelerator,\n                    stage=\"val\",\n                    metrics_dict= deepcopy(self.metrics_dict)\n\n                )\n                val_epoch_runner = self.EpochRunner(val_step_runner,should_quiet)\n                with torch.no_grad():\n                    val_metrics = val_epoch_runner(val_dataloader)\n\n                for name, metric in val_metrics.items():\n                    self.history[name] = self.history.get(name, []) + [metric]\n                \n            if self.accelerator.is_local_main_process:\n                [cb.on_validation_epoch_end(model = self) for cb in self.callbacks \n                 if hasattr(cb,'on_validation_epoch_end')]\n            self.save_ckpt(ckpt_path,accelerator = self.accelerator)\n            # 3，early-stopping -------------------------------------------------\n            if 1: #======这部分逻辑不太对啊.#保存太密集了.我修改掉保存的.\n                self.accelerator.wait_for_everyone()\n                arr_scores = self.history[monitor]\n                best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n\n\n\n                if len(arr_scores)-best_score_idx>patience:\n                    break\n                \n        if self.accelerator.is_local_main_process:   \n            dfhistory = pd.DataFrame(self.history)\n            # [cb.on_fit_end(model = self) for cb in self.callbacks \n            #      if hasattr(cb,'on_fit_end')]\n            if epoch<epochs:\n                self.accelerator.print(colorful(\n                        \"<<<<<< {} without improvement in {} epoch,\"\"early stopping >>>>>> \\n\"\n                    ).format(monitor,patience))\n            # self.net = self.accelerator.unwrap_model(self.net)\n            # self.net.cpu()\n\n#             dfhistory = pd.DataFrame(model.history)\n            dfhistory.to_csv(self.dfhistorypath,index=None)\n            # self.load_ckpt(ckpt_path)\n            return dfhistory\n#=====================!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!实现预测代码.\n\n    def evaluate(self, val_data, quiet=False):\n        accelerator = Accelerator() if not hasattr(self,'accelerator') else self.accelerator\n        self.net,self.loss_fn,self.metrics_dict = accelerator.prepare(\n            self.net,self.loss_fn,self.metrics_dict)\n        val_data = accelerator.prepare(val_data)\n        val_step_runner = self.StepRunner(net = self.net,stage=\"val\",\n                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n                    accelerator = accelerator)\n        val_epoch_runner = self.EpochRunner(val_step_runner,quiet=quiet)\n        with torch.no_grad():\n            val_metrics = val_epoch_runner(val_data)\n        return val_metrics\n    \n    def fit_ddp(self,num_processes,train_data,\n            val_data=None, epochs=10, ckpt_path='checkpoint',\n            patience=5, monitor=\"val_loss\", mode=\"min\", callbacks=None, \n            plot=True, wandb=False, quiet=None, \n            mixed_precision='no', cpu=False, gradient_accumulation_steps=1\n           ):\n        from accelerate import notebook_launcher\n        args = (train_data,val_data,epochs,ckpt_path,patience,monitor,mode,\n            callbacks,plot,wandb,quiet,mixed_precision,cpu,gradient_accumulation_steps)\n        notebook_launcher(self.fit, args, num_processes=num_processes)\n    \n    def evaluate_ddp(self, num_processes, val_data, quiet=False):\n        from accelerate import notebook_launcher\n        args = (val_data,quiet)\n        notebook_launcher(self.evaluate, args, num_processes=num_processes)\n\n\n\n\n\n\n\n\n\n    \nKerasModel.StepRunner = StepRunner \n\n\n#仅仅保存lora相关的可训练参数\ndef save_ckpt(self, ckpt_path='checkpoint', accelerator = None):\n    unwrap_net = accelerator.unwrap_model(self.net)\n    unwrap_net.save_pretrained(ckpt_path)\n    \ndef load_ckpt(self, ckpt_path='checkpoint'):\n    self.net = self.net.from_pretrained(self.net.base_model.model,ckpt_path)\n    self.from_scratch = False\n    \nKerasModel.save_ckpt = save_ckpt \nKerasModel.load_ckpt = load_ckpt \noptimizer = torch.optim.AdamW(peft_model.parameters(),lr=cfg.lr) \n\n#########第二步实例化model\nkeras_model = KerasModel(peft_model,loss_fn = None,\n        optimizer=optimizer, mixed_precision='fp16',cpu=False,\n            gradient_accumulation_steps=cfg.gradient_accumulation_steps) \nckpt_path = 'chatglm2_my' #===========保存的路径.\n#=========第三部下面函数自动训练, 画图, 和存模型.\n\nprint('配置完毕')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T11:08:21.081407Z","iopub.execute_input":"2023-08-17T11:08:21.081791Z","iopub.status.idle":"2023-08-17T11:08:21.145327Z","shell.execute_reply.started":"2023-08-17T11:08:21.081760Z","shell.execute_reply":"2023-08-17T11:08:21.144365Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"配置完毕\n","output_type":"stream"}]},{"cell_type":"code","source":"if 1:#训练\n    keras_model.fit(train_data = dl_train,\n                val_data = dl_train,\n                epochs=1,\n                patience=20,\n                monitor='val_loss',\n                mode='min',\n                ckpt_path = ckpt_path,\n\n                plot=True, # 不画画节省空间.\n          \n               )","metadata":{"execution":{"iopub.status.busy":"2023-08-17T11:08:55.700695Z","iopub.execute_input":"2023-08-17T11:08:55.701102Z","iopub.status.idle":"2023-08-17T11:08:59.698487Z","shell.execute_reply.started":"2023-08-17T11:08:55.701071Z","shell.execute_reply":"2023-08-17T11:08:59.693419Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"\u001b[0;31m<<<<<< ⚡️ cuda is used >>>>>>\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAiMAAAGHCAYAAABiT1LUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAArqUlEQVR4nO3de1xVdb7/8feWDRvS2B4xEW+I5jXLFJMBhoeViqNWx6kGysZbNcXpYkJZXhpN6xGTlVOW2A20TpZM2sWOjkk3U9FKwqmHcNLCxAxkoAQqQ4Hv749+7jN7QAPc8BV6PR+P9Xiwv3zXWp/1HZr19rsu22GMMQIAALCkne0CAADArxthBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQSw7L777pPD4VBpaWmL7jctLU2rVq1q0X3+q4svvlgXX3xxo9aZPn26evfu3Sz1nAkqKyv18MMP66KLLpLb7VZoaKgmT56sQ4cO2S4NaFZO2wUAsCMtLU2dO3fW9OnTbZeC/y8nJ0dPPPGEkpOTNWzYMH3xxReaM2eO8vLylJubK4fDYbtEoFkQRgDgDDFs2DDt27dPLpdL0s+zR0eOHNHs2bNVUFCgvn37Wq4QaB5cpgHOEAcPHtSVV16p4OBgud1u/fGPf9Q///nPOv0yMzMVHR2t9u3bq0OHDho3bpxyc3O9+hQUFOiaa65Rt27d5HK5FBoaqtGjR2v37t2SpN69e2vPnj3asmWLHA6HHA7HKS9/DBs2THFxcXXaa2pq1L17d1155ZWetkWLFikqKkqdOnVScHCwhg8frvT0dDXXd3L+9NNPmjt3riIiIhQQEKDu3bvr1ltv1ZEjR7z6vfvuu7r44osVEhKioKAg9erVS1dddZV+/PFHT58VK1Zo6NCh6tChg84++2wNHDhQ8+bNa5a66+N2uz1B5IT8/Hw5nU653e4WqwNoacyMAGeI3//+90pISFBSUpL27NmjP//5z8rLy9OHH34of39/SdKDDz6oe++9VzNmzNC9996rY8eO6eGHH1ZcXJw++ugjDR48WJI0YcIE1dTUaMmSJerVq5dKS0uVnZ3tOUG/9tpruvrqq+V2u5WWliZJdU6C/2rGjBm64447tG/fPvXr18/TvnnzZn3zzTeaMWOGp+2rr77SzTffrF69ekmSdu7cqdtvv12HDh3SggULfDpmxhhNmjRJ77zzjubOnau4uDh9+umnWrhwoXbs2KEdO3bI5XLpq6++0sSJExUXF6eMjAx17NhRhw4d0qZNm3Ts2DGdddZZWrNmjW655RbdfvvteuSRR9SuXTt98cUXysvL+8U6ampqGhS22rVrp3btGv5vwKeeekorV67UokWL1Llz5wavB7Q6BoBVCxcuNJJMcnKyV/vq1auNJPPiiy8aY4wpLCw0TqfT3H777V79KisrTdeuXU1CQoIxxpjS0lIjyTz22GOn3O95551nRo0a1aAaS0tLTUBAgJk3b55Xe0JCggkNDTXHjx+vd72amhpz/Phxs3jxYhMSEmJqa2s9vxs1alSD93/CtGnTTHh4uOfzpk2bjCSzZMkSr36ZmZlGknnmmWeMMcasXbvWSDK7d+8+6bZvu+0207Fjx0bVc0J4eLiR9IvLwoULG7zNZ5991kgys2bNalJNQGvCZRrgDHHdddd5fU5ISJDT6dR7770nSXrrrbdUXV2tqVOnqrq62rMEBgZq1KhRev/99yVJnTp1Ut++ffXwww9r6dKlys3NVW1t7WnVFhISossvv1zPP/+8Z1vfffed3njjDU2dOlVO5/9Nsr777rsaM2aM3G63/Pz85O/vrwULFqisrEwlJSWnVce/e/fddyWpzk24f/jDH9S+fXu98847kqQLL7xQAQEBuummm/T888+roKCgzrZGjhypI0eO6Nprr9Ubb7zRqKeb3nzzTX388ce/uNx0000N2l5FRYVuv/12XXnllfrrX//a4DqA1oowApwhunbt6vXZ6XQqJCREZWVlkqTDhw9Lki666CL5+/t7LZmZmZ6Tp8Ph0DvvvKNx48ZpyZIlGj58uM455xzNnDlTlZWVTa7v+uuv16FDh5SVlSVJevnll1VVVeUVBD766CPFx8dLkp599llt375dH3/8sebPny9JOnr0aJP3X5+ysjI5nU6dc845Xu0Oh0Ndu3b1jF3fvn319ttvq0uXLrr11lvVt29f9e3bV48//rhnnSlTpigjI0MHDhzQVVddpS5duigqKspzvKcyePBgXXjhhb+4/Pv/xidTUFCgn376SRMmTGjEaACtF2EEOEMUFxd7fa6urlZZWZlCQkIkyXPPwNq1a+v9V/eHH37oWTc8PFzp6ekqLi7W559/ruTkZKWlpWn27NlNrm/cuHHq1q2bVq5cKUlauXKloqKiPPepSNKaNWvk7++v//mf/1FCQoJiYmI0YsSIJu/zl4SEhKi6urrOjb7GGBUXF3vdZxEXF6c333xT5eXl2rlzp6KjozVr1iytWbPG02fGjBnKzs5WeXm5NmzYIGOMLrvsMh04cOCUdfTt27dOQKxvWbx4cYOOy9/fXwMGDFCnTp0aMRpA68UNrMAZYvXq1YqMjPR8/tvf/qbq6mrPi8HGjRsnp9OpL7/8UldddVWDt9u/f3/de++9WrdunT755BNPu8vlatRMhZ+fn6ZMmaLHHntMW7du1a5du/T000979XE4HHI6nfLz8/O0HT16VP/93//d4P00xujRo7VkyRK9+OKLSk5O9rSvW7dOP/zwg0aPHl3vcURFRWngwIFavXq1PvnkE11zzTVefdq3b6/x48fr2LFjmjRpkvbs2aPw8PCT1vHmm2+qqqrqF+vt1q1bg47rvPPO0//+7/82qC/QFhBGgDPEq6++KqfTqbFjx3qephk6dKgSEhIk/fw47uLFizV//nwVFBTod7/7nf7jP/5Dhw8f1kcffaT27dtr0aJF+vTTT3XbbbfpD3/4g/r166eAgAC9++67+vTTTzVnzhzP/s4//3ytWbNGmZmZ6tOnjwIDA3X++eefssbrr79eDz30kCZPnqygoCAlJiZ6/X7ixIlaunSpJk+erJtuukllZWV65JFHTvmkzukYO3asxo0bp3vuuUcVFRWKjY31PE0zbNgwTZkyRdLPT6W8++67mjhxonr16qWffvpJGRkZkqQxY8ZIkv70pz8pKChIsbGxCgsLU3FxsVJTU+V2u3XRRRedso5fGrfG2rJli0aPHq2MjAxNnTrVp9sGzki276AFfu1OPE2Tk5NjLr/8ctOhQwdz9tlnm2uvvdYcPny4Tv/XX3/dXHLJJSY4ONi4XC4THh5urr76avP2228bY4w5fPiwmT59uhk4cKBp37696dChg7ngggvMX//6V1NdXe3ZzldffWXi4+PN2WefbSR5PaVyKjExMUaSue666+r9fUZGhhkwYIBxuVymT58+JjU11aSnpxtJZv/+/Z5+vniaxhhjjh49au655x4THh5u/P39TVhYmPmv//ov891333n67Nixw/z+97834eHhxuVymZCQEDNq1Cizfv16T5/nn3/eXHLJJSY0NNQEBASYbt26mYSEBPPpp582qkZfeO+994wks3LlyhbfN2CDw5hmehMRAABAA3ADKwAAsIp7RgBY90tvMHU4HF43xQJoW5gZAWDd6NGjT/lILF8QB7RtVu8Z+eCDD/Twww8rJydHRUVFeu211zRp0qRTrrNlyxalpKRoz5496tatm+6++24lJSW1TMEAmsXnn39+yheyuVwunz+xAuDMYfUyzQ8//KChQ4dqxowZDXpvwv79+zVhwgT96U9/0osvvqjt27frlltu0TnnnNOo9y4AOLMMGDDAdgkALDpjnqZxOBy/ODNyzz33aP369crPz/e0JSUl6R//+Id27NjRAlUCAABfa1U3sO7YscPzvRcnjBs3Tunp6Tp+/Ljna9b/VVVVldebEWtra/Xtt98qJCREDoej2WsGAKCtMMaosrJS3bp1U7t2vrvttFWFkeLiYoWGhnq1hYaGqrq6WqWlpQoLC6uzTmpqqhYtWtRSJQIA0OYdPHhQPXr08Nn2WlUYkVRnNuPEVaaTzXLMnTtXKSkpns/l5eXq1auXDh48qODg4OYrFACANqaiokI9e/bU2Wef7dPttqow0rVr1zrfbFpSUuL5qvX6uFyuer8XIzg4mDACAEAT+Po2h1b1npHo6GhlZWV5tW3evFkjRoyo934RAABw5rMaRr7//nvt3r1bu3fvlvTzo7u7d+9WYWGhpJ8vsfzrN1YmJSXpwIEDSklJUX5+vjIyMpSenq677rrLRvkAAMAHrF6m2bVrly655BLP5xP3dkybNk2rVq1SUVGRJ5hIUkREhDZu3Kjk5GQtX75c3bp107Jly3jHCAAArdgZ856RllJRUSG3263y8nLuGQEAoBGa6xzaqu4ZAQAAbQ9hBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWGU9jKSlpSkiIkKBgYGKjIzU1q1bT9l/9erVGjp0qM466yyFhYVpxowZKisra6FqAQCAr1kNI5mZmZo1a5bmz5+v3NxcxcXFafz48SosLKy3/7Zt2zR16lTdcMMN2rNnj1555RV9/PHHuvHGG1u4cgAA4CtWw8jSpUt1ww036MYbb9SgQYP02GOPqWfPnlqxYkW9/Xfu3KnevXtr5syZioiI0G9/+1vdfPPN2rVrVwtXDgAAfMVaGDl27JhycnIUHx/v1R4fH6/s7Ox614mJidHXX3+tjRs3yhijw4cPa+3atZo4ceJJ91NVVaWKigqvBQAAnDmshZHS0lLV1NQoNDTUqz00NFTFxcX1rhMTE6PVq1crMTFRAQEB6tq1qzp27KgnnnjipPtJTU2V2+32LD179vTpcQAAgNNj/QZWh8Ph9dkYU6fthLy8PM2cOVMLFixQTk6ONm3apP379yspKemk2587d67Ky8s9y8GDB31aPwAAOD1OWzvu3Lmz/Pz86syClJSU1JktOSE1NVWxsbGaPXu2JOmCCy5Q+/btFRcXpwceeEBhYWF11nG5XHK5XL4/AAAA4BPWZkYCAgIUGRmprKwsr/asrCzFxMTUu86PP/6odu28S/bz85P084wKAABofaxepklJSdFzzz2njIwM5efnKzk5WYWFhZ7LLnPnztXUqVM9/S+//HK9+uqrWrFihQoKCrR9+3bNnDlTI0eOVLdu3WwdBgAAOA3WLtNIUmJiosrKyrR48WIVFRVpyJAh2rhxo8LDwyVJRUVFXu8cmT59uiorK/Xkk0/qzjvvVMeOHXXppZfqoYcesnUIAADgNDnMr+z6RkVFhdxut8rLyxUcHGy7HAAAWo3mOodaf5oGAAD8uhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABglfUwkpaWpoiICAUGBioyMlJbt249Zf+qqirNnz9f4eHhcrlc6tu3rzIyMlqoWgAA4GtOmzvPzMzUrFmzlJaWptjYWD399NMaP3688vLy1KtXr3rXSUhI0OHDh5Wenq5zzz1XJSUlqq6ubuHKAQCArziMMcbWzqOiojR8+HCtWLHC0zZo0CBNmjRJqampdfpv2rRJ11xzjQoKCtSpU6cm7bOiokJut1vl5eUKDg5ucu0AAPzaNNc51NplmmPHjiknJ0fx8fFe7fHx8crOzq53nfXr12vEiBFasmSJunfvrv79++uuu+7S0aNHT7qfqqoqVVRUeC0AAODMYe0yTWlpqWpqahQaGurVHhoaquLi4nrXKSgo0LZt2xQYGKjXXntNpaWluuWWW/Ttt9+e9L6R1NRULVq0yOf1AwAA37B+A6vD4fD6bIyp03ZCbW2tHA6HVq9erZEjR2rChAlaunSpVq1addLZkblz56q8vNyzHDx40OfHAAAAms7azEjnzp3l5+dXZxakpKSkzmzJCWFhYerevbvcbrenbdCgQTLG6Ouvv1a/fv3qrONyueRyuXxbPAAA8BlrMyMBAQGKjIxUVlaWV3tWVpZiYmLqXSc2NlbffPONvv/+e0/b3r171a5dO/Xo0aNZ6wUAAM3D6mWalJQUPffcc8rIyFB+fr6Sk5NVWFiopKQkST9fYpk6daqn/+TJkxUSEqIZM2YoLy9PH3zwgWbPnq3rr79eQUFBtg4DAACcBqvvGUlMTFRZWZkWL16soqIiDRkyRBs3blR4eLgkqaioSIWFhZ7+HTp0UFZWlm6//XaNGDFCISEhSkhI0AMPPGDrEAAAwGmy+p4RG3jPCAAATdPm3jMCAAAgEUYAAIBlhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGBVk8LI888/rw0bNng+33333erYsaNiYmJ04MABnxUHAADaviaFkQcffFBBQUGSpB07dujJJ5/UkiVL1LlzZyUnJ/u0QAAA0LY5m7LSwYMHde6550qSXn/9dV199dW66aabFBsbq4svvtiX9QEAgDauSTMjHTp0UFlZmSRp8+bNGjNmjCQpMDBQR48e9V11AACgzWvSzMjYsWN14403atiwYdq7d68mTpwoSdqzZ4969+7ty/oAAEAb16SZkeXLlys6Olr//Oc/tW7dOoWEhEiScnJydO211/q0QAAA0LY5jDHGdhEtqaKiQm63W+Xl5QoODrZdDgAArUZznUObNDOyadMmbdu2zfN5+fLluvDCCzV58mR99913PisOAAC0fU0KI7Nnz1ZFRYUk6bPPPtOdd96pCRMmqKCgQCkpKT4tEAAAtG1NuoF1//79Gjx4sCRp3bp1uuyyy/Tggw/qk08+0YQJE3xaIAAAaNuaNDMSEBCgH3/8UZL09ttvKz4+XpLUqVMnz4wJAABAQzRpZuS3v/2tUlJSFBsbq48++kiZmZmSpL1796pHjx4+LRAAALRtTZoZefLJJ+V0OrV27VqtWLFC3bt3lyT9/e9/1+9+9zufFggAANo2Hu0FAAAN0lzn0CZdppGkmpoavf7668rPz5fD4dCgQYP0n//5n/Lz8/NZcQAAoO1rUhj54osvNGHCBB06dEgDBgyQMUZ79+5Vz549tWHDBvXt29fXdQIAgDaqSfeMzJw5U3379tXBgwf1ySefKDc3V4WFhYqIiNDMmTN9XSMAAGjDmjQzsmXLFu3cuVOdOnXytIWEhOgvf/mLYmNjfVYcAABo+5o0M+JyuVRZWVmn/fvvv1dAQMBpFwUAAH49mhRGLrvsMt1000368MMPZYyRMUY7d+5UUlKSrrjiCl/XCAAA2rAmhZFly5apb9++io6OVmBgoAIDAxUTE6Nzzz1Xjz32mI9LBAAAbVmT7hnp2LGj3njjDX3xxRfKz8+XMUaDBw/Wueee6+v6AABAG9fgMPJL38b7/vvve35eunRpkwsCAAC/Lg0OI7m5uQ3q53A4mlwMAAD49WlwGHnvvfeasw4AAPAr1aQbWAEAAHyFMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrrIeRtLQ0RUREKDAwUJGRkdq6dWuD1tu+fbucTqcuvPDC5i0QAAA0K6thJDMzU7NmzdL8+fOVm5uruLg4jR8/XoWFhadcr7y8XFOnTtXo0aNbqFIAANBcHMYYY2vnUVFRGj58uFasWOFpGzRokCZNmqTU1NSTrnfNNdeoX79+8vPz0+uvv67du3c3eJ8VFRVyu90qLy9XcHDw6ZQPAMCvSnOdQ63NjBw7dkw5OTmKj4/3ao+Pj1d2dvZJ11u5cqW+/PJLLVy4sEH7qaqqUkVFhdcCAADOHNbCSGlpqWpqahQaGurVHhoaquLi4nrX2bdvn+bMmaPVq1fL6XQ2aD+pqalyu92epWfPnqddOwAA8B3rN7A6HA6vz8aYOm2SVFNTo8mTJ2vRokXq379/g7c/d+5clZeXe5aDBw+eds0AAMB3Gja90Aw6d+4sPz+/OrMgJSUldWZLJKmyslK7du1Sbm6ubrvtNklSbW2tjDFyOp3avHmzLr300jrruVwuuVyu5jkIAABw2qzNjAQEBCgyMlJZWVle7VlZWYqJianTPzg4WJ999pl2797tWZKSkjRgwADt3r1bUVFRLVU6AADwIWszI5KUkpKiKVOmaMSIEYqOjtYzzzyjwsJCJSUlSfr5EsuhQ4f0wgsvqF27dhoyZIjX+l26dFFgYGCddgAA0HpYDSOJiYkqKyvT4sWLVVRUpCFDhmjjxo0KDw+XJBUVFf3iO0cAAEDrZvU9IzbwnhEAAJqmzb1nBAAAQCKMAAAAywgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAq6yHkbS0NEVERCgwMFCRkZHaunXrSfu++uqrGjt2rM455xwFBwcrOjpab731VgtWCwAAfM1qGMnMzNSsWbM0f/585ebmKi4uTuPHj1dhYWG9/T/44AONHTtWGzduVE5Oji655BJdfvnlys3NbeHKAQCArziMMcbWzqOiojR8+HCtWLHC0zZo0CBNmjRJqampDdrGeeedp8TERC1YsKBB/SsqKuR2u1VeXq7g4OAm1Q0AwK9Rc51Drc2MHDt2TDk5OYqPj/dqj4+PV3Z2doO2UVtbq8rKSnXq1OmkfaqqqlRRUeG1AACAM4e1MFJaWqqamhqFhoZ6tYeGhqq4uLhB23j00Uf1ww8/KCEh4aR9UlNT5Xa7PUvPnj1Pq24AAOBb1m9gdTgcXp+NMXXa6vPyyy/rvvvuU2Zmprp06XLSfnPnzlV5eblnOXjw4GnXDAAAfMdpa8edO3eWn59fnVmQkpKSOrMl/y4zM1M33HCDXnnlFY0ZM+aUfV0ul1wu12nXCwAAmoe1mZGAgABFRkYqKyvLqz0rK0sxMTEnXe/ll1/W9OnT9dJLL2nixInNXSYAAGhm1mZGJCklJUVTpkzRiBEjFB0drWeeeUaFhYVKSkqS9PMllkOHDumFF16Q9HMQmTp1qh5//HH95je/8cyqBAUFye12WzsOAADQdFbDSGJiosrKyrR48WIVFRVpyJAh2rhxo8LDwyVJRUVFXu8cefrpp1VdXa1bb71Vt956q6d92rRpWrVqVUuXDwAAfMDqe0Zs4D0jAAA0TZt7zwgAAIBEGAEAAJYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFXWw0haWpoiIiIUGBioyMhIbd269ZT9t2zZosjISAUGBqpPnz566qmnWqhSAADQHKyGkczMTM2aNUvz589Xbm6u4uLiNH78eBUWFtbbf//+/ZowYYLi4uKUm5urefPmaebMmVq3bl0LVw4AAHzFYYwxtnYeFRWl4cOHa8WKFZ62QYMGadKkSUpNTa3T/5577tH69euVn5/vaUtKStI//vEP7dixo0H7rKiokNvtVnl5uYKDg0//IAAA+JVornOo02dbaqRjx44pJydHc+bM8WqPj49XdnZ2vevs2LFD8fHxXm3jxo1Tenq6jh8/Ln9//zrrVFVVqaqqyvO5vLxc0s8DCgAAGu7EudPX8xjWwkhpaalqamoUGhrq1R4aGqri4uJ61ykuLq63f3V1tUpLSxUWFlZnndTUVC1atKhOe8+ePU+jegAAfr3Kysrkdrt9tj1rYeQEh8Ph9dkYU6ftl/rX137C3LlzlZKS4vl85MgRhYeHq7Cw0KcDiZOrqKhQz549dfDgQS6NtRDGvOUx5i2PMW955eXl6tWrlzp16uTT7VoLI507d5afn1+dWZCSkpI6sx8ndO3atd7+TqdTISEh9a7jcrnkcrnqtLvdbv54W1hwcDBj3sIY85bHmLc8xrzltWvn2+dfrD1NExAQoMjISGVlZXm1Z2VlKSYmpt51oqOj6/TfvHmzRowYUe/9IgAA4Mxn9dHelJQUPffcc8rIyFB+fr6Sk5NVWFiopKQkST9fYpk6daqnf1JSkg4cOKCUlBTl5+crIyND6enpuuuuu2wdAgAAOE1W7xlJTExUWVmZFi9erKKiIg0ZMkQbN25UeHi4JKmoqMjrnSMRERHauHGjkpOTtXz5cnXr1k3Lli3TVVdd1eB9ulwuLVy4sN5LN2gejHnLY8xbHmPe8hjzltdcY271PSMAAADWXwcPAAB+3QgjAADAKsIIAACwijACAACsapNhJC0tTREREQoMDFRkZKS2bt16yv5btmxRZGSkAgMD1adPHz311FMtVGnb0Zgxf/XVVzV27Fidc845Cg4OVnR0tN56660WrLZtaOzf+Qnbt2+X0+nUhRde2LwFtkGNHfOqqirNnz9f4eHhcrlc6tu3rzIyMlqo2rahsWO+evVqDR06VGeddZbCwsI0Y8YMlZWVtVC1rd8HH3ygyy+/XN26dZPD4dDrr7/+i+v45Bxq2pg1a9YYf39/8+yzz5q8vDxzxx13mPbt25sDBw7U27+goMCcddZZ5o477jB5eXnm2WefNf7+/mbt2rUtXHnr1dgxv+OOO8xDDz1kPvroI7N3714zd+5c4+/vbz755JMWrrz1auyYn3DkyBHTp08fEx8fb4YOHdoyxbYRTRnzK664wkRFRZmsrCyzf/9+8+GHH5rt27e3YNWtW2PHfOvWraZdu3bm8ccfNwUFBWbr1q3mvPPOM5MmTWrhyluvjRs3mvnz55t169YZSea11147ZX9fnUPbXBgZOXKkSUpK8mobOHCgmTNnTr397777bjNw4ECvtptvvtn85je/abYa25rGjnl9Bg8ebBYtWuTr0tqspo55YmKiuffee83ChQsJI43U2DH/+9//btxutykrK2uJ8tqkxo75ww8/bPr06ePVtmzZMtOjR49mq7Eta0gY8dU5tE1dpjl27JhycnIUHx/v1R4fH6/s7Ox619mxY0ed/uPGjdOuXbt0/PjxZqu1rWjKmP+72tpaVVZW+vyLl9qqpo75ypUr9eWXX2rhwoXNXWKb05QxX79+vUaMGKElS5aoe/fu6t+/v+666y4dPXq0JUpu9Zoy5jExMfr666+1ceNGGWN0+PBhrV27VhMnTmyJkn+VfHUOtf6tvb5UWlqqmpqaOl+0FxoaWucL9k4oLi6ut391dbVKS0sVFhbWbPW2BU0Z83/36KOP6ocfflBCQkJzlNjmNGXM9+3bpzlz5mjr1q1yOtvUf/YtoiljXlBQoG3btikwMFCvvfaaSktLdcstt+jbb7/lvpEGaMqYx8TEaPXq1UpMTNRPP/2k6upqXXHFFXriiSdaouRfJV+dQ9vUzMgJDofD67Mxpk7bL/Wvrx0n19gxP+Hll1/Wfffdp8zMTHXp0qW5ymuTGjrmNTU1mjx5shYtWqT+/fu3VHltUmP+zmtra+VwOLR69WqNHDlSEyZM0NKlS7Vq1SpmRxqhMWOel5enmTNnasGCBcrJydGmTZu0f/9+z/edoXn44hzapv6J1LlzZ/n5+dVJzSUlJXWS2wldu3att7/T6VRISEiz1dpWNGXMT8jMzNQNN9ygV155RWPGjGnOMtuUxo55ZWWldu3apdzcXN12222Sfj5RGmPkdDq1efNmXXrppS1Se2vVlL/zsLAwde/eXW6329M2aNAgGWP09ddfq1+/fs1ac2vXlDFPTU1VbGysZs+eLUm64IIL1L59e8XFxemBBx5gprsZ+Ooc2qZmRgICAhQZGamsrCyv9qysLMXExNS7TnR0dJ3+mzdv1ogRI+Tv799stbYVTRlz6ecZkenTp+ull17iem4jNXbMg4OD9dlnn2n37t2eJSkpSQMGDNDu3bsVFRXVUqW3Wk35O4+NjdU333yj77//3tO2d+9etWvXTj169GjWetuCpoz5jz/+qHbtvE9rfn5+kv7vX+vwLZ+dQxt1u2srcOJRsPT0dJOXl2dmzZpl2rdvb7766itjjDFz5swxU6ZM8fQ/8VhScnKyycvLM+np6Tza20iNHfOXXnrJOJ1Os3z5clNUVORZjhw5YusQWp3Gjvm/42maxmvsmFdWVpoePXqYq6++2uzZs8ds2bLF9OvXz9x44422DqHVaeyYr1y50jidTpOWlma+/PJLs23bNjNixAgzcuRIW4fQ6lRWVprc3FyTm5trJJmlS5ea3Nxcz+PUzXUObXNhxBhjli9fbsLDw01AQIAZPny42bJli+d306ZNM6NGjfLq//7775thw4aZgIAA07t3b7NixYoWrrj1a8yYjxo1ykiqs0ybNq3lC2/FGvt3/q8II03T2DHPz883Y8aMMUFBQaZHjx4mJSXF/Pjjjy1cdevW2DFftmyZGTx4sAkKCjJhYWHmuuuuM19//XULV916vffee6f8/+fmOoc6jGHuCgAA2NOm7hkBAACtD2EEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQBtwvvvvy+Hw6EjR47YLgVAIxFGAACAVYQRAABgFWEEgE8YY7RkyRL16dNHQUFBGjp0qNauXSvp/y6hbNiwQUOHDlVgYKCioqL02WefeW1j3bp1Ou+88+RyudS7d289+uijXr+vqqrS3XffrZ49e8rlcqlfv35KT0/36pOTk6MRI0borLPOUkxMjD7//PPmPXAAp40wAsAn7r33Xq1cuVIrVqzQnj17lJycrD/+8Y/asmWLp8/s2bP1yCOP6OOPP1aXLl10xRVX6Pjx45J+DhEJCQm65ppr9Nlnn+m+++7Tn//8Z61atcqz/tSpU7VmzRotW7ZM+fn5euqpp9ShQwevOubPn69HH31Uu3btktPp1PXXX98ixw/gNJzu1w0DwPfff28CAwNNdna2V/sNN9xgrr32Ws/Xkq9Zs8bzu7KyMhMUFGQyMzONMcZMnjzZjB071mv92bNnm8GDBxtjjPn888+NJJOVlVVvDSf28fbbb3vaNmzYYCSZo0eP+uQ4ATQPZkYAnLa8vDz99NNPGjt2rDp06OBZXnjhBX355ZeeftHR0Z6fO3XqpAEDBig/P1+SlJ+fr9jYWK/txsbGat++faqpqdHu3bvl5+enUaNGnbKWCy64wPNzWFiYJKmkpOS0jxFA83HaLgBA61dbWytJ2rBhg7p37+71O5fL5RVI/p3D4ZD08z0nJ34+wRjj+TkoKKhBtfj7+9fZ9on6AJyZmBkBcNoGDx4sl8ulwsJCnXvuuV5Lz549Pf127tzp+fm7777T3r17NXDgQM82tm3b5rXd7Oxs9e/fX35+fjr//PNVW1vrdQ8KgLaBmREAp+3ss8/WXXfdpeTkZNXW1uq3v/2tKioqlJ2drQ4dOig8PFyStHjxYoWEhCg0NFTz589X586dNWnSJEnSnXfeqYsuukj333+/EhMTtWPHDj355JNKS0uTJPXu3VvTpk3T9ddfr2XLlmno0KE6cOCASkpKlJCQYOvQAfgAYQSAT9x///3q0qWLUlNTVVBQoI4dO2r48OGaN2+e5zLJX/7yF91xxx3at2+fhg4dqvXr1ysgIECSNHz4cP3tb3/TggULdP/99yssLEyLFy/W9OnTPftYsWKF5s2bp1tuuUVlZWXq1auX5s2bZ+NwAfiQw/zrRVkAaAbvv/++LrnkEn333Xfq2LGj7XIAnGG4ZwQAAFhFGAEAAFZxmQYAAFjFzAgAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAqv8Hut6IunpcXGUAAAAASUVORK5CYII="},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* background: */\n    progress::-webkit-progress-bar {background-color: #CDCDCD; width: 100%;}\n    progress {background-color: #CDCDCD;}\n\n    /* value: */\n    progress::-webkit-progress-value {background-color: #00BFFF  !important;}\n    progress::-moz-progress-bar {background-color: #00BFFF  !important;}\n    progress {color: #00BFFF ;}\n\n    /* optional */\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #000000;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      0% [0/1]\n      <br>\n      \n    </div>\n    "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[94mif\u001b[0m \u001b[94m1\u001b[0m:\u001b[2m#训练\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 2 \u001b[2m│   \u001b[0mkeras_model.fit(train_data = dl_train,                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mval_data = dl_train,                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mepochs=\u001b[94m1\u001b[0m,                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpatience=\u001b[94m20\u001b[0m,                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mfit\u001b[0m:\u001b[94m228\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrain_epoch_runner = \u001b[96mself\u001b[0m.EpochRunner(train_step_runner,should_quiet)          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrain_metrics = {\u001b[33m'\u001b[0m\u001b[33mepoch\u001b[0m\u001b[33m'\u001b[0m:epoch}                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m228 \u001b[2m│   │   │   \u001b[0mtrain_metrics.update(train_epoch_runner(train_dataloader))                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m229 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m230 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m name, metric \u001b[95min\u001b[0m train_metrics.items():                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m231 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.history[name] = \u001b[96mself\u001b[0m.history.get(name, []) + [metric]             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m__call__\u001b[0m:\u001b[94m48\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m step, batch \u001b[95min\u001b[0m loop:                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 47 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.accelerator.accumulate(\u001b[96mself\u001b[0m.net):                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 48 \u001b[2m│   │   │   │   \u001b[0mstep_losses,step_metrics = \u001b[96mself\u001b[0m.steprunner(batch,step)                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 49 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mstep_log = \u001b[96mdict\u001b[0m(step_losses,**step_metrics)                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m#                 print(step_losses.items())\u001b[0m                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m k,v \u001b[95min\u001b[0m step_losses.items():                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m__call__\u001b[0m:\u001b[94m115\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.optimizer \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.stage==\u001b[33m\"\u001b[0m\u001b[33mtrain\u001b[0m\u001b[33m\"\u001b[0m:                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.backward(loss)                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.accelerator.sync_gradients:                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.clip_grad_norm_(\u001b[96mself\u001b[0m.net.parameters(), \u001b[94m1.0\u001b[0m)               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.optimizer.step()                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.lr_scheduler \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.lr_scheduler.step()                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m1893\u001b[0m in \u001b[92mclip_grad_norm_\u001b[0m        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1890 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# `accelerator.backward(loss)` is doing that automatically. Therefore, its i\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1891 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# We cannot return the gradient norm because DeepSpeed does it.\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1892 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mNone\u001b[0m                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1893 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.unscale_gradients()                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1894 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m torch.nn.utils.clip_grad_norm_(parameters, max_norm, norm_type=norm_type)  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1895 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1896 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mclip_grad_value_\u001b[0m(\u001b[96mself\u001b[0m, parameters, clip_value):                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m1856\u001b[0m in \u001b[92munscale_gradients\u001b[0m      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1853 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m opt \u001b[95min\u001b[0m optimizer:                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1854 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[96misinstance\u001b[0m(opt, AcceleratedOptimizer):                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1855 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mopt = opt.optimizer                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1856 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.scaler.unscale_(opt)                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1857 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1858 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mclip_grad_norm_\u001b[0m(\u001b[96mself\u001b[0m, parameters, max_norm, norm_type=\u001b[94m2\u001b[0m):                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1859 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/\u001b[0m\u001b[1;33mgrad_scaler.py\u001b[0m:\u001b[94m275\u001b[0m in \u001b[92munscale_\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m272 \u001b[0m\u001b[2m│   │   \u001b[0moptimizer_state = \u001b[96mself\u001b[0m._per_optimizer_states[\u001b[96mid\u001b[0m(optimizer)]                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m273 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m274 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m optimizer_state[\u001b[33m\"\u001b[0m\u001b[33mstage\u001b[0m\u001b[33m\"\u001b[0m] \u001b[95mis\u001b[0m OptState.UNSCALED:                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m275 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33munscale_() has already been called on this optimizer sin\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m276 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m optimizer_state[\u001b[33m\"\u001b[0m\u001b[33mstage\u001b[0m\u001b[33m\"\u001b[0m] \u001b[95mis\u001b[0m OptState.STEPPED:                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33munscale_() is being called after step().\u001b[0m\u001b[33m\"\u001b[0m)                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m278 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mRuntimeError: \u001b[0m\u001b[1;35munscale_\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m has already been called on this optimizer since the last \u001b[1;35mupdate\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#训练</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 2 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>keras_model.fit(train_data = dl_train,                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>val_data = dl_train,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>epochs=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>patience=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span>,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">228</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>train_epoch_runner = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.EpochRunner(train_step_runner,should_quiet)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>train_metrics = {<span style=\"color: #808000; text-decoration-color: #808000\">'epoch'</span>:epoch}                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>228 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>train_metrics.update(train_epoch_runner(train_dataloader))                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">229 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">230 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> name, metric <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> train_metrics.items():                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">231 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.history[name] = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.history.get(name, []) + [metric]             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">48</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 46 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> step, batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> loop:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 47 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.accumulate(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.net):                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 48 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>step_losses,step_metrics = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.steprunner(batch,step)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 49 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>step_log = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>(step_losses,**step_metrics)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 50 #                 print(step_losses.items())</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 51 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k,v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> step_losses.items():                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.stage==<span style=\"color: #808000; text-decoration-color: #808000\">\"train\"</span>:                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.backward(loss)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.sync_gradients:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.clip_grad_norm_(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.net.parameters(), <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span>)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.step()                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lr_scheduler <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lr_scheduler.step()                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1893</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">clip_grad_norm_</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1890 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># `accelerator.backward(loss)` is doing that automatically. Therefore, its i</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1891 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># We cannot return the gradient norm because DeepSpeed does it.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1892 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1893 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.unscale_gradients()                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1894 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.nn.utils.clip_grad_norm_(parameters, max_norm, norm_type=norm_type)  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1895 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1896 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">clip_grad_value_</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, parameters, clip_value):                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1856</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unscale_gradients</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1853 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> opt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> optimizer:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1854 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(opt, AcceleratedOptimizer):                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1855 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>opt = opt.optimizer                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1856 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.unscale_(opt)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1857 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1858 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">clip_grad_norm_</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, parameters, max_norm, norm_type=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>):                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1859 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">grad_scaler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">275</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unscale_</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">272 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>optimizer_state = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._per_optimizer_states[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">id</span>(optimizer)]                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">273 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">274 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> optimizer_state[<span style=\"color: #808000; text-decoration-color: #808000\">\"stage\"</span>] <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> OptState.UNSCALED:                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>275 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"unscale_() has already been called on this optimizer sin</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">276 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> optimizer_state[<span style=\"color: #808000; text-decoration-color: #808000\">\"stage\"</span>] <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> OptState.STEPPED:                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"unscale_() is being called after step().\"</span>)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">278 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">unscale_</span><span style=\"font-weight: bold\">()</span> has already been called on this optimizer since the last <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">update</span><span style=\"font-weight: bold\">()</span>.\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"!huggingface-cli login --token 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 --add-to-git-credential\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:53:50.821981Z","iopub.execute_input":"2023-08-17T10:53:50.822350Z","iopub.status.idle":"2023-08-17T10:53:53.020795Z","shell.execute_reply.started":"2023-08-17T10:53:50.822288Z","shell.execute_reply":"2023-08-17T10:53:53.019610Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"if 1:\n    from huggingface_hub import HfApi\n    api = HfApi()\n    #创建huggingface 模型库\n    repo_id = \"zhangbo2008/chatglm2-6b-torchkeras\"\n    api.create_repo(repo_id=repo_id)\n    #上传模型可能需要等待10分钟左右~\n    api.upload_folder(\n        folder_path=ckpt_path,\n        repo_id=repo_id,\n        repo_type=\"model\", #space, model, datasets\n    )","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:53:53.022383Z","iopub.execute_input":"2023-08-17T10:53:53.023326Z","iopub.status.idle":"2023-08-17T10:53:53.030387Z","shell.execute_reply.started":"2023-08-17T10:53:53.023286Z","shell.execute_reply":"2023-08-17T10:53:53.029322Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from peft import PeftModel  # 合并model之后才可以预测.\n\npeft_loaded = PeftModel.from_pretrained(model,ckpt_path)\nmodel_new = peft_loaded.merge_and_unload() #合并lora权重","metadata":{"execution":{"iopub.status.busy":"2023-08-17T11:05:23.071839Z","iopub.execute_input":"2023-08-17T11:05:23.072275Z","iopub.status.idle":"2023-08-17T11:05:36.713578Z","shell.execute_reply.started":"2023-08-17T11:05:23.072239Z","shell.execute_reply":"2023-08-17T11:05:36.712496Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"response,history= model_new.chat(tokenizer,query='梦中情炉？',history=[])\nprint(response)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T11:05:45.960015Z","iopub.execute_input":"2023-08-17T11:05:45.960427Z","iopub.status.idle":"2023-08-17T11:05:51.253641Z","shell.execute_reply.started":"2023-08-17T11:05:45.960392Z","shell.execute_reply":"2023-08-17T11:05:51.252514Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"to folders忙|\n，\t; of\n也互联\n也互联垛 (  \n也 these along饮水ESes. D D D D D D D C IN\n管\n是倍  \n管溜.痂。\n是个→) –I\n也 of\n – =前后,->\n –I/ he\n是目: –UN\n學\n也 . D D D D C IN\n瓜 \"\"; ==\n使之\n也.茅直升ich是人类'\n是全球 D C\n","output_type":"stream"}]},{"cell_type":"code","source":"if 0:\n    tokenizer.decode([13,    13,    13,    13,    13,\n         31404,])","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:54:08.467537Z","iopub.execute_input":"2023-08-17T10:54:08.467920Z","iopub.status.idle":"2023-08-17T10:54:08.476087Z","shell.execute_reply.started":"2023-08-17T10:54:08.467883Z","shell.execute_reply":"2023-08-17T10:54:08.475013Z"},"trusted":true},"execution_count":12,"outputs":[]}]}